[" link : canonical link : sitemap [ submit ] explore download learn values community blog donate search \u2190 back how nix works how nix works nix is a purely functional package manager . this means that it treats packages like values in purely functional programming languages such as haskell \u2014 they are built by functions that don \u2019 t have side - effects , and they never change after they have been built . nix stores packages in the nix store , usually the directory / nix / store , where each package has its own unique subdirectory such as / nix / store / b6gvzjyb2pg0kjfwrjm", "g1vfhh54ad73z - firefox - 33 . 1 / where b6gvzjyb2pg0 \u2026 is a unique identifier for the package that captures all its dependencies ( it \u2019 s a cryptographic hash of the package \u2019 s build dependency graph ) . this enables many powerful features . multiple versions you can have multiple versions or variants of a package installed at the same time . this is especially important when different applications have dependencies on different versions of the same package \u2014 it prevents the \u201c dll hell \u201d . because of the hashing scheme , different versions of a package", " end up in different paths in the nix store , so they don \u2019 t interfere with each other . an important consequence is that operations like upgrading or uninstalling an application cannot break other applications , since these operations never \u201c destruct ively \u201d update or delete files that are used by other packages . complete dependencies when you \u2019 re making a package for a package management system , like rpm , you are supposed to declare its dependencies , but you can \u2019 t easily guarantee that your dependency declaration is complete . if you forget a dependency , that you have separately installed on your machine , then the component may build and work correctly on", " your machine , but failing on the end user \u2019 s machine . nix ensures that package dependency specifications are complete . under nix , a build process will only find resources that have been declared explicitly as dependencies . there \u2019 s no way it can build until everything it needs has been correctly declared . if it builds , you will know you \u2019 ve provided a complete declaration . once a build is complete , ongoing runtime dependencies are detected automatically . multi - user support starting at version 0 . 11 , nix has multi - user support . this means that non - privileged users can securely install software . each user can have a different profile , a set", " of packages in the nix store that appear in the user \u2019 s path . if a user installs a package that another user has already installed previously , the package won \u2019 t be built or downloaded a second time . at the same time , it is not possible for one user to inject a trojan horse into a package that might be used by another user . atomic upgrades and rollbacks since package management operations never overwrite packages in the nix store but just add new versions in different paths , they are atomic . so during a package upgrade , there is no time window in which the package has some files from the old version and some files from", " the new version \u2014 which would be bad because a program might well crash if it \u2019 s started during that period . and since packages aren \u2019 t overwritten , the old versions are still there after an upgrade . this means that you can roll back to the old version : $ nix - env - - upgrade _ some - packages _ $ nix - env - - rollback garbage collection when you uninstall a package like this \u2026 $ nix - env - - uninstall firefox the package isn \u2019 t deleted from the system right away ( after all , you might want to do a rollback , or", " it might be in the profiles of other users ) . instead , unused packages can be deleted safely by running the garbage collector : $ nix - collect - garbage this deletes all packages that aren \u2019 t in use by any user profile or by a currently running program . functional package language packages are built from nix expressions , which is a simple functional language . a nix expression describe s everything that goes into a package build action ( a \u201c derivation \u201d ) : other packages , sources , the build script , environment variables for the build script , etc . nix tries very hard to ensure that nix expressions are deterministic :building a", " nix expression twice should yield the same result . because it \u2019 s a functional language , it \u2019 s easy to supportbuilding variants of a package : turn the nix expression into a function and call it any number of times with the appropriate arguments . due to the hashing scheme , variants don \u2019 t conflict with each other in the nix store . transparent source / binary deployment nix expressions generally describe how to build a package from source , so an installation action like $ nix - env - - install firefox could cause quite a bit of build activity , as not only firefox but also all its dependencies ( all the way", " up to the c library and the compiler ) would have to be built , at least if they are not already in the nix store . this is a source deployment model . for most users ,building from source is not very pleasant as it takes far too long . however , nix can automatically skipbuilding from source and instead use a binary cache , a web server that provides pre - built binaries . for instance , when asked to build / nix / store / b6gvzjyb2pg0 \u2026 - firefox - 33 . 1 from source , nix would first check if the file http : / / cache . nix", "os . org / b6gvzjyb2pg0 \u2026 . narinfo exists , and if so , fetch the pre - built binary referenced from there ; otherwise , it would fall back tobuilding from source . nix packages collection we provide a large set of nix expressions containing thousands of existing unix packages , the nix packages collection ( nixpkgs ) . portability nix runs on linux and macos . how nixos works ? nixos is based on nix , a purely functional package management system . nix stores all packages in isolation from each other under paths such as / nix / store / 5rnfzla", "9kcx4mj5zdc7nlnv8na1najvg - firefox - 3 . 5 . 4 / the string 5rnf . . . is a cryptographic hash of all input used to build the package . packages are never overwritten after they have been built ; instead , if you change the build descript ion of a package ( its \u2018 nix expression \u2019 ) , it \u2019 s rebuilt and installed in a different path in / nix / store so it doesn \u2019 t interfere with the old version . nixos extends this by using nix not only to build packages , but also things", " like configuration files . for instance , the configuration of the ssh daemon is also built from a nix expression and stored under a path like / nix / store / s2sjbl85xnrc18rl4fhn56irkxqxyk4p - sshd \\ _ config bybuilding entire system configurations from a nix expression , nixos ensures that such configurations don \u2019 t overwrite each other , can be rolled back , and so on . a big implication of the way that nix / nixos stores packages is that there is no / bin , / sbin , / lib , / usr", " , and so on . instead all packages are kept in / nix / store . ( the only exception is a symlink / bin / sh to bash in the nix store . ) not using \u2018 global \u2019 directories such as / bin is what allows multiple versions of a package to coexist . nix does have a / etc to keep system - wide configuration files , but most files in that directory are symlinks to generated files in / nix / store . declarative system configuration model in nixos , the entire operating system \u2014 the kernel , applications , system packages , configuration files , and so on \u2014 is built by", " the nix package manager from a descript ion in a purely functional build language . the fact that it \u2019 s purely functional essentially means thatbuilding a new configuration cannot overwrite previous configurations . most of the other features follow from this . you configure a nixos system by writing a specification of the functionality that you want on your machine in / etc / nixos / configuration . nix . for instance , here is a minimal configuration of a machine running an ssh daemon : { boot . loader . grub . device = \" / dev / sda \" ; filesystems . \" / \" . device = \" /", " dev / sda1 \" ; services . sshd . enable = true ; } after changing / etc / nixos / configuration . nix , you realise the configuration by running this command : $ nixos - rebuild switch this command does everything necessary to make the configuration happen , including downloading and compiling openssh , generating the configuration files for the ssh server , and so on . reliable upgrades another advantage of purely functional package management is that nixos - rebuild switch will always produce the same result , regardless of what packages or configuration files you already had on your system . thus , upgrading a system is as reliable as reinstalling from scratch .", " atomic upgrades nixos has a transactional approach to configuration management : configuration changes such as upgrades are atomic . this means that if the upgrade to a new configuration is interrupted \u2014 say , the power fails half - way through \u2014 the system will still be in a consistent state : it will either boot in the old or the new configuration . in most other systems , you \u2019 ll end up in an inconsistent state , and your machine may not even boot anymore . rollbacks because the files of a new configuration don \u2019 t overwrite old ones , you can ( atomically ) roll back to a previous configuration . for instance , if after a nixos", " - rebuild switch you discover that you don \u2019 t like the new configuration , you can just go back : $ nixos - rebuild switch - - rollback in fact , all old system configurations automatically show up in the boot menu . so if the new configuration crashes or doesn \u2019 t boot properly , you can just roll back by selecting an older configuration in the boot menu . rollbacks are very fast : it doesn \u2019 t involve lots of files having to be restored from copies . nixos boot menu reproducible system configurations nixos \u2019 declarative configuration model makes it easy to reproduce a system configuration on another machine ( for instance , to", " test a change in a test environment before doing it on the production server ) . you just copy the configuration . nix file to the target nixos machine and run nixos - rebuild switch . this will give you the same configuration ( kernel , applications , system services , and so on ) except for \u2018 mutable state \u2019 ( such as the stuff that lives in / var ) . safe to test changes nixos makes it safe to test potentially dangerous changes to the system , because you can always roll back . ( unless you screw up the boot loader , that is \u2026 ) for instance , whether the change is as simple as enabling a system", " service , or as large as rebuilding the entire system with a new version of glibc , you can test it by doing : $ nixos - rebuild test this builds and activates the new configuration , but doesn \u2019 t make it the boot default . thus , rebooting the system will take you back to the previous , known - good configuration . an even nicer way to test changes is the following : $ nixos - rebuild build - vm $ . / result / bin / run - \\ * - vm this builds and starts a virtual machine that contains the new system configuration ( i . e . a clone of", " the configuration of the host machine , with any changes that you made to configuration . nix ) . the vm doesn \u2019 t share any data with the host , so you can safely experiment inside the vm . the build - vm command is very efficient ( it doesn \u2019 t require a disk image for the vm to be created ) , so it \u2019 s a very effective way to test changes . the project * channel status * packages search * options search * reproducible builds status * security get in touch * forum * matrix chat * commercial support contribute * contributing guide * donate stay up to date * blog * newsletter - - -", " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - copyright \u00a9 2024 nixos contributors cc - by - sa - 4 . 0 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -", " - - - - - - - - - - - - - - - - - - - - - - - - - connect with us :", " nixos in production the nixos handbook for professional use only gabriella gonzalez this book is available at http : / / leanpub . com / nixos - in - production this version was published on 2024 - 09 - 07 * * * * * this is a leanpub book . leanpub empowers authors and publishers with the lean publishing process . lean publishing is the act of publishing an in - progress ebook using lightweight tools and many iterations to get reader feedback , pivot until you have the right book and build traction once you do . * * * * * this work is licensed under a creative commons at", "tribution - noncommercial - sharealike 4 . 0 international license table of contents 1 introduction 2 what is nixos for ? desktop vs . server on - premises vs . software as a service virtualization the killer app for nixos profile of a nixos adopter what does nixos replace ? 3 the big picture the zen of nixos gitops devops architecture scope 4 setting up your development environment installing nix running a nixos virtual machine 5 our first web server hello ,world ! devops todo list passing through the filesystem 6 nixos option definitions anatomy of a nixos module syntactic sugar nixos", " modules are not language features nixos recursion 7 advanced option definitions imports lib utilities 8 deploying to aws using terraform configuring your access keys a minimal terraform specification deploying our configuration cleaning up terraform walkthrough s3 backend version control 9 continuous integration and deployment continuous integration continuous deployment 10 flakes motivation flakes , step - by - step flake - related commands 11 integration testing nixos test interactive testing shared constants 12 containers docker registry podman streamlayeredimage nixos containers notes 1 introduction this book is a guide to using nixos in production , where nixos is", " an operating system built on top of the nix package manager . this guide assumes that you have some familiarity with nixos , so if you have never used nixos before and you \u2019 re looking for a tutorial or introduction then this book might not be for you . some chapters may review basic concepts , but in general they will not bewritten for a beginner audience . however , this book will appeal to you if you wish to answer the following questions : what real -world use cases does nixos address better than the alternatives ? what does a mature nixos enterprise look like ? how do i smoothly migrate an organization to adopt nixos ?", " what potential pitfalls of nixos should i be mindful to avoid ? how can i effectively support and debug nixos when things go wrong ? i \u2019 m writing this book because i cultivated years of professional experience doing all of the above , back when no such resource existed . i learned nixos the hard way and i \u2019 m writing this book so that you don \u2019 t have to make the same mistakes i did . currently , most educational resources for nixos ( including the nixos manual ) arewritten with desktop users in mind , whereas i view nixos as far better suited as a production operating system . this book attempts to", " fill that documentation gap by catering to professional nixos users instead of hobbyists . continue reading on if you want to use nixos \u201c for real \u201d and build a career around one of the hottest emerging devops technologies . this book will improve your nixos proficiency and outline a path towards using nixos to improve your organization \u2019 s operational maturity and reliability . 2 what is nixos for ? some nixos users might try to \u201c convert \u201d others to nixos using a pitch that goes something like this : nixos is a linux distribution built on top of the nix package manager . it uses declarative configuration and allows reliable system upgrades .", " source : wikipedia - nixos this sort of feature - oriented descript ion explains what nixos does , but does not quite explain what nixos is for . what sort of useful things can you do with nixos ? when is nixos the best solution ? what types of projects , teams , or organizations should prefer using nixos over other the alternatives ? come to think of it , what are the alternatives ? is nixos supposed to replace debian ? or docker ? or ansible ? or vagrant ? where does nixos fit in within the modern software landscape ? in this chapter i \u2019 ll help you better understand when you should", " recommend nixos to others and ( just as important ! ) when you should gently nudge people away from nixos . hopefully this chapter will improve your overall understanding of nixos \u2019 s \u201c niche \u201d . desktop vs . server the title of this book might have tipped you off that i will endorse nixos for use as a server operating system rather than a desktop operating system . i would not confidently recommend nixos as a desktop operating system because : nixos expects users to be developers who are more hands - on with their system nixos does not come preinstalled on most computers and the installation guide assumes quite a bit of", " technical proficiency . for example , nixos is typically configured via text files and upgrades are issued from the command line . nixpkgs doesn \u2019 t enjoy mainstream support for desktop - oriented applications \u2026 especially games and productivity tools . nixpkgs is a fairly large software distribution , especially compared to other linux software distributions , but most desktop applications will not support the nix ecosystem out - of - the - box . the nixos user experience differs from what most desktop users expect most desktop users ( especially non - technical users ) expect to install packages by either downloading the package from the publisher \u2019 s web page or by visiting an \u201c app store", " \u201d of some sort . they don \u2019 t expect to modify a text configuration file in order to install package . however , the above limitations don \u2019 t apply when using nixos as a server operating system : servers are managed by technical users comfortable with the command - line server operating systems are often headless machines that only support a command - line interface . in fact , a typical ops team would likely frown upon managing a server in any other way . nixpkgs provides amazing support for server - oriented software and services nginx , postgres , redis , \u2026 you name it , nixpkgs most likely has the service", " you need and it \u2019 s a dream to set up . end users can more easily self - serve if they stray from the beaten path server - oriented software is more likely to be open source than desktop - oriented software and therefore easier to package . furthermore , nixos possesses several unique advantages compared to other server - oriented operating systems : nixos can be managed entirely declaratively you can manage every single aspect of a nixos server using a single , uniform , declarative option system . this goes hand - in - hand with gitops for managing a fleet of machines ( which i \u2019 ll cover in a future chapter ) . nix", "os upgrades are fast , safe and reliable upgrades are atomic , meaning that you can \u2019 t leave a system in an unrecoverable state by canceling the upgrade midway ( e . g . ctrl - c or loss of power ) . you can also build the desired system ahead of time if you want to ensure that the upgrade is quick and smooth . nixos systems are lean , lean , lean if you like alpine linux then you \u2019 ll love nixos . nixos systems tend to be very light on disk , memory , and cpu resources because you only pay for what you use . you can achieve astonishingly small system footprints", " whether you run services natively on the host or inside of containers . nixos systems have better security - related defaults you get several security improvements for free or almost free by virtue of using nixos . for example , your system \u2019 s footprint is immutable and internal references to filepaths or executables are almost always fully qualified . on - premises vs . software as a service \u201c server operating systems \u201d is still a fairly broad category and we can narrow things down further depending on where we deploy the server : on - premises ( \u201c on - prem \u201d for short ) \u201c on - premises \u201d software runs within the end", " user \u2019 s environment . for example , if the software product is a server then an on - premises deployment runs within the customer \u2019 s data center , either as a virtual machine or aphysical rack server . software as a service ( \u201c saas \u201d for short ) the opposite of on - premises is \u201c off - premises \u201d ( more commonly known as \u201c software as a service \u201d ) . this means that you centrally host your software , either in your data center or in the cloud , and customers interact with the software via a web interface or api . nixos is better suited for saas than on - prem deployments , because nixos", " fares worse in restricted network environments where network access is limited or unavailable . you can still deploy nixos for on - prem deployments and i will cover that in a later chapter , but you will have a much better time using nixos for saas deployments . virtualization you might be interested in how nixos fares with respect to virtualization or containers , so i \u2019 ll break things down into these four potential use cases : nixos without virtualization you can run nixos on a bare metal machine ( e . g . a desktop computer orphysical rack server ) without any virtual machines or containers . this implies that services run directly on", " the bare metal machine . nixos as a host operating system you can also run nixos on a bare metal machine ( i . e the \u201c host \u201d ) but then on that machine you run containers or virtual machines ( i . e . the \u201c guests \u201d ) . typically , you do this if you want services to run inside the guest machines . nixos as a guest operating system virtual machines or os containers can run a fully - fledged operating system inside of them , which can itself be a nixos operating system . i consider this similar in spirit to the \u201c nixos without virtualization \u201d case above because in both cases the services are", " managed by nixos . application containers containers technically do not need to run an entire operating system and can instead run a single process ( e . g . one service ) . you can do this using nixpkgs , which provides support forbuilding application containers . so which use cases are nixos / nixpkgs well - suited for ? if i had to rank these deployment models then my preference ( in descending order ) would be : nixos as a guest operating system specifically , this means that you would run nixos as a virtual machine on a cloud provider ( e . g . aws ) and all of your services run within", " that nixos guest machine with no intervening containers . i prefer this because this is the leanest deployment model and the lowest maintenance to administer . nixos without virtualization this typically entails running nixos on aphysical rack server and you still use nixos to manage all of your services without containers . this can potentially be the most cost - effective deployment model if you \u2019 re willing to manage your own hardware ( including raid and backup / restore ) or you operate your own data center . nixos as a host operating system - static containers nixos also works well when you want to statically specify a set of containers to run . not only", " can nixos run docker containers or oci containers , but nixos also provides special support for \u201c nixos containers \u201d ( which are systemd - nspawn containers under the hood ) or application containers built by nixpkgs . i rank this lower than \u201c nixos without virtualization \u201d because nixos obviates some ( but not all ) of the reasons for using containers . in other words , once you switch to using nixos you might find that you can do just fine without containers or at least use them much more sparingly . nixos as a host operating system - dynamic containers you can also use nix", "os to run containers dynamically , but nixos is not special in this regard . at best , nixos might simplify administering a container orchestration service ( e . g . kubernetes ) . application containers sans nixos this is technically a use case for nixpkgs and not nixos , but i mention it for completeness . application containers built by nixpkgs work best if you are trying to introduce the nix ecosystem ( but not nixos ) within a legacy environment . however , you lose out on the benefits of using nixos because , well , you \u2019 re no longer using nixos . the killer", " app for nixos based on the above guidelines , we can outline the ideal use case for nixos : nixos shines as a server operating system for saas deployments services should preferably be statically defined via the nixos configuration nixos can containerize these services , but it \u2019 s simpler to skip the containers if your deployment model matches that outline then nixos is not only a safe choice , but likely the best choice ! you will be in great company if you use nixos in this way . you can still use nixos in other capacities , but the further you depart from the above \u201c killer app \u201d the more you", " will need to roll up your sleeves . profile of a nixos adopter nixos is a devops tool , meaning that nixos blurs the boundary between software development and operations . the reason why nixos fits the devops space so well is because nixos unifies all aspects of managing a system through the uniform nixos options interface . in other words , you can use nixos options to configure operational details ( e . g . raid , encryption , boot loaders ) and also software development details ( e . g . dependency versions , patches , and even small amounts of inline code ) . this means that a dev", "ops engineer or devops team is best situated to introduce nixos within an engineering organization . devops is more of a set ofcultural practices than a team , but some organizations explicitly create a devops team or hire engineers for their devops expertise in order to support tools ( like nixos ) that enable thosecultural practices . what does nixos replace ? if nixos is a server operating system , does that mean that nixos competes with other server operating systems like ubuntu server , debian or fedora ? not exactly . nixos competes more with the docker ecosystem , meaning that a lot of the value that nixos", " adds overlaps with docker : nixos supports declarative system specification \u2026 analogous to docker compose . nixos provides better isolation \u2026 analogous to containers . nixos uses the nix package manager to declaratively assemble software \u2026 analogous to dockerfiles . you can use nixos in conjunction with docker containers since nixos supports declaratively launching containers , but you probably want to avoid buying further into the broader docker ecosystem if you use nixos . you don \u2019 t want to be in a situation where your engineering organization fragments and does everything in two different ways : the nixos way and the docker way", " . for those familiar with the gentoo linux distribution , nixos is like gentoo , but for docker1 . similar to gentoo , nixos is an operating system that provides unparalleled control over the machinewhile targeting use cases and workflows similar to the docker ecosystem . 3 the big picture before diving in further you might want to get some idea of what a \u201c real \u201d nixos software enterprise looks like . specifically : what are the guiding principles for a nixos - centric software architecture ? how does a nixos - centric architecture differ from other architectures ? what would a \u201c nix", "os team \u201d need to be prepared to support and maintain ? here i \u2019 ll do my best to answer those questions so that you can get a better idea of what you would be signing up for . the zen of nixos i like to use the term \u201c master cue \u201d to denote an overarching sign that indicates that you \u2019 re doing things right . this master cue might not tell you how to do things right , but it can still provide a high - level indicator of whether you are on the right track . the master cue for nixos is very similar to the master cue for the nix ecosystem , which is this : every common", " build / test / deploy - related activity should be possible with at most one command using nix \u2019 s command line interface . i say \u201c at most one command \u201d because some activities ( like continuous deployment ) should ideally require no human intervention at all . however , activities that do require human intervention should in principle be compressible into a single nix command . i can explain this by providing an example of a development workflow that disregards this master cue : suppose that you want to test your local project \u2019 s changes within the context of some larger system at work ( i . e . an integration test ) . your organization \u2019 s process for testing", " your code might hypothetically look like this : create and publish a branch in version control recording your changes manually trigger some workflow to build a software artifact containing your changes update some configuration file to reference the newly - built software artifact run the appropriate integration test now what if i told you that the entire integration testing process from start to finish could be : run nix flake check in other words : there would be no need to create or publish your branch you could test uncommitted changes straight from your local project checkout . there would be no multi - step publication process all of the intermediate build products and internal references would be handled transparently", " by the nix build tool . the test itself would be managed by the nix build tool in other words , nix would treat your integration test no differently than any other build product . tests and their outputs are build products . there would be no need to select the appropriate tests to rerun the nix build tool would automatically infer which tests depended on your project and rerun those . other test runs and their results would be cached if their dependency tree did not include your changes . some of these potential improvements are not specific to the nix ecosystem . after all , you could attempt to create a script that automates the more painstaking multi -", " step process . however , you would likely need to reinvent large portions of the nix ecosystem for this automation to be sufficiently robust and efficient . for example : do you maintain a file server for storing intermediate build products ? you \u2019 re likely implementing your own version of the nix store and caching system do you generate unique labels for build products to isolate parallel workflows ? in the best case scenario , you label build products by a hash of their dependencies and you \u2019 ve reinvented the nix store \u2019 s hashing scheme . in the worst case scenario you \u2019 re doing something less accurate ( e . g . using timestamps", " in the labels instead of hashes ) . do you have a custom script that updates references to these build products ? this would be reinventing nix \u2019 s language support for automatically updating dependency references . do you need to isolate your integration tests or run them in parallel ? you would likely reimplement the nixos test framework . you can save yourself a lot of headaches by taking time to learn and use the nix ecosystem as idiomatically as possible instead of learning these lessons the hard way . gitops nixos exemplifies the infrastruct ure as code ( iac ) paradigm , meaning that every", " aspect of your organization ( including hardware / systems / software ) is stored in code or configuration files that are the source of truth for how everything is built . in particular , you don \u2019 t make undocumented changes to your infrastruct ure that cause it to diverge from what is recorded within those files . this book will espouse a specific flavor of infrastruct ure of code known as gitops where : the code and configuration files are ( primarily ) declarative in other words , they tend to specify the desired state of the system rather than a sequence of steps to get there . these files are", " stored in version control proponents of this approach most commonly use git as their version control software , which is why it \u2019 s called \u201c gitops \u201d . pull requests are the change management system in other words , the pull request review process determines whether you have sufficient privileges , enough vetting , or the correct approvals from relevant maintainers . devops nixos also exemplifies the devops principle of breaking down boundaries between software developers ( \u201c dev \u201d ) and operations ( \u201c ops \u201d ) . specifically , nixos goes further in this regard than most other tools by unifying both software configuration and system configuration underneath the nixos option", " system . these nixos options fall into roughly three categories : systems configuration these are options that are mostly interesting to operations engineers , such as : log rotation policies kernel boot parameters disk encryption settings hybrid systems / software options these are options that live in the grey area between dev and ops , such as : service restart policies networking credentials / secrets management software configuration these are options that are mostly interesting to software engineers , such as : patches command - line arguments environment variables in extreme cases , you can even embed non - nix code inside of nix and do \u201c pure software development \u201d . in other words , you can author inline codewritten within another language inside", " of a nixos configuration file . i \u2019 ll include one example of this later on in the \u201c our first web server \u201d chapter . architecture a nixos - centric architecture tends to have the following key pieces of infrastruct ure : version control if you \u2019 re going to use gitops then you had better use git ! more specifically , you \u2019 ll likely use a git hosting provider like github or gitlab which supports pull requests and continuous integration . most companies these days use version control , so this is not a surprising requirement . product servers these are the nixos servers that actually host your product -", " related services . a central build server ( the \u201c hub \u201d ) this server initiates builds for continuous integration , which are delegated to builders . builders for each platform these builders perform the actual nix builds . however , remember that integration tests will be nix builds , too , so these builders also run integration tests . these builders will come in two flavors : builders for the hub ( the \u201c spokes \u201d ) builders for developers to use a cache in simpler setups the \u201c hub \u201d can double as a cache , but as you grow you will likely want to upload build products to a dedicated cache . one or more \u201c utility \u201d servers a", " \u201c utility \u201d server is a nixos server that you can use to host it infrastruct ure and miscellaneous utility services to support developers ( e . g . web pages , chat bots ) . this server will play a role analogous to a container engine or virtual machine hypervisor in other software architectures , except that we won \u2019 t necessarily be using virtual machines or containers : many things will run natively on the host as nixos services . of course , you can also use this machine to run a container engine or hypervisor in addition to running things natively on the host . a \u201c utility \u201d server should", " not be part of your continuous integration or continuous deployment pipeline . you should think of such a server as a \u201c junk drawer \u201d for stuff that does not belong in ci / cd . moreover , you will either need a cloud platform ( e . g . aws ) or data center for hosting these machines . in this book we \u2019 ll primarily focus on hosting infrastruct ure on aws . these are not the only components you will need to build out your product , but these should be the only components necessary to support devops workflows , including continuous integration and continuous deployment . notably absent from the above list are : container", " - specific infrastruct ure a nixos - centric architecture already mitigates some of the need for containerizing services , but the architecture doesn \u2019 t change much even if you do use containers , because containers can be built by nixpkgs , distributed via the cache , and declaratively deployed to any nixos machine . programming - language - specific infrastruct ure if nixpkgs supports a given language then we require no additional infrastruct ure to supportbuilding and deploying that language . however , we might still host language - specific amenities on our utility server , such as", " generated documentation . continuous - deployment services nixos provides out - of - the - box services that we can use for continuous deployment , which we will cover in a later chapter . cloud / virtual development environments nix \u2019 s support for development shells ( e . g . nix develop ) will be our weapon of choice here . scope so far i \u2019 ve explained nixos in high - level terms , but you might prefer a more down - to - earth picture of the day - to - day requirements and responsibilities for a professional nixos user . to that end , here is a checklist that will summarize what you would need to understand in", " order to effectively introduce and support nixos within an organization : infrastruct ure setup continuous integration builders caching development nixos module system project organization nixos best practices quality controls testing running virtual machines automated testing deployment provisioning a new system upgrading a system dealing with restricted networks system administration infrastruct ure as code disk management filesystem networking users and authentication limits and quotas security system hardening patching dependencies diagnostics and debugging nix failures test failures production failures useful references fielding inquiries system settings licenses vulnerabilities non - nixos integrations images containers this book will cover all of the above topics and", " more , although they will not necessarily be grouped or organized in that exact order . 4 setting up your development environment i \u2019 d like you to be able to follow along with the examples in this book , so this chapter provides a quick setup guide to bootstrap from nothing to deploying a blank nixos system that you can use for experimentation . installing nix in order to follow along with this book you will need the following requirements : nix version 2 . 18 . 1 or newer flake support enabled specifically , you \u2019 ll need to enable the following experimental features in your nix configuration file : extra - experimental - features = nix - command flakes", " repl - flake you \u2019 ve likely already installed nix if you \u2019 re reading this book , but i \u2019 ll still cover how to do this because i have a few tips to share that can help you author a more reliable installation script for your colleagues . needless to say , if you or any of your colleagues are using nixos as your development operating system then you don \u2019 t need to install nix and you can skip to the running a nixos virtual machine section below . default installation if you go to the download page for nix it will tell you to run something similar to this : $ sh < ( curl - - location", " https : / / nixos . org / nix / install ) throughout this book i \u2019 ll use consistently long option names instead of short names ( e . g . - - location instead of - l ) , for two reasons : long option names are more self - documenting long option names are easier to remember for example , tar - - extract - - file is clearer and a better mnemonic than tar xf . you may freely use shorter option names if you prefer , though , but i still highly recommend using long option names at least for non - interactive script s . depending on your platform the download instruct ions might also tell", " you to pass the - - daemon or - - no - daemon option to the installation script to specify a single - user or multi - user installation . for simplicity , the instruct ions in this chapter will omit the - - daemon / - - no - daemon flag , but keep in mind the following platform - specific advice : on macos the installer defaults to a multi - user nix installation macos doesn \u2019 t even support a single - user nix installation , so this is a good default . on windows the installer defaults to a single - user nix installation this default is also the recommended option . on linux", " the installer defaults to a single - user nix installation this is the one case where the default behavior is questionable . multi - user nix installations are typically better if your linux distribution supports systemd , so you should explicitly specify - - daemon if you use systemd . pinning the version first , we will want to pin the version of nix that you install if you \u2019 re creating setup instruct ions for others to follow . for example , this book will be based on nix version 2 . 18 . 1 , and you can pin the nix version like this : $ version = ' 2 . 18 . 1 ' $ url = \" https", " : / / releases . nixos . org / nix / nix - $ { version } / install \" $ sh < ( curl - - location \" $ { url } \" ) \u2026 and you can find the full set of available releases by visiting the release file server . feel free to use a nix version newer than 2 . 18 . 1 if you want . the above example installation script only pins the version 2 . 18 . 1 because that \u2019 s what happened to be the latest stable version at the time of this writing . that \u2019 s also the nix version that the examples from this book have been tested against . the only really", " important thing is that everyone within your organization uses the same version of nix , if you want to minimize your support burden . however , there are a few more options that the script accepts that we \u2019 re going to make good use of , and we can list those options by supplying - - help to the script : $ version = ' 2 . 18 . 1 ' $ url = \" https : / / releases . nixos . org / nix / nix - $ { version } / install \" $ sh < ( curl - - location \" $ { url } \" ) - - help nix installer [ - - daemon |", " - - no - daemon ] [ - - daemon - user - count int ] [ - - no - channel - add ] [ - - no - modify - profile \\ ] [ - - nix - extra - conf - file file ] choose installation method . - - daemon : installs and configures a background daemon that manages the store , providing multi - user support and better isolation for local builds . both for security and reproducibility , this method is recommended if supported on your platform . see https : / / nixos . org / manual / nix / stable / installation / installing - binary . html # multi -", " user - i \\ nstallation - - no - daemon : simple , single - user installation that does not require root and is trivial to uninstall . ( default ) - - no - channel - add : don ' t add any channels . nixpkgs - unstable is installed by default . - - no - modify - profile : don ' t modify the user profile to automatically load nix . - - daemon - user - count : number of build users to create . defaults to 32 . - - nix - extra - conf - file : path to nix . conf to prepend when installing / etc / nix", " / nix . conf - - tarball - url - prefix url : base url to download the nix tarball from . you might wonder if you can use the - - tarball - url - prefix option for distributing a custom build of nix , but that \u2019 s not what this option is for . you can only use this option to download nix from a different location ( e . g . an internal mirror ) , because the new download still has to match the same integrity check as the old download . don \u2019 t worry , though ; there still is a way to distribute a custom build of nix , and we \u2019", " ll cover that in a later chapter . configuring the installation the extra options of interest to us are : - - nix - extra - conf - file this lets you extend the installed nix . conf if you want to make sure that all users within your organization share the same settings . - - no - channel - add you can ( and should ) enable this option within a professional organization to disable the preinstallation of any channels . these two options are crucial because we are going to use them to systematically replace nix channels with flakes . nix channels are a trap and i treat them as a legacy nix feature poorly", " suited for professional development , despite how ingrained they are in the nix ecosystem . the issue with channels is that they essentially introduce impurity into your builds by depending on the nix _ path and there aren \u2019 t great solutions for enforcing that every nix user or every machine within your organization has the exact same nix _ path . moreover , nix now supports flakes , which you can think of as a more modern alternative to channels . familiarity with flakes is not a precondition to reading this book , though : i \u2019 ll teach you what you need to know . so what we \u2019 re going to do is : disable channels by default", " developers can still opt in to channels by installing them , but disabling channels by default will discourage people from contributing nix code that depends on the nix _ path . append the following setting to nix . conf to enable the use of flakes : extra - experimental - features = nix - command flakes repl - flake so the final installation script we \u2019 ll end up with is : $ version = ' 2 . 18 . 1 ' $ url = \" https : / / releases . nixos . org / nix / nix - $ { version } / install \" $ configuration = \" extra - experimental - features =", " nix - command flakes repl - flake extra - trusted - users = $ { user } \" $ sh < ( curl - - location \" $ { url } \" ) \\ - - no - channel - add \\ - - nix - extra - conf - file < ( < < < \" $ { configuration } \" ) the prior script only works if your shell is bash or zsh and all shell commands throughout this book assume the use of one of those two shells . for example , the above command uses support for process substitution ( which is not available in a posix shell environment ) because otherwise we \u2019 d", " have to create a temporary file to store the configuration and clean up the temporary file afterwards ( which is tricky to do 100 % reliably ) . process substitution is also more reliable than a temporary file because it happens entirely in memory and the intermediate result can \u2019 t be accidentally deleted . running a nixos virtual machine now that you \u2019 ve installed nix i \u2019 ll show you how to launch a nixos virtual machine ( vm ) so that you can easily test the examples throughout this book . macos - specific instruct ions if you are using macos , then follow the instruct ions in the nixpkgs manual to set", " up a local linux builder . we \u2019 ll need this builder to create other nixos machines , since they require linux build products . in particular , you will need to leave that builder running in the backgroundwhile following the remaining examples in this chapter . in other words , in one terminal window you will need to run : $ nix run ' nixpkgs # darwin . linux - builder ' \u2026 and you will need that to be running whenever you need to build a nixos system . however , you can shut down the builder when you \u2019 re not using it by giving the builder the shutdown now command . the nix run nixpk", "gs # darwin . linux - builder command is not enough to set up linux builds on macos . read and follow the full set of instruct ions from the nixpkgs manual linked above . if you are using linux ( including nixos or the windows subsystem for linux ) you can skip to the next step . platform - independent instruct ions run the following command to generate your first project : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # setup ' \u2026 that will generate the following flake . nix file : {", " inputs = { flake - utils . url = \" github : numtide / flake - utils / v1 . 0 . 0 \" ; nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; } ; outputs = { flake - utils , nixpkgs , . . . } : flake - utils . lib . eachdefaultsystem ( system : let pkgs = nixpkgs . legacypackages . \" $ { system } \" ; base = { lib ,", " modulespath , . . . } : { imports = [ \" $ { modulespath } / virtualisation / qemu - vm . nix \" ] ; # https : / / github . com / utmapp / utm / issues / 2353 networking . nameservers = lib . mkif pkgs . stdenv . isdarwin [ \" 8 . 8 . 8 . 8 \" ] ; virtualisation = { graphics = false ; host = { inherit pkgs ; } ; } ; } ; machine = nixpkgs . lib . nixossystem { system =", " builtins . replacestrings [ \" darwin \" ] [ \" linux \" ] system ; modules = [ base . / module . nix ] ; } ; program = pkgs . writeshellscript \" run - vm . sh \" ' ' export nix _ disk _ image = $ ( mktemp - u - t nixos . qcow2 ) trap \" rm - f $ nix _ disk _ image \" exit $ { machine . config . system . build . vm } / bin / run - nixos - vm ' ' ; in { packages = { inherit machine ; } ; apps .", " default = { type = \" app \" ; program = \" $ { program } \" ; } ; } ) ; } \u2026 and also the following module . nix file : # module . nix { services . getty . autologinuser = \" root \" ; } then run this command within the same directory to run our test virtual machine : $ nix run warning : creating lock file ' \u2026 / flake . lock ' trace : warning : system . stateversion is not set , defaulting to 23 . 11 . \u2026 \u2026 run ' nixos - help ' for the nixos manual . nixos login : root ( automatic log", "in ) [ root @ nixos : ~ ] # you can then shut down the virtual machine by entering shutdown now . if you \u2019 re unable to shut down the machine gracefully for any reason you can shut down the machine non - gracefully by typing ctrl - a + c to open the qemu prompt and then entering quit to exit . also , don \u2019 t worry about the system . stateversion warning for now . we \u2019 ll fix that later . if you were able to successfully launch and shut down the virtual machine then you \u2019 re ready to follow along with the remaining examples throughout this book . if you see an example in", " this book that begins with this line : # module . nix \u2026 \u2026 then that means that i want you to save that example code to the module . nix file and then restart the virtual machine by running nix run . for example , let \u2019 s test that right now ; save the following file to module . nix : # module . nix { services . getty . autologinuser = \" root \" ; services . postgresql . enable = true ; } \u2026 then start the virtual machine and log into the machine . as the root user , run : [ root @ nixos : ~ ] # sudo - - user", " postgres psql psql ( 14 . 5 ) type \" help \" for help . postgres = # \u2026 and now you should have command - line access to a postgres database . the run script in the flake . nix file ensures that the virtual machine does not persist state in between runs so that you can safely experiment inside of the virtual machine without breaking upcoming examples . 5 our first web server now that we can build and run a local nixos virtual machine we can create our first toy web server . we will use this server throughout this book as the running example which will start off simple and slowly", " grow in maturity as we increase the realism of the example and build out the supporting infrastruct ure . hello ,world ! we \u2019 ll begin from the template project from \u201c setting up your development environment \u201d . you can either begin from the previous chapter by running the following command ( if you haven \u2019 t done so already ) : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # setup ' \u2026 or if you want to skip straight to the final result at the end of this chapter you can run : $ nix flake init", " - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # server ' let \u2019 s modify module . nix to specify a machine that serves a simple static \u201c hello ,world ! \u201d page on http : / / localhost : # module . nix { pkgs , . . . } : { services = { getty . autologinuser = \" root \" ; nginx = { enable = true ; virtualhosts . localhost . locations . \" / \" = { index = \" index . html \" ; root = pkgs . writetext", "dir \" index . html \" ' ' < html > < body > hello ,world ! < / body > < / html > ' ' ; } ; } ; } ; networking . firewall . allowedtcpports = [ 80 ] ; virtualisation . forwardports = [ { from = \" host \" ; guest . port = 80 ; host . port = 8080 ; } ] ; system . stateversion = \" 23 . 11 \" ; } you can read the above code as saying : enable nginx which currently only listens on localhost in other words , nginx will only respond to requests addressed", " to localhost ( e . g . 127 . 0 . 0 . 1 ) . serve a static web page \u2026 which is a bare - bones \u201c hello ,world ! \u201d html page . open port 80 on the virtual machine \u2019 s firewall \u2026 since that is the port that nginx will listen on by default until we create a certificate and enable tls . forward port 8080 on the \u201c host \u201d to port 80 on the \u201c guest \u201d the \u201c guest \u201d is the virtual machine and the \u201c host \u201d is your development machine . allow the root user to log in with an empty password set the system \u2019 s \u201c state", " version \u201d to 23 . 11 you always want to specify a system state version that matches the starting version of nixpkgs for that machine and never change it afterwards . in other words , even if you upgrade nixpkgs later on you would keep the state version the same . nixpkgs uses the state version to migrate your nixos system because in order to migrate your system each migration needs to know where your system started from . two common mistakes nixos users sometimes make are : updating the state version when they upgrade nixpkgs this will cause the machine to never be migrated because nixpkgs will think that", " the machine was never deployed to an older version . specifying a uniform state version across a fleet of nixos machines for example , you might have one nixos machine in your data center that was first deployed using nixpkgs 23 . 05 and another machine in your data center that was first deployed using nixpkgs 23 . 11 . if you try to change their state versions to match then one or the other might not upgrade correctly . if you deploy that using nix run you can open the web page in your browser by visiting http : / / localhost : 8080 which should display the following contents : hello ,world !", " in general i don \u2019 t recommend testing things by hand like this . remember the \u201c master cue \u201d : every common build / test / deploy - related activity should be possible with at most a single command using nix \u2019 s command line interface . in a later chapter we \u2019 ll cover how to automate this sort of testing using nixos \u2019 s support for integration tests . these tests will also take care of starting up and tearing down the virtual machine for you so that you don \u2019 t have to do that by hand either . devops the previous example illustrates how nixos promotes devops on a small scale . if the inline web page represents", " the software development half of the project ( the \u201c dev \u201d ) and the nginx configuration represents the operational half of the project ( the \u201c ops \u201d ) then we can in principle store both the \u201c dev \u201d and the \u201c ops \u201d halves of our project within the same file . as an extreme example , we can even template the web page with system configuration options ! # module . nix { config , lib , pkgs , . . . } : { services = { getty . autologinuser = \" root \" ; nginx = { enable = true ; virtualhosts . localhost .", " locations . \" / \" = { index = \" index . html \" ; root = pkgs . writetextdir \" index . html \" ' ' < html > < body > this server ' s firewall has the following open ports : < ul > $ { let renderport = port : \" < li > $ { tostring port } < / li > \\ n \" ; in lib . concatmapstrings renderport config . networking . firewall . allowedtcpports } < / ul > < / body > < / html > ' ' ; } ; } ; }", " ; networking . firewall . allowedtcpports = [ 80 ] ; virtualisation . forwardports = [ { from = \" host \" ; guest . port = 80 ; host . port = 8080 ; } ] ; system . stateversion = \" 23 . 11 \" ; } if you restart the machine and refresh http : / / localhost : 8080 the page should now display : this server \u2019 s firewall has the following open ports : 80 there are less roundabout ways to query our system \u2019 s configuration that don \u2019 t involve serving a web page . for example , using the same flake . nix file", " we can more directly query the open ports using : $ nix eval ' . # machine . config . networking . firewall . allowedtcpports ' [ 80 ] todo list now we \u2019 re going to create the first prototype of a toy web application : a todo list implemented entirely in client - side javascript ( later on we \u2019 ll add a backend service ) . create a subdirectory named www within your current directory : $ mkdir www \u2026 and then save a file named index . html with the following contents underneath that subdirectory : < html > < body", " > < button id = ' add ' > + < / button > < / body > < script > let add = document . getelementbyid ( ' add ' ) ; function newtask ( ) { let subtract = document . createelement ( ' button ' ) ; subtract . textcontent = \" - \" ; let input = document . createelement ( ' input ' ) ; input . setattribute ( ' type ' , ' text ' ) ; let div = document . createelement ( ' div ' ) ; div . replacechildren ( sub", "tract , input ) ; function remove ( ) { div . replacechildren ( ) ; div . remove ( ) ; } subtract . addeventlistener ( ' click ' , remove ) ; add . before ( div ) ; } add . addeventlistener ( ' click ' , newtask ) ; < / script > < / html > in other words , the above file should be located at www / index . html relative to the directory containing your module . nix file . now save the following nixos configuration to module . nix : # module . nix { services = { getty", " . autologinuser = \" root \" ; nginx = { enable = true ; virtualhosts . localhost . locations . \" / \" = { index = \" index . html \" ; root = . / www ; } ; } ; } ; networking . firewall . allowedtcpports = [ 80 ] ; virtualisation . forwardports = [ { from = \" host \" ; guest . port = 80 ; host . port = 8080 ; } ] ; system . stateversion = \" 23 . 11 \" ; } if you restart the virtual machine and refresh the web page you \u2019 ll see a", " single + button : each time you click the + button it will add a todo list item consisting of : a text entry field to record the todo item a - button to delete the todo item passing through the filesystem the previous nixos configuration requires rebuilding and restarting the virtual machine every time we change the web page . if you try to change the . / www / index . html filewhile the virtual machine is running you won \u2019 t see any changes take effect . however , we can pass through our local filesystem to the virtual machine so that we can easily test changes . to do so , add", " the following option to the configuration : virtualisation . shareddirectories . www = { source = \" $ www \" ; target = \" / var / www \" ; } ; \u2026 and change module . nix to reference / var / www , like this : virtualhosts . localhost . locations . \" / \" = { index = \" index . html \" ; root = \" / var / www \" ; } ; finally , restart the machine , except with a slightly modified version of our original nix run command : $ www = \" $ pwd / www \" nix run now , we only need to refresh the page", " to view any changes we make to index . html and we no longer need to restart the virtual machine . exercise : add a \u201c todo list \u201d heading ( i . e . < h1 > todo list < / h1 > ) to the web page and refresh the page to confirm that your changes took effect . 6 nixos option definitions by this point in the book you may have copied and pasted some nixos code , but perhaps you don \u2019 t fully understand what is going on , especially if you \u2019 re not an experienced nixos user . this chapter will slow down and help you solidify your understanding of the", " nixos module system so that you can improve your ability to read , author , and debug modules . throughout this book i \u2019 ll consistently use the following terminology to avoid ambiguity : \u201c option declarations \u201d will refer to the options attribute of a nixos module \u201c option definitions \u201d will refer to the config attribute of a nixos module along the same lines : \u201c declare an option \u201d will mean to set an attribute nested underneath options \u201c define an option \u201d will mean to set an attribute nested underneath config in this chapter and the next chapter we \u2019 ll focus mostly on option definitions and later on we \u2019 ll", " cover option declarations in more detail . anatomy of a nixos module in the most general case , a nixos module has the following \u201c shape \u201d : # module arguments which our system can use to refer to its own configuration { config , lib , pkgs , . . . } : { # other modules to import imports = [ \u2026 ] ; # options that this module declares options = { \u2026 } ; # options that this module defines config = { \u2026 } ; } in other words , in the fully general case a nixos module is a function whose output is an attribute set with three attributes named imports", " , options , and config . nix supports data struct ures known \u201c attribute sets \u201d which are analogous to \u201c maps \u201d or \u201c records \u201d in other programming languages . to be precise , nix uses the following terminology : an \u201c attribute set \u201d is a data struct ure associating keys with values for example , this is a nested attribute set : { bio = { name = \" alice \" ; age = 24 ; } ; job = \" software engineer \" ; } an \u201c attribute \u201d is nix \u2019 s name for a key or a field of an \u201c attribute set \u201d for example , bio , job , name", " , and age are all attributes in the above example . an \u201c attribute path \u201d is a chain of one or more attributes separated by dots for example , bio . name is an attribute path . i \u2019 m explaining all of this because i \u2019 ll use the terms \u201c attribute set \u201d , \u201c attribute \u201d , and \u201c attribute path \u201d consistently throughout the text to match nix \u2019 s official terminology ( even though no other language uses those terms ) . syntactic sugar all elements of a nixos module are optional and nixos supports \u201c syntactic sugar \u201d to simplify several common cases . for example , you can omit the module arguments", " if you don \u2019 t use them : { imports = [ \u2026 ] ; options = { \u2026 } ; config = { \u2026 } ; } you can also omit any of the imports , options , or config attributes , too , like in this module , which only imports other modules : { imports = [ . /physical . nix . / logical . nix ] ; } \u2026 or this config - only module : { config = { services = { apache - kafka . enable = true ; zookeeper . enable = true ; } ; } ; } additionally , the nixos module system provides special", " support for modules which only define options by letting you elide the config attribute and promote the options defined within to the \u201c top level \u201d . as an example , we can simplify the previous nixos module to this : { services = { apache - kafka . enable = true ; zookeeper . enable = true ; } ; } you might wonder if there should be some sort of coding style which specifies whether people should include or omit these elements of a nixos module . for example , perhaps you might require that all elements are present , for consistency , even if they are empty or unused . my coding style for nix", "os modules is : you should permit omitting the module arguments you should permit omitting the imports , options , or config attributes you should avoid eliding the config attribute in other words , if you do define any options , always nest them underneath the config attribute . nixos modules are not language features the nix programming language does not provide any built - in support for nixos modules . this sometimes confuses people new to either the nix programming language or the nixos module system . the nixos module system is a domain - specific language implemented within the nix programming language . specifically , the nixos module system", " is ( mostly ) implemented within the lib / modules . nix file included in nixpkgs . if you ever receive a stack trace related to the nixos module system you will often see functions from modules . nix show up in the stack trace , because they are ordinary functions and not language features . in fact , a nixos module in isolation is essentially \u201c inert \u201d from the nix language \u2019 s point of view . for example , if you save the following nixos module to a file named example . nix : { config = { services . openssh . enable = true ; } ; } \u2026 and you evaluate that", " , the result will be the same , just without the syntactic sugar : $ nix eval - - file . / example . nix { config = { services = { openssh = { enable = true ; } ; } ; } ; } the nix programming language provides \u201c syntactic sugar \u201d for compressing nested attributes by chaining them using a dot ( . ) . in other words , this nix expression : { config = { services . openssh . enable = true ; } ; } \u2026 is the same thing as this nix expression : { config = { services = { openssh =", " { enable = true ; } ; } ; } ; } \u2026 and they are both also the same thing as this nix expression : { config . services . openssh . enable = true ; } note that this syntactic sugar is a feature of the nix programming language , not the nixos module system . in other words , this feature works even for nix expressions that are not destined for use as nixos modules . along the same lines , the following nixos module : { config , . . . } : { config = { services . apache - kafka . enable = config . services", " . zookeeper . enable ; } ; } \u2026 is just a function . if we save that to example . nix and then evaluate that the interpreter will simply say that the file evaluates to a \u201c lambda \u201d ( an anonymous function ) : $ nix eval - - file . / example . nix < lambda > \u2026 although we can get a more useful result within the nix repl by calling our function on a sample argument : $ nix repl \u2026 nix - repl > example = import . / example . nix nix - repl > input = { config = { services . zookeeper . enable = true ; } ;", " } nix - repl > output = example input nix - repl > : p output { config = { services = { apache - kafka = { enable = true ; } ; } ; } ; } nix - repl > output . config . services . apache - kafka . enable true this illustrates that our nixos module really is just a function whose input is an attribute set and whose output is also an attribute set . there is nothing special about this function other than it happens to be the same shape as what the nixos module system accepts . nixos so if nixos modules are just pure", " functions or pure attribute sets , what turns those functions or attribute sets into a useful operating system ? in other words , what puts the \u201c nixos \u201d in the \u201c nixos module system \u201d ? the answer is that this actually happens in two steps : all nixos modules your system depends on are combined into a single , composite attribute set in other words all of the imports , options declarations , and config settings are fully resolved , resulting in one giant attribute set . the code for combining these modules lives in lib / modules . nix in nixpkgs . the final composite attribute set contains a special attribute that builds the system", " specifically , there will be a config . system . build . toplevel attribute path which contains a derivation you can use to build a runnable nixos system . the top - level code for assembling an operating system lives in nixos / modules / system / activation / top - level . nix in nixpkgs . this will probably make more sense if we use the nixos module system ourselves to create a fake placeholder value that will stand in for a real operating system . first , we \u2019 ll create our own top - level . nix module that will include a fake config . system . build .", " toplevel attribute path that is a string instead of a derivation forbuilding an operating system : # top - level . nix { config , lib , . . . } : { imports = [ . / other . nix ] ; options = { system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a string \" ; type = lib . types . str ; } ; } ; config = { system . build . toplevel = \" fake nixos - version $ { config . system . nixos . release", " } \" ; } ; } that imports a separate other . nix module which we also need to create : # other . nix { lib , . . . } : { options = { system . nixos . release = lib . mkoption { descript ion = \" the nixos version \" ; type = lib . types . str ; } ; } ; config = { system . nixos . release = \" 23 . 11 \" ; } ; } we can then materialize the final composite attribute set like this : $ nix repl github : nixos / nixpkgs / 23", " . 11 \u2026 nix - repl > result = lib . evalmodules { modules = [ . / top - level . nix ] ; } nix - repl > : p result . config { system = { build = { toplevel = \" fake nixos - version 23 . 11 \" ; } ; nixos = { release = \" 23 . 11 \" ; } ; } ; } nix - repl > result . config . system . build . toplevel \" fake nixos - version 23 . 11 \" in other words , lib . evalmodules is the magic function that", " combines all of our nixos modules into a composite attribute set . nixos essentially does the same thing as in the above example , except on a much larger scale . also , in a real nixos system the final config . system . build . toplevel attribute path stores a buildable derivation instead of a string . recursion the nixos module system lets modules refer to the final composite configuration using the config function argument that is passed into every nixos module . for example , this is how our top - level . nix module was able to refer to the system . nixos . release option that was set in", " the other . nix module : # this represents the final composite configuration # | { config , lib , . . . } : { \u2026 config = { system . build . toplevel = \" fake nixos - version $ { config . system . nixos . release } \" ; # | # \u2026 which we can use within our configuration } ; } you \u2019 re not limited to referencing configuration values set in other nixos modules ; you can even reference configuration values set within the same module . in other words , nixos modules support recursion where modules can refer to themselves . as a concrete example", " of recursion , we can safely merge the other . nix module into the top - level . nix module : { config , lib , . . . } : { options = { system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a string \" ; type = lib . types . str ; } ; system . nixos . release = lib . mkoption { descript ion = \" the nixos version \" ; type = lib . types . str ; } ; } ; config = { system", " . build . toplevel = \" fake nixos - version $ { config . system . nixos . release } \" ; system . nixos . release = \" 23 . 11 \" ; } ; } \u2026 and this would still work , even though this module now refers to its own configuration values . the nix interpreter won \u2019 t go into an infinite loop because the recursion is still well - founded . we can better understand why this recursion is well - founded by simulating how lib . evalmodules works by hand . conceptually what lib . evalmodules does is : combine all", " of the input modules compute the fixed point of this composite module we \u2019 ll walk through this by performing the same steps as lib . evalmodules . first , to simplify things we \u2019 ll consolidate the prior example into a single flake that we can evaluate as we go : # save this to ` . / evalmodules / flake . nix ` { inputs . nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; outputs = { nixpkgs , . . . } : let other = { lib , . . . }", " : { # to save space , this example compresses the code a bit options . system . nixos . release = lib . mkoption { descript ion = \" the nixos version \" ; type = lib . types . str ; } ; config . system . nixos . release = \" 23 . 11 \" ; } ; toplevel = { config , lib , . . . } : { imports = [ other ] ; options . system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a", " string \" ; type = lib . types . str ; } ; config . system . build . toplevel = \" fake nixos - version $ { config . system . nixos . release } \" ; } ; in nixpkgs . lib . evalmodules { modules = [ toplevel ] ; } ; } you can evaluate the above flake like this : $ nix eval ' . / evalmodules # config ' { system = { build = { toplevel = \" fake nixos - version 23 . 11 \" ; } ; nixos =", " { release = \" 23 . 11 \" ; } ; } ; } $ nix eval ' . / evalmodules # config . system . build . toplevel ' \" fake nixos - version 23 . 11 \" various nix commands ( like nix eval ) take a flake reference as an argument which has the form : $ { uri } # $ { attribute _ path } in the previous example , the uri was . / evalmodules ( a file path in this case ) and the attribute _ path was config . system . build . toplevel . however , if you use", " zsh as your shell with extended _ glob glob support ( i . e . setopt extended _ glob ) then zsh interprets # as a special character . this is why all of the examples from this book quote the flake reference as a precaution , but if you \u2019 re not using zsh or its extended globbing support then you can remove the quotes , like this : $ nix eval . / evalmodules # config . system . build . toplevel if you run into an error like : error : getting status of ' / nix / store /", " \u2026 - source / evalmodules ' : no such file or directory \u2026 this can happen because you created the . / evalmodules directory inside of a git repository . when you use flakes inside of a repository you need to explicitly add them and all files they depend on to the repository using : $ git add . / evalmodules / flake . nix technically , the bare minimum you need to do is actually : $ git add - - intent - to - add . / evalmodules / flake . nix \u2026 which comes in handy if you don \u2019 t plan to ever actually commit the", " file . the first thing that lib . evalmodules does is to merge the other module into the toplevel module , which we will simulate by hand by performing the same merge ourselves : { inputs . nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; outputs = { nixpkgs , . . . } : let toplevel = { config , lib , . . . } : { options . system . nixos . release = lib . mkoption { descript ion = \" the nixos version \" ;", " type = lib . types . str ; } ; options . system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a string \" ; type = lib . types . str ; } ; config . system . nixos . release = \" 23 . 11 \" ; config . system . build . toplevel = \" fake nixos - version $ { config . system . nixos . release } \" ; } ; in nixpkgs . lib . evalmodules { modules = [ toplev", "el ] ; } ; } after that we compute the fixed point of our module by passing the module \u2019 s output as its own input , the same way that evalmodules would : { inputs . nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; outputs = { nixpkgs , . . . } : let toplevel = { config , lib , . . . } : { options . system . nixos . release = lib . mkoption { descript ion = \" the nixos version \" ; type =", " lib . types . str ; } ; options . system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a string \" ; type = lib . types . str ; } ; config . system . nixos . release = \" 23 . 11 \" ; config . system . build . toplevel = \" fake nixos - version $ { config . system . nixos . release } \" ; } ; result = toplevel { inherit ( result ) config options ; inherit ( nixpkgs", " ) lib ; } ; in result ; } this walkthrough grossly oversimplifies what evalmodules does . for starters , we \u2019 ve completely ignored how evalmodules uses the options declarations to : check that configuration values match their declared types replace missing configuration values with their default values however , this oversimplification is fine for now . the last step is that when nix eval accesses the config . system . build . toplevel field of the result , the nix interpreter conceptually performs the following substitutions : result . config . system . build . toplevel", " # substitute ` result ` with its right - hand side = ( toplevel { inherit ( result ) config options ; inherit ( nixpkgs ) lib ; } ) . config . system . build . toplevel # ` inherit ` is syntactic sugar for this equivalent nix expression = ( toplevel { config = result . config ; options = result . options ; lib = nixpkgs . lib ; } ) . config . system . build . toplevel # evaluate the ` toplevel ` function = ( { options . system . nix", "os . release = lib . mkoption { descript ion = \" the nixos version \" ; type = lib . types . str ; } ; options . system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a string \" ; type = lib . types . str ; } ; config . system . nixos . release = \" 23 . 11 \" ; config . system . build . toplevel = \" fake nixos - version $ { result . config . system . nixos . release", " } \" ; } ) . config . system . build . toplevel # access the ` config . system . build . toplevel ` attribute path = \" fake nixos - version $ { result . config . system . nixos . release } \" # substitute ` result ` with its right - hand side ( again ) = \" fake nixos - version $ { ( toplevel { inherit ( result ) config options ; inherit ( nixpkgs ) lib ; } ) . config . system . nixos . release } \" # evaluate the ` toplevel `", " function ( again ) = \" fake nixos - version $ { ( { options . system . nixos . release = lib . mkoption { descript ion = \" the nixos version \" ; type = lib . types . str ; } ; options . system . build . toplevel = lib . mkoption { descript ion = \" a fake nixos , modeled as a string \" ; type = lib . types . str ; } ; config . system . nixos . release = \" 23 . 11 \" ; config . system . build . toplevel =", " \" fake nixos - version $ { result . config . system . nixos . release } \" ; } ) . config . system . nixos . release } \" # access the ` config . system . nixos . release ` attribute path = \" fake nixos - version $ { \" 23 . 11 \" } \" # evaluate the string interpolation = \" fake nixos - version 23 . 11 \" so even though our nixos module is defined recursively in terms of itself , that recursion is still well - founded and produces an actual result . 7 advanced option definitions nixos option", " definitions are actually much more sophisticated than the previous chapter let on and in this chapter we \u2019 ll cover some common tricks and pitfalls . make sure that you followed the instruct ions from the \u201c setting up your development environment \u201d chapter if you would like to test the examples in this chapter . imports the nixos module system lets you import other modules by their path , which merges their option declarations and option definitions with the current module . but , did you know that the elements of an imports list don \u2019 t have to be paths ? you can put inline nixos configurations in the imports list , like these : { imports = [ {", " services . openssh . enable = true ; } { services . getty . autologinuser = \" root \" ; } ] ; } \u2026 and they will behave as if you had imported files with the same contents as those inline configurations . in fact , anything that is a valid nixos module can go in the import list , including nixos modules that are functions : { imports = [ { services . openssh . enable = true ; } ( { lib , . . . } : { services . getty . autologinuser = lib . mkdefault \" root \" ; } ) ] ; } i", " will make use of this trick in a few examples below , so that we can simulate modules importing other modules within a single file . lib utilities nixpkgs provides several utility functions for nixos modules that are stored underneath the \u201c lib \u201d hierarchy , and you can find the source code for those functions in lib / modules . nix . if you want to become a nixos module system expert , take the time to read and understand all of the code in lib / modules . nix . remember that the nixos module system is implemented as a domain - specific language in nix and lib / modules . nix contains the", " implementation of that domain - specific language , so if you understand everything in that file then you understand essentially all that there is to know about how the nixos module system works under the hood . that said , this chapter will still try to explain things enough so that you don \u2019 t have to read through that code . you do not need to use or understand all of the functions in lib / modules . nix , but you do need to familiarize yourself with the following four primitive functions : lib . mkmerge lib . mkoverride lib . mkif lib . mkorder by \u201c primitive \u201d , i mean", " that these functions cannot be implemented in terms of other functions . they all hook into special behavior built into lib . evalmodules . mkmerge the lib . mkmerge function merges a list of \u201c configuration sets \u201d into a single \u201c configuration set \u201d ( where \u201c configuration set \u201d means a potentially nested attribute set of configuration option settings ) . for example , the following nixos module : { lib , . . . } : { config = lib . mkmerge [ { services . openssh . enable = true ; } { services . getty . autologinuser = \" root", " \" ; } ] ; } \u2026 is equivalent to this nixos module : { config = { services . openssh . enable = true ; services . getty . autologinuser = \" root \" ; } ; } you might wonder whether you should merge modules using lib . mkmerge or merge them using the imports list . after all , we could have alsowritten the previous mkmerge example as : { imports = [ { services . openssh . enable = true ; } { services . getty . autologinuser = \" root \" ; } ] ; } \u2026 and that would have produced the same", " result . so which is better ? the short answer is : lib . mkmerge is usually what you want . the long answer is that the main trade - off between imports and lib . mkmerge is : the imports section can merge nixos modules that are functions lib . mkmerge can only merge configuration sets and not functions . the list of imports can \u2019 t depend on any configuration values in practice , this means that you can easily trigger an infinite recursion if you try to do anything fancy using imports and you can typically fix the infinite recursion by switching to lib . mkmerge . the", " latter point is why you should typically prefer using lib . mkmerge . merging options you can merge configuration sets that define same option multiple times , like this : { lib , . . . } : { config = lib . mkmerge [ { networking . firewall . allowedtcpports = [ 80 ] ; } { networking . firewall . allowedtcpports = [ 443 ] ; } ] ; } \u2026 and the outcome of merging two identical attribute paths depends on the option \u2019 s \u201c type \u201d . for example , the networking . firewall . allowedtcpports option \u2019", " s type is : $ nix eval ' . # machine . options . networking . firewall . allowedtcpports . type . descript ion ' \" list of 16 bit unsigned integer ; between 0 and 65535 ( both inclusive ) \" if you specify a list - valued option twice , the lists are combined , so the above example reduces to this : { lib , . . . } : { config = lib . mkmerge [ { networking . firewall . allowedtcpports = [ 80 443 ] ; } ] ; } \u2026 and we can even prove that by querying", " the final value of the option from the command line : $ nix eval ' . # machine . config . networking . firewall . allowedtcpports ' [ 80 443 ] however , you might find the nix repl more convenient if you prefer to interactively browse the available options . run this command : $ nix repl ' . # machine ' \u2026 added 7 variables . \u2026 which will load your nixos system into the repl and now you can use tab - completion to explore what is available : nix - repl > config . < tab > config . appstream config", " . nix config . assertions config . nixops \u2026 nix - repl > config . networking . < tab > config . networking . bonds config . networking . bridges \u2026 nix - repl > config . networking . firewall . < tab > config . networking . firewall . allowping config . networking . firewall . allowedtcpportranges \u2026 nix - repl > config . networking . firewall . allowedtcpports [ 80 443 ] exercise : try to save the following nixos module to module . nix , which", " specifies the same option twice without using lib . mkmerge : { lib , . . . } : { config = { networking . firewall . allowedtcpports = [ 80 ] ; networking . firewall . allowedtcpports = [ 443 ] ; } ; } this will fail to deploy . do you understand why ? specifically , is the failure a limitation of the nixos module system or the nix programming language ? you can also nest lib . mkmerge underneath an attribute . for example , this : { config = lib . mkmerge [ { networking . fire", "wall . allowedtcpports = [ 80 ] ; } { networking . firewall . allowedtcpports = [ 443 ] ; } ] ; } \u2026 is the same as this : { config . networking = lib . mkmerge [ { firewall . allowedtcpports = [ 80 ] ; } { firewall . allowedtcpports = [ 443 ] ; } ] ; } \u2026 is the same as this : { config . networking . firewall = lib . mkmerge [ { allowedtcpports = [ 80 ] ; } { allowedtc", "pports = [ 443 ] ; } ] ; } \u2026 is the same as this : { config . networking . firewall . allowedtcpports = lib . mkmerge [ [ 80 ] [ 443 ] ] ; } \u2026 is the same as this : { config . networking . firewall . allowedtcpports = [ 80 443 ] ; } conflict s duplicate options cannot necessarily always be merged . for example , if you merge two configuration sets that disagree on whether to enable a service : { lib , . . . } : { config = { services", " . openssh . enable = lib . mkmerge [ true false ] ; } ; } \u2026 then that will fail at evaluation time with this error : error : the option ` services . openssh . enable ' has conflict ing definition values : - in ` / nix / store / \u2026 - source / module . nix ' : true - in ` / nix / store / \u2026 - source / module . nix ' : false ( use ' - - show - trace ' to show detailed location information ) this is because services . openssh . enable is declared to have a boolean type , and you can only merge multiple boolean", " values if all occurrences agree . you can verify this yourself by changing both occurrences to true , which will fix the error . as a general rule of thumb : most scalar option types will fail to merge distinct values e . g . boolean values , strings , integers . most complex option types will successfully merge in the obvious way e . g . lists will be concatenated and attribute sets will be combined . the most common exception to this rule of thumb is the \u201c lines \u201d type ( lib . types . lines ) , which is a string option type that you can define multiple times . services . zookeeper . extraconf is", " an example of one such option that has this type : { lib , . . . } : { config = { services . zookeeper = { enable = true ; extraconf = lib . mkmerge [ \" initlimit = 5 \" \" synclimit = 2 \" ] ; } ; } ; } \u2026 and merging multiple occurrences of that option concatenates them as lines by inserting an intervening newline character : $ nix eval ' . # machine . config . services . zookeeper . extraconf ' \" initlimit = 5 \\ nsynclimit", " = 2 \" mkoverride the lib . mkoverride function specifies the \u201c priority \u201d of an option definition , which comes in handy if you want to override a configuration value that another nixos module already defined . higher priority overrides this most commonly comes up when we need to override an option that was already defined by one of our dependencies ( typically a nixos module provided by nixpkgs ) . one example would be overriding the restart frequency of nginx : { config = { services . nginx . enable = true ; systemd . services . nginx . servicecon", "fig . restartsec = \" 5s \" ; } ; } the above naive attempt will fail at evaluation time with : error : the option ` systemd . services . nginx . serviceconfig . restartsec ' has conflict ing definition values : - in ` / nix / store / \u2026 - source / nixos / modules / services / web - servers / nginx / default . nix ' : \" 10s \" - in ` / nix / store / \u2026 - source / module . nix ' : \" 5s \" ( use ' - - show - trace ' to show detailed location information )", " the problem is that when we enable nginx that automatically defines a whole bunch of other nixos options , including systemd . services . nginx . serviceconfig . restartsec . this option is a scalar string option that disallows multiple distinct values because the nixos module system by default has no way to known which one to pick to resolve the conflict . however , we can use mkoverride to annotate our value with a higher priority so that it overrides the other conflict ing definition : { lib , . . . } : { config = { services .", " nginx . enable = true ; systemd . services . nginx . serviceconfig . restartsec = lib . mkoverride 50 \" 5s \" ; } ; } \u2026 and now that works , since we specified a new priority of 50 that takes priority over the default priority of 100 . there is also a pre - existing utility named lib . mkforce which sets the priority to 50 , so we could have also used that instead : { lib , . . . } : { config = { services . nginx . enable = true ; systemd . services . nginx", " . serviceconfig . restartsec = lib . mkforce \" 5s \" ; } ; } you do not want to do this : { lib , . . . } : { config = { services . nginx . enable = true ; systemd . services . nginx . serviceconfig = lib . mkforce { restartsec = \" 5s \" } ; } ; } that is not equivalent , because it overrides not only the restartsec attribute , but also all other attributes underneath the serviceconfig attribute ( like restart , user , and group ,", " all of which are now gone ) . you always want to narrow your use of lib . mkforce as much as possible to protect against this common mistake . the default priority is 100 and lower numeric values actually represent higher priority . in other words , an option definition with a priority of 50 takes precedence over an option definition with a priority of 100 . yes , the nixos module system confusingly uses lower numbers to indicate higher priorities , but in practice you will rarely see explicit numeric priorities . instead , people tend to use derived utilities like lib . mkforce or lib . mkdefault which select the appropriate numeric", " priority for you . in extreme cases you might still need to specify an explicit numeric priority . the most common example is when one of your dependencies already define an option using lib . mkforce and you need to override that . in that scenario you could use lib . mkoverride 49 , which would take precedence over lib . mkforce { lib , . . . } : { config = { services . nginx . enable = true ; systemd . services . nginx . serviceconfig . restartsec = lib . mkmerge [ ( lib . mkforce", " \" 5s \" ) ( lib . mkoverride 49 \" 3s \" ) ] ; } ; } \u2026 which will produce a final value of : $ nix eval ' . # machine . config . systemd . services . nginx . serviceconfig . restartsec ' \" 3s \" lower priority overrides the default values for options also have a priority , which is priority 1500 and there \u2019 s a lib . mkoptiondefault that sets a configuration value to that same priority . that means that a nixos module like this : { lib , . . . }", " : { options . foo = lib . mkoption { default = 1 ; } ; } \u2026 is the exact same thing as a nixos module like this : { lib , . . . } : { options . foo = lib . mkoption { } ; config . foo = lib . mkoptiondefault 1 ; } however , you will more commonly use lib . mkdefault which defines a configuration option with priority 1000 . typically you \u2019 ll use lib . mkdefault if you want to override the default value of an option ,while still allowing a downstream", " user to override the option yet again at the normal priority ( 100 ) . mkif mkif is far - and - away the most widely used nixos module primitive , because you can use mkif to selectively enable certain options based on the value of another option . an extremely common idiom from nixpkgs is to use mkif in conjunction with an enable option , like this : # module . nix let # pretend that this came from another file cowsay = { config , lib , pkgs , . . . } : { options . services . cowsay = { enable = lib . mk", "enableoption \" cowsay \" ; greeting = lib . mkoption { descript ion = \" the phrase the cow will greet you with \" ; type = lib . types . str ; default = \" hello ,world ! \" ; } ; } ; config = lib . mkif config . services . cowsay . enable { systemd . services . cowsay = { wantedby = [ \" multi - user . target \" ] ; script = \" $ { pkgs . cowsay } / bin / cowsay $ { config . services . cowsay . greeting", " } \" ; } ; } ; } in { imports = [ cowsay ] ; config = { services . cowsay . enable = true ; services . getty . autologinuser = \" root \" ; } ; } if you launch the above nixos configuration you should be able to verify that the cowsay service is running like this : [ root @ nixos : ~ ] # systemctl status cowsay cowsay . service loaded : loaded ( / etc / systemd / system / cowsay . service ; enabled ; preset : enabl > active : inactive ( dead ) since sat 2023", " - 11 - 05 20 : 11 : 05 utc ; 43s ago duration : 106ms process : 683 execstart = / nix / store / v02wsh00gi1vcblpcl8p103qhlpkaifb - unit - scr > main pid : 683 ( code = exited , status = 0 / success ) ip : 0b in , 0b out cpu : 19ms nov 05 20 : 11 : 04 nixos systemd [ 1 ] : started cowsay . service . nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] :", " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] : < hello ,world ! > nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] : - - - - - - - - - - - - - - - nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] : \\ ^ _ _ ^ nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] : \\ ( oo ) \\ _ _ _ _ _ _ _ nov 05", " 20 : 11 : 05 nixos cowsay - start [ 689 ] : ( _ _ ) \\ ) \\ / \\ nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] : | | - - - - w | nov 05 20 : 11 : 05 nixos cowsay - start [ 689 ] : | | | | nov 05 20 : 11 : 05 nixos systemd [ 1 ] : cowsay . service : deactivated successfully . you might wonder why we need a mkif primitive at all . couldn \u2019 t we use an if expression like this instead ? { config ,", " lib , pkgs , . . . } : { \u2026 config = if config . services . cowsay . enable then { systemd . services . cowsay = { wantedby = [ \" multi - user . target \" ] ; script = \" $ { pkgs . cowsay } / bin / cowsay $ { config . services . cowsay . greeting } \" ; } ; } else { } ; } the most important reason why this doesn \u2019 t work is because it triggers an infinite loop : error : infinite recursion encountered at / nix / store / vgicc", "88fhmlh7mwik7gqzzm2jyfva9l9 - source / lib / modules . nix : 259 : 21 : 258 | ( regularmodules + + [ internalmodule ] ) 259 | ( { inherit lib options config specialargs ; } / / specialargs ) ; | ^ 260 | in mergemodules prefix ( reverselist collected ) ; ( use ' - - show - trace ' to show detailed location information ) the reason why is because the recursion is not well - founded : # this attribute directly depends on", " itself # | | config = if config . services . cowsay . enable then { \u2026 and the reason why lib . mkif doesn \u2019 t share the same problem is because evalmodules pushes mkif conditions to the \u201c leaves \u201d of the configuration tree , as if we had insteadwritten this : { config , lib , pkgs , . . . } : { \u2026 config = { systemd . services . cowsay = { wantedby = lib . mkif config . services . cowsay . enable [ \" multi - user . target \" ] ; s", "cript = lib . mkif config . services . cowsay . enable \" $ { pkgs . cowsay } / bin / cowsay $ { config . services . cowsay . greeting } \" ; } ; } ; } \u2026 which makes the recursion well - founded . the second reason we use lib . mkif is because it correctly handles the fallback case . to see why that matters , consider this example that tries to create a service . kafka . enable short - hand synonym for services . apache - kafka . enable : let kafkasynonym = {", " config , lib , . . . } : { options . services . kafka . enable = lib . mkenableoption \" apache \" ; config . services . apache - kafka . enable = config . services . kafka . enable ; } ; in { imports = [ kafkasynonym ] ; config . services . apache - kafka . enable = true ; } the above example leads to a conflict because the kafkasynonym module defines services . kafka . enable to false ( at priority 100 ) , and the", " downstream module defines services . apache - kafka . enable to true ( also at priority 100 ) . had we instead used mkif like this : let kafkasynonym = { config , lib , . . . } : { options . services . kafka . enable = lib . mkenableoption \" apache \" ; config . services . apache - kafka . enable = lib . mkif config . services . kafka . enable true ; } ; in { imports = [ kafkasynonym ] ; config . services . apache", " - kafka . enable = true ; } \u2026 then that would do the right thing because in the default case services . apache - kafka . enable would remain undefined , which would be the same thing as being defined as false at priority 1500 . that avoids defining the same option twice at the same priority . mkorder the nixos module system strives to make the behavior of our system depend as little as possible on the order in which we import or mkmerge nixos modules . in other words , if we import two modules that we depend on : { imports = [ . / a . nix . / b .", " nix ] ; } \u2026 then ideally the behavior shouldn \u2019 t change if we import those same two modules in a different order : { imports = [ . / b . nix . / a . nix ] ; } \u2026 and in most cases that is true . 99 % of the time you can safely sort your import list and either your nixos system will be exactly the same as before ( producing the exact same nix store build product ) or essentially the same as before , meaning that the difference is irrelevant . however , for those 1 % of cases where order matters we need the lib . mkorder function . here \u2019 s one example of", " where ordering matters : let modulea = { pkgs , . . . } : { environment . defaultpackages = [ pkgs . gcc ] ; } ; moduleb = { pkgs , . . . } : { environment . defaultpackages = [ pkgs . clang ] ; } ; in { imports = [ modulea moduleb ] ; } both the gcc package and clang package add a cc executable to the path , so the order matters here because the first cc on the path wins . in the above example , clang \u2019 s cc is the first one on the", " path , because we imported moduleb second : [ root @ nixos : ~ ] # readlink $ ( type - p cc ) / nix / store / 6szy6myf8vqrmp8mcg8ps7s782kygy5g - clang - wrapper - 11 . 1 . 0 / bin / cc \u2026 but if we flip the order imports : imports = [ moduleb modulea ] ; \u2026 then gcc \u2019 s cc comes first on the path : [ root @ nixos : ~ ] # readlink $ ( type - p cc ) / nix / store / 9", "wqn04biky07333wkl35bfjv9zv009pl - gcc - wrapper - 9 . 5 . 0 / bin / cc this sort of order - sensitivity frequently arises for \u201c list - like \u201d option types , including actual lists or string types like lines that concatenate multiple definitions . fortunately , we can fix situations like these with the lib . mkorder function , which specifies a numeric ordering that nixos will respect when merging multiple definitions of the same option . every option \u2019 s numeric order is 1000 by default , so if we set the numeric", " order of clang to 1500 : let modulea = { pkgs , . . . } : { environment . defaultpackages = [ pkgs . gcc ] ; } ; moduleb = { lib , pkgs , . . . } : { environment . defaultpackages = lib . mkorder 1500 [ pkgs . clang ] ; } ; in { imports = [ modulea moduleb ] ; } \u2026 then gcc will always come first on the path , no matter which order we import the modules . you can also use lib . mkbefore and lib .", " mkafter , which provide convenient synonyms for numeric order 500 and 1500 , respectively : mkbefore = mkorder 500 ; mkafter = mkorder 1500 ; \u2026 so we could have alsowritten : let modulea = { pkgs , . . . } : { environment . defaultpackages = [ pkgs . gcc ] ; } ; moduleb = { lib , pkgs , . . . } : { environment . defaultpackages = lib . mkafter [ pkgs . clang ] ; } ; in { imports = [ modulea moduleb ]", " ; } 8 deploying to aws using terraform up until now we \u2019 ve been playing things safe and test - driving everything locally on our own machine . we could even prolong this for quite awhile because nixos has advanced support forbuilding and testing clusters of nixos machines locally using virtual machines . however , at some point we need to dive in and deploy a server if we \u2019 re going to use nixos for real . in this chapter we \u2019 ll deploy our todo app to our first \u201c production \u201d server in aws meaning that you will need to create an aws account to follow along . aws prices and", " offers will vary so this book can \u2019 t provide any strong guarantees about what this would cost you . however , at the time of this writing the examples in this chapter would fit well within the current aws free tier , which is 750 hours of a t3 . micro instance . even if there were no free tier , the cost of a t3 . micro instance is currently \u22481\u00a2 / hour or \u2248 $ 7 . 50 / month if you never shut it off ( and you can shut it off when you \u2019 re not using it ) . so at most this chapter should only cost you a few cents from start to finish . throughout", " this book i \u2019 ll take care to minimize your expenditures by showing how you to develop and test locally as much as possible . in the spirit of infrastruct ure as code , we \u2019 ll be using terraform to declaratively provision aws resources , but before doing so we need to generate aws access keys for programmatic access . configuring your access keys to generate your access keys , follow the instruct ions in accessing aws using aws credentials . in particular , take care to not generate access keys for your account \u2019 s root user . instead , use the identity and access management ( ia", "m ) service to create a separate user with \u201c admin \u201d privileges and generate access keys for that user . the difference between a root user and an admin user is that an admin user \u2019 s privileges can later be limited or revoked , but the root user \u2019 s privileges can never be limited nor revoked . the above aws documentation also recommends generating temporary access credentials instead of long - term credentials . however , setting this up properly and ergonomically requires setting up the iam identity center which is only permitted for aws accounts that have set up an aws organization . that is way outside of the scope of this book so", " instead you should just generate long - term credentials for a non - root admin account . if you generated the access credentials correctly you should have : an access key id ( i . e . aws _ access _ key _ id ) a secret access key ( i . e . aws _ secret _ access _ key ) if you haven \u2019 t already , configure your development environment to use these tokens by running : $ nix run ' github : nixos / nixpkgs / 23 . 11 # awscli ' - - configure - - profile nixos - in - production aws", " access key id [ none ] : \u2026 aws secret access key [ none ] : \u2026 defaultregion name [ none ] : \u2026 default output format [ none ] : if you \u2019 re not sure whatregion to use , pick the one closest to you based on the list of aws service endpoints . a minimal terraform specification now run the following command to bootstrap our first terraform project : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # terraform ' \u2026 which will generate the following files : module . nix + www /", " index . html the nixos configuration for our todo list web application , except adapted to run on aws instead of inside of a qemu vm . flake . nix a nix flake that wraps our nixos configuration so that we can refer to the configuration using a flake uri . main . tf the terraform specification for deploying our nixos configuration to aws . backend / main . tf this terraform configuration provisions an s3 bucket for use with terraform \u2019 s s3 backend . we won \u2019 t use this until the very end of this chapter , though , so we \u2019", " ll ignore it for now . deploying our configuration to deploy the terraform configuration , run the following commands : $ nix shell ' github : nixos / nixpkgs / 23 . 05 # terraform ' $ terraform init $ terraform apply \u2026 and when prompted to enter theregion , use the same awsregion you specified earlier when running aws configure : var .region enter a value : \u2026 after that , terraform will display the execution plan and ask you to confirm the plan : module . ami . data . external . ami : reading . . . module . ami . data . external", " . ami : read complete after 1s [ id = - ] terraform used the selected providers to generate the following execution plan . resource actions are indicated with the following symbols : + create < = read ( data resources ) terraform will perform the following actions : \u2026 do you want to perform these actions ? terraform will perform the actions describe d above . only ' yes ' will be accepted to approve . enter a value : yes \u2026 and if you confirm then terraform will deploy that execution plan : \u2026 apply complete ! resources : 5 added , 0 changed , 0 destroyed . outputs : public _ dns = \" ec2 - \u2026", " . compute . amazonaws . com \" the final output will include the url for your server . if you open that url in your browser you will see the exact same todo server as before , except now running on aws instead of inside of a qemu virtual machine . if this is your first time deploying something to aws then congratulations ! cleaning up once you verify that everything works you can destroy all deployed resources by running : $ terraform apply - destroy terraform will prompt you for the same information ( i . e . the sameregion ) and also prompt for confirmation just like before : var .region enter", " a value : \u2026 \u2026 do you want to perform these actions ? terraform will perform the actions describe d above . only ' yes ' will be accepted to approve . enter a value : yes \u2026 and once you confirm then terraform will destroy everything : \u2026 apply complete ! resources : 0 added , 0 changed , 7 destroyed . now you can read the rest of this chapter in peace knowing that you are no longer being billed for this example . terraform walkthrough the key file in our terraform project is main . tf containing the terraform logic for how to deploy our todo list application . you can think of a", " terraform module as being sort of like a function with side effects , meaning : the function has inputs terraform calls these input variables . the function has outputs terraform calls these output values . the function does things other than producing output values for example , the function might provision a resource . you can invoke another terraform module like a function call in other words , one terraform module can call another terraform module by supplying the child module with appropriate function arguments . our starting main . tf file provides examples of all of the above concepts . input variables for example , the beginning of the module declares one input variable : variable \"region", " \" { type = string nullable = false } \u2026 which is analogous to a nix function like this one that takes the following attribute set as an input : {region } : \u2026 when you run terraform apply you will be automatically prompted to supply all input variables : $ terraform apply var .region enter a value : \u2026 \u2026 but you can also provide the same values on the command line , too , if you don \u2019 t want to supply them interactively : $ terraform apply - varregion = \u2026 \u2026 and if you really want to make the whole command non - interactive you can also add the - auto - approve flag : $", " terraform apply - varregion = \u2026 - auto - approve \u2026 so that you don \u2019 t have to manually confirm the deployment by entering \u201c yes \u201d . output variables the end of the terraform module declares one output value : output \" public _ dns \" { value = aws _ instance . todo . public _ dns } \u2026 which would be like our function returning an attribute set with one attribute : {region } : let \u2026 in { output = aws _ instance . todo . public _ dns ; } \u2026 and when the deploy completes terraform will render all output values : outputs : public _ dns =", " \" ec2 - \u2026 . compute . amazonaws . com \" resources in between the input variables and the output values the terraform module declares several resources . for now , we \u2019 ll highlight the resource that provisions the ec2 instance : resource \" aws _ security _ group \" \" todo \" { \u2026 } resource \" tls _ private _ key \" \" nixos - in - production \" { \u2026 } resource \" local _ sensitive _ file \" \" ssh _ private _ key \" { } resource \" local _ file \" \" ssh _ public _ key \" { } resource \" aws _ key _ pair \" \"", " nixos - in - production \" { \u2026 } resource \" aws _ instance \" \" todo \" { ami = module . ami . ami instance _ type = \" t3 . micro \" security _ groups = [ aws _ security _ group . todo . name ] key _ name = aws _ key _ pair . nixos - in - production . key _ name root _ block _ device { volume _ size = 7 } } resource \" null _ resource \" \" wait \" { \u2026 } \u2026 and you can think of resources sort of like let bindings that provision infrastruct ure as a side effect :", " {region } : let \u2026 ; aws _ security _ group . todo = aws _ security _ group { \u2026 } ; tls _ private _ key . nixos - in - production = tls _ private _ key { \u2026 } ; local _ sensitive _ file . ssh _ private _ key = local _ sensitive _ file { \u2026 } ; local _ file . ssh _ public _ key = local _ file { \u2026 } ; aws _ key _ pair . nixos - in - production = aws _ key _ pair { \u2026 } ; aws _ instance . todo = aws _ instance {", " ami = module . ami . ami ; instance _ type = \" t3 . micro \" ; security _ groups = [ aws _ security _ group . todo . name ] ; key _ name = aws _ key _ pair . nixos - in - production . key _ name ; root _ block _ device . volume _ size = 7 ; } null _ resource . wait = null _ resource { \u2026 } ; in { output = aws _ instance . todo . public _ dns ; } our terraform deployment declares six resources , the first of which declares a security group ( basically like a firewall ) : resource", " \" aws _ security _ group \" \" todo \" { # the \" nixos \" terraform module requires ssh access to the machine to deploy # our desired nixos configuration . ingress { from _ port = 22 to _ port = 22 protocol = \" tcp \" cidr _ blocks = [ \" 0 . 0 . 0 . 0 / 0 \" ] } # we will bebuilding our nixos configuration on the target machine , so we # permit all outbound connections so that the build can download any missing # dependencies . egress { from _ port = 0 to _ port = 0 protocol = \" -", " 1 \" cidr _ blocks = [ \" 0 . 0 . 0 . 0 / 0 \" ] } # we need to open port 80 so that we can view our todo list web page . ingress { from _ port = 80 to _ port = 80 protocol = \" tcp \" cidr _ blocks = [ \" 0 . 0 . 0 . 0 / 0 \" ] } } the next four resources generate an ssh key pair that we \u2019 ll use to manage the machine : # generate an ssh key pair as strings stored in terraform state resource \" tls _ private _ key \" \" nixos - in -", " production \" { algorithm = \" ed25519 \" } # synchronize the ssh private key to a local file that the \" nixos \" module can # use resource \" local _ sensitive _ file \" \" ssh _ private _ key \" { filename = \" $ { path . module } / id _ ed25519 \" content = tls _ private _ key . nixos - in - production . private _ key _ openssh } resource \" local _ file \" \" ssh _ public _ key \" { filename = \" $ { path . module } / id _ ed25519 . pub", " \" content = tls _ private _ key . nixos - in - production . public _ key _ openssh } # mirror the ssh public key to ec2 so that we can later install the public key # as an authorized key for our server resource \" aws _ key _ pair \" \" nixos - in - production \" { public _ key = tls _ private _ key . nixos - in - production . public _ key _ openssh } the tls _ private _ key resource is currently not secure because the deployment state is stored locally unencrypted . we will fix this later on in this chapter", " by storing the deployment state using terraform \u2019 s s3 backend . after that we get to the actual server : resource \" aws _ instance \" \" todo \" { # this will be an ami for a stock nixos server which we ' ll get to below . ami = module . ami . ami # we could use a smaller instance size , but at the time of this writing the # t3 . micro instance type is available for 750 hours under the aws free tier . instance _ type = \" t3 . micro \" # install the security groups we defined earlier security _ groups = [ aws _ security _ group", " . todo . name ] # install our ssh public key as an authorized key key _ name = aws _ key _ pair . nixos - in - production . key _ name # request a bit more space because we will bebuilding on the machine root _ block _ device { volume _ size = 7 } # we will use this in a future chapter to bootstrap other secrets user _ data = < < - eof # ! / bin / sh ( umask 377 ; echo ' $ { tls _ private _ key . nixos - in - production . private _ key _ openssh } ' > /", " var / lib / id _ ed2551 \\ 9 ) eof } finally , we declare a resource whose sole purpose is to wait until the ec2 instance is reachable via ssh so that the \u201c nixos \u201d module knows how long to wait before deploying the nixos configuration : # this ensures that the instance is reachable via ` ssh ` before we deploy nixos resource \" null _ resource \" \" wait \" { provisioner \" remote - exec \" { connection { host = aws _ instance . todo . public _ dns private _ key = tls _ private _ key . nixos -", " in - production . private _ key _ openssh } inline = [ \" : \" ] # do nothing ; we ' re just testing ssh connectivity } } modules our terraform module also invokes two other terraform modules ( which i \u2019 ll refer to as \u201c child modules \u201d ) and we \u2019 ll highlight here the module that deploys the nixos configuration : module \" ami \" { \u2026 ; } module \" nixos \" { source = \" github . com / gabriella439 / terraform - nixos - ng / / nixos ? ref = d8563d06cc65bc69", "9ffbf1ab8d692b1343ec \\ d927 \" host = \" root @ $ { aws _ instance . todo . public _ ip } \" flake = \" . # default \" arguments = [ \" - - build - host \" , \" root @ $ { aws _ instance . todo . public _ ip } \" ] ssh _ options = \" - o stricthostkeychecking = accept - new \" depends _ on = [ null _ resource . wait ] } you can liken child modules to nix function calls for imported functions : {region } : let module", " . ami = \u2026 ; module . nixos = let source = fetchfromgithub { owner = \" gabriella439 \" ; repo = \" terraform - nixos - ng \" ; rev = \" d8563d06cc65bc699ffbf1ab8d692b1343ecd927 \" ; hash = \u2026 ; } ; in import source { host = \" root @ $ { aws _ instance . todo _ public _ ip } \" ; flake = \" . # default \" ; arguments = [ \" - - build - host \" \" root @", " $ { aws _ instance . todo . public _ ip } \" ] ; ssh _ options = \" - o stricthostkeychecking = accept - new \" ; depends _ on = [ null _ resource . wait ] ; } ; aws _ security _ group . todo = aws _ security _ group { \u2026 } ; tls _ private _ key . nixos - in - production = tls _ private _ key { \u2026 } ; local _ sensitive _ file . ssh _ private _ key = local _ sensitive _ file { \u2026 } ; local _ file . ssh _ public _ key =", " local _ file { \u2026 } ; aws _ key _ pair . nixos - in - production = aws _ key _ pair { \u2026 } ; aws _ instance . todo = aws _ instance { \u2026 } ; null _ resource . wait = null _ resource { \u2026 } ; in { output = aws _ instance . todo . public _ dns ; } the first child module selects the correct nixos ami to use : module \" ami \" { source = \" github . com / gabriella439 / terraform - nixos - ng / / ami ? ref = d8563d0", "6cc65bc699ffbf1ab8d692b1343ecd9 \\ 27 \" release = \" 23 . 05 \"region = var .region system = \" x86 _ 64 - linux \" } \u2026 and the second child module deploys our nixos configuration to our ec2 instance : module \" nixos \" { source = \" github . com / gabriella439 / terraform - nixos - ng / / nixos ? ref = d8563d06cc65bc699ffbf1ab8d692b1343ec \\ d9", "27 \" host = \" root @ $ { aws _ instance . todo . public _ ip } \" # get the nixos configuration from the nixosconfigurations . default attribute # of our flake . nix file flake = \" . # default \" # build our nixos configuration on the same machine that we ' re deploying to arguments = [ \" - - build - host \" , \" root @ $ { aws _ instance . todo . public _ ip } \" ] ssh _ options = \" - o stricthostkeychecking = accept - new - i $ { local _ sensitive _", " file . ssh _ private _ key . filenam \\ e } \" depends _ on = [ null _ resource . wait ] } in this example we build our nixos configuration on our web server so that this example can be deployed without any supporting infrastruct ure . however , you typically will want to build the nixos configuration on a dedicated builder rather thanbuilding on the target server for two reasons : you can deploy to a smaller / leaner server building a nixos system typically requires more disk space , ram , and network bandwidth than running / deploying the same system . centralizing that build work onto a larger special", " - purpose builder helps keep other machines lightweight . you can lock down permissions on the target server for example , if we didn \u2019 t have to build on our web server then we wouldn \u2019 t need to permit outbound connections on that server since it would no longer need to fetch build - time dependencies . a future chapter will cover how to provision a dedicated builder for this purpose . s3 backend the above terraform deployment doesn \u2019 t properly protect the key pair used to ssh into and manage the nixos machine . by default the private key of the key pair is stored in aworld - readable terraform . tfs", "tate file . however , even if we were to restrict that file \u2019 s permissions we wouldn \u2019 t be able to easily share our terraform deployment with colleagues . in particular , we wouldn \u2019 t want to add the terraform . tfstate file to version control in a shared repository since it contains sensitive secrets . the good news is that we can fix both of those problems by setting up an s3 backend for terraform which allows the secret to be securely stored in an s3 bucket that can be shared by multiple people managing the same terraform deployment . the template for this chapter \u2019 s terraform configuration already comes with a", " backend / subdirectory containing a terraform specification that provisions a suitable s3 bucket and dynamodb table for an s3 backend . all you have to do is run : $ cd . / backend $ terraform apply var .region enter a value : \u2026 \u2026 do you want to perform these actions ? terraform will perform the actions describe d above . only ' yes ' will be accepted to approve . enter a value : yes just make sure to use the sameregion as our original terraform deployment when prompted . when the deployment succeeds it will output the name of the randomly - generated s3 bucket , which", " will look something like this ( with a timestamp in place of the xs ) : \u2026 apply complete ! resources : 4 added , 0 changed , 0 destroyed . outputs : bucket = \" nixos - in - productionxxxxxxxxxxxxxxxxxxxxxxxxxx \" then switch back to the original terraform deployment in the parent directory : $ cd . . \u2026 and modify that deployment \u2019 s main . tf to reference the newly - created bucket like this : terraform { required _ version = \" > = 1 . 3 . 0 \" required _ providers { aws = { source = \" hashicorp", " / aws \" version = \" ~ > 4 . 56 \" } } # this is the new bit you want to add backend \" s3 \" { bucket = \" nixos - in - productionxxxxxxxxxxxxxxxxxxxxxxxxxx \" key = \" terraform \"region = \" \u2026 \" # use the sameregion here that you used before dynamodb _ table = \" terraform - state \" profile = \" nixos - in - production \" } } these last few manual steps to update the s3 backend are a bit gross but this is primarily to work around limitations in terraform . in", " particular , terraform doesn \u2019 t provide a way for our main deployment to automatically reference the s3 backend we created . terraform specifically prohibits backend stanzas from referencing variables so all of the backend options have to be hard - coded values . then you can upgrade your existing deployment to reference the s3 backend you just provisioned by re - running terraform init with the - migrate - state option : $ terraform init - migrate - state initializing modules . . . initializing the backend . . . do you want to copy existing state to the new backend ? pre - existing state was foundwhile", " migrating the previous \" local \" backend to the newly configured \" s3 \" backend . no existing state was found in the newly configured \" s3 \" backend . do you want to copy this state to the new \" s3 \" backend ? enter \" yes \" to copy and \" no \" to start with an empty state . enter a value : yes \u2026 and once that \u2019 s done you can verify that nothing broke by running terraform apply again , which should report that no new changes need to be deployed : $ terraform apply var .region enter a value : \u2026 \u2026 no changes . your infrastruct ur", "e matches the configuration . the difference is that now the terraform state is securely stored in an s3 bucket instead of on your filesystem so you \u2019 d now be able to store your terraform configuration in version control and let other developers manage the same deployment . there \u2019 s just one last thing you need to do , which is to remove the terraform . tfstate . backup file , which contains the old ( pre - s3 - backend ) terraform state , including the secrets : $ rm terraform . tfstate . backup you can also remove the terraform . tfstate file , too , since", " it \u2019 s empty and no longer used : $ rm terraform . tfstate future terraform examples in this book won \u2019 t include the s3 backend code to keep them shorter , but feel free to reuse the same s3 bucket created in this chapter to upgrade any of those examples with an s3 backend . however , if you do that then keep in mind that you need to use a different key for storing terraform \u2019 s state if you want to keep those examples separate . in other words , when adding the s3 backend to the terraform clause , specify a different key for each separate deployment : terra", "form { \u2026 backend \" s3 \" { \u2026 key = \" \u2026 \" # this is what needs to be unique per deployment \u2026 } } this key is used by terraform to record where to store the deployment \u2019 s state within the s3 bucket , so if you use the same key for two different deployments they will will interfere with one another . version control once you create the s3 backend you can safely store your terraform configuration in version control . specifically , these are the files that you want to store in version control : flake . nix , module . nix , www / these provide the configuration for the machine we", " \u2019 re deploying so we obviously need to keep these . flake . lock it \u2019 s also worth keeping this in version control even though it \u2019 s not strictly necessary . the lock file slightly improves the determinism of the deployment , although the flake included in the template is already fairly deterministic even without the lockfile because it references a specific tag from nixpkgs . main . tf , backend / main . tf we definitely want to keep the terraform deployments for our main deployment and the s3 backend . terraform . tfstate you don \u2019 t need to keep this in", " version control ( it \u2019 s an empty file just as important , you do not want to keep the id _ ed25519 file in version control ( since this contains the private key ) . in fact , the provided template includes a . gitignore file to prevent you from accidentally adding the private key to version control . terraform will recreate this private key file locally for each developer that manages the deployment . for example , if another developer were to apply the deployment for the first time , they would see this diff : terraform will perform the following actions : # local _ sensitive _ file . ssh _ private _ key", " will be created + resource \" local _ sensitive _ file \" \" ssh _ private _ key \" { + content = ( sensitive value ) + directory _ permission = \" 0700 \" + file _ permission = \" 0700 \" + filename = \" . / id _ ed25519 \" + id = ( known after apply ) } plan : 1 to add , 0 to change , 0 to destroy . \u2026 indicating that terraform will download the private key from the s3 backend and create a secure local copy in order to ssh into the machine . however , it \u2019 s completely fine to add the public key to version", " control if you want . 9 continuous integration and deployment this chapter will cover how to use both continuous integration ( a . k . a . \u201c ci \u201d ) and continuous deployment ( a . k . a . \u201c cd \u201d ) , beginning with a brief explanation of what those terms mean . both continuous integration and continuous deployment emphasize continuously incorporating code changes into your product . continuous integration emphasizes continuously incorporating code changes into the trunk development branch of your version control repository whereas continuous deployment emphasizes continuously incorporating code changes into production . continuous integration colloquially developers often understand \u201c continuous integration \u201d to mean automatically testing pull requests before they are merged into version control . however , continuous integration", " is about more than just automated tests and is really about ensuring that changes are regularly being integrated into the trunk development branch ( and automated tests help with that ) . for example , if you have long - lived development branches that \u2019 s not really adhering to the spirit of continuous integration , even if you do put them through automated tests . i \u2019 m mentioning this because this book will offer opinionated guidance that works better if you \u2019 re not supporting long - lived development branches . you can still modify this book \u2019 s guidance to your tastes , but in my experience sticking to only one long - lived development branch ( the trunk branch ) will sim", "plify your architecture , reduce communication overhead between developers , and improve your release frequency . in fact , this specific flavor of continuous integration has a name : trunk - based development . that said , this chapter will focus on how to set up automated tests since that \u2019 s the part of continuous integration that \u2019 s nixos - specific . the ci solution i endorse for most nix / nixos projects is garnix because with garnix you don \u2019 t have to manage secrets and you don \u2019 t have to set up your own build servers or cache . in other words , garnix is architecturally simple to install and manage .", " however , garnix only works with github ( it \u2019 s a github app ) so if you are using a different version control platform then you \u2019 ll have to use a different ci solution . the two major alternatives that people tend to use are : hydra like garnix , hydra is a nix - aware continuous integration service but unlike garnix , hydra is self - hosted1 . hydra \u2019 s biggest strength is deep visibility into builds in progress and ease of scaling out build capacity but hydra \u2019 s biggest weakness is that it is high maintenance to support , and difficult to debug when things go wrong . a", " non - nix - aware ci service that just runs nix build for example , you could have a github action or jenkins job that runs some nix build command on all pull requests . the advantage of this approach is that it is very simple but the downside is that the efficiency is worse when you need to scale out your build capacity . the reason why non - nix - aware ci solutions tend to do worse at scale is because they typically have their own notion of available builders / agents / slots which does not map cleanly onto nix \u2019 s notion of available builders . this means that you have to waste time tuning the two sets of builders", " to avoid wasting available build capacity and even after tuning you \u2019 ll probably end up with wasted build capacity . the reason hydra doesn \u2019 t have this problem is because hydra uses nix \u2019 s native notion of build capacity ( remote builds ) configured via the nix . distributedbuilds and nix . buildmachines nixos options . that means that you can easily scale out build capacity by adding more builders2 . this chapter will focus on setting up garnix since it \u2019 s dramatically simpler than the alternatives . also , we \u2019 re going to try to minimize the amount of logic that needs to live outside of nix . for example : checks", " that you \u2019 d normally run in a non - nix - aware job can be incorporated into a nix build \u2019 s check phase non - nix - aware jobs that deploy ( \u201c push \u201d ) a machine configuration can be replaced by machines periodically fetching and installing ( \u201c pulling \u201d ) their configuration this is covered later in this chapter \u2019 s continuous deployment section . for more discussion on the tradeoffs of \u201c push \u201d vs \u201c pull \u201d continuous deployment , see : push vs . pull in gitops : is there really a difference ? . garnix garnix already has official documentation for how to set it up , but i \u2019 ll", " mention here the relevant bits for setting up ci for our own production deployment . we \u2019 re going to configure this ci to build and cache the machine that we deploy to production , which will also ensure that we don \u2019 t merge any changes that break the build . this exercise will build upon the same example as the previous chapter on terraform , and you can reuse the example from that chapter or you can generate the example if you haven \u2019 t already by running these commands : $ mkdir todo - app $ cd todo - app $ nix flake init - - template ' github : gabriella", "439 / nixos - in - production / 0 . 9 # terraform ' \u2026 or you can skip straight to the final result ( minus the secrets file ) by running : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # continuous - deployment ' garnix requires the use of nix flakes in order to support efficient evaluation caching and the good news is that we can already build our nixos system without any changes to our flake , but it might not be obvious how at first glance . if we wanted to build our system", " , we would run : $ nix build ' . # nixosconfigurations . default . config . system . build . toplevel ' if your development system is apple silicon ( i . e . aarch64 - darwin ) you will not yet be able to build that locally . even if you use the linux builder from the setting up your development environment chapter that won \u2019 t work because the builder \u2019 s architecture ( aarch64 - linux ) won \u2019 t match the architecture of the system we \u2019 re deploying ( x86 _ 64 - linux ) . in a future chapter we \u2019 ll cover how to set", " up an x86 _ 64 - linux remote builders that you can use for testing builds like these , but until then you will have to settle for just evaluating the system configuration instead ofbuilding it , like this : $ nix eval ' . # nixosconfigurations . default . config . system . build . toplevel ' this will catch errors at the level of nix evaluation ( e . g . nix syntax errors or bad function calls ) but this won \u2019 t catch errors related to actuallybuilding the system . in fact , if all you care about is evaluation , you can simplify that latter command even further by", " just running : $ nix flake check \u2026 which does exactly the same thing ( among other things ) . however , typically we want to build and cache our nixos system , which is why we don \u2019 t just run nix flake check in ci . attributes let \u2019 s step through this attribute path : nixosconfigurations . default . config . system . build . toplevel \u2026 to see where each attribute comes from because that will come in handy if you choose to integrate nix into a non - nix - aware ci solution : nixosconfigurations this is one of the \u201c standard \u201d output attributes for", " flakes where we store nixos configurations that we want to build . this attribute name is not just a convention ; nixos configurations stored under this attribute enjoy special support from nix tools . specifically : nixos - rebuild only supports systems underneath the nixosconfigurations output we use nixos - rebuild indirectly as part of our terraform deployment because the terraform - nixos - ng module uses nixos - rebuild under the hood . in our project \u2019 s main . tf file the module . nixos . flake option is set to . # default which nixos - rebuild replaces with . # nixosconfigurations", " . default3 . nix flake check automatically checks the nixosconfigurations flake output \u2026 as noted in the previous aside . garnix \u2019 s default configuration builds all of the nixosconfigurations flake outputs \u2026 so if we stick to using that output then we don \u2019 t need to specify a non - default configuration . default we can store more than one nixos system configuration underneath the nixosconfigurations output . we can give each system any attribute name , but typically if you only have one system to build then the convention is to name that the default system . the command - line tooling", " does not give this default attribute any special treatment , though . config the output of the nixpkgs . lib . nixossystem system is similar in struct ure to a nixos module , which means that it has attributes like config and options . the config attribute lets you access the finalized values for all nixos options . system . build . toplevel this is a nixos option that stores the final derivation forbuilding our nixos system . for more details , see the nixos option definitions chapter . you can use nix repl to explore flake outputs by running : $ nix", " repl . # welcome to nix 2 . 18 . 1 . type : ? for help . loading installable ' path : / users / gabriella / proj / todo - app # ' . . . added 1 variables . nix - repl > \u2026 and then you can use autocompletion within the repl to see what \u2019 s available . for example : nix - repl > nixosconfigurations . < tab > nix - repl > nixosconfigurations . default . < tab > nixosconfigurations . default . _ module nixosconfigurations . default .", " extendmodules nixosconfigurati \\ ons . default . options nixosconfigurations . default . type nixosconfigurations . default . config nixosconfigurations . default . extraargs nixosconfigurati \\ ons . default . pkgs enabling garnix ci the only thing you \u2019 ll need in order to enable garnix ci for your project is to : turn your local directory into a git repository $ git init $ git add - - all $ git commit - - message ' initial commit ' host your git", " repository on github \u2026 by following these instruct ions . also , make this repository private , because later in this chapter we \u2019 re going to practice fetching a nixos configuration from a private repository . enable garnix on that repository \u2026 by visiting the garnix github app , installing it , and enabling it on your newly - created repository . \u2026 and you \u2019 re mostly done ! you won \u2019 t see any activity , though , until you create your first pull request so you can verify that garnix is working by creating a pull request to make the following change to the flake . nix file : -", " - - a / flake . nix + + + b / flake . nix @ @ - 7 , 4 + 7 , 12 @ @ modules = [ . / module . nix ] ; } ; } ; + + nixconfig = { + extra - substituters = [ \" https : / / cache . garnix . io \" ] ; + + extra - trusted - public - keys = [ + \" cache . garnix . io : ctfpykslcx5rmjkflo5eepuobba78b0yq2dtcjxqr9g = \" +", " ] ; + } ; } once you create that pull request , garnix will report two status checks on that pull request : \u201c evaluate flake . nix \u201d this verifies that your flake . nix file is well - formed and also serves as a fallback status check you can use if your flake has no outputs ( for whatever reason ) . \u201c nixosconfig default \u201d this status check verifies that our nixosconfigurations . default output builds correctly and caches it . the next thing you need to do is to enable branch protection settings so that those new status checks gate merge into your", " main branch . to do that , visit the \u201c settings \u2192 branches \u2192 add branch protection rule \u201d page of your repository ( which you can also find at https : / / github . com / $ { owner } / $ { repository } / settings / branch _ protection _ rules / new where $ { owner } is your username and $ { repository } is the repository name you chose ) . then select the following options : branch name pattern : main require status checks to pass before merging status checks that are required : \u201c evaluate flake . nix \u201d \u201c nixosconfig default \u201d since this is a tutorial project we", " won \u2019 t enable any other branch protection settings , but for a real project you would probably want to enable some other settings ( like requiring at least one approval from another contributor ) . once you \u2019 ve made those changes , merge the pull request you just created . you \u2019 ve just set up automated tests for your repository ! using garnix \u2019 s cache one of the reasons i endorse garnix for most nix / nixos projects is that they also take care of hosting a cache on your behalf . anything built by your ci is made available from their cache . the pull request you just merged configures your flake", " to automatically make use of garnix \u2019 s cache . if you were using an x86 _ 64 - linux machine , you could test this by running : $ nix build . # nixosconfigurations . default . config . system . build . toplevel the above command does not work on other systems ( e . g . aarch64 - darwin ) , even though the complete build product is cached ! you would think that nix would just download ( \u201c substitute \u201d ) the complete build product even if there were a system mismatch , but this does not work because nix refuses to substitute certain derivations", " . the above nix build command will only work if your local system is x86 _ 64 - linux or you have a remote builder configured to build x86 _ 64 - linux build products because nix will insist onbuilding some of the build products instead of substituting them . it is possible to work around this by adding the following two nix . conf options ( and restarting your nix daemon ) : extra - substituters = https : / / cache . garnix . io extra - trusted - public - keys = cache . garnix . io : ctfpykslcx5rmjkflo5eepuobba", "78b0yq2dtcjxqr9g = \u2026 and then you can run : $ flake = ' . # nixosconfigurations . default . config . system . build . toplevel ' $ nix - store - - realise \" $ ( nix eval - - raw \" $ { flake } . outpath \" ) \" \u2026 but that \u2019 s not as great of a user experience . continuous deployment we \u2019 re going to be using \u201c pull - based \u201d continuous deployment to manage our server , meaning that our server will periodically fetch the desired nixos configuration and install that", " configuration . nixos already has a set of system . autoupgrade options for managing a server in this way . what we want is to be able to set at least the following two nixos options : system . autoupgrade = { enable = true ; flake = \" github : $ { username } / $ { repository } # default \" ; } ; however , there \u2019 s a catch : this means that our machine will need to be able to access our private git repository . normally the way you \u2019 d do this is to specify an access token in nix . conf like this : access - tokens", " = github . com = $ { secret _ access _ token } \u2026 but don \u2019 t want to save this access token in version control in order to deploy our machine . another way we could fetch from a private git repository is to specify a flake like this : flake = \" git + ssh : / / git @ github . com / $ { username } / $ { repository } # default \" ; \u2026 which would allow us to access the private git repository using an ssh key pair instead of using a github access token ( assuming that we configure gith", "ub to grant that key pair access to the repository ) . either way , we \u2019 d need some sort of secret to be present on the machine in order to access the private repository . so we need some way to securely transmit or install secrets ( such as personal access tokens ) to our machine , but how do we bootstrap all of that ? for the examples in this book , we \u2019 re going to reuse the ssh key pair generated for our terraform deployment as a \u201c primary key pair \u201d . in other words , we \u2019 re going to install the private key of our ssh key pair on the target machine and", " then use the corresponding public key ( which we can freely share ) to encrypt other secrets ( which only our target machine can decrypt , using the private key ) . in fact , our original terraform template already does this : resource \" aws _ instance \" \" todo \" { \u2026 # we will use this in a future chapter to bootstrap other secrets user _ data = < < - eof # ! / bin / sh ( umask 377 ; echo ' $ { tls _ private _ key . nixos - in - production . private _ key _ openssh } ' > / var /", " lib / id _ ed2551 \\ 9 ) eof } we are now living in the future and we \u2019 re going to use the ssh private key mirrored to / var / lib / id _ ed25519 as the primary key that bootstraps all our other secrets . this implies that our \u201c admin \u201d ( the person deploying our machine using terraform ) will be able to transitively access all other secrets that the machine depends on because the admin has access to the same private key . however , there \u2019 s no real good way to prevent this sort of privilege escalation , because the ad", "min has root access to the machine and good luck granting the machine access to a secret without granting the root user access to the same secret . 4 sops - nix we \u2019 re going to use sops - nix ( a nixos wrapper around sops ) to securely distribute all other secrets we need to our server . the way that sops - nix works is : you generate an asymmetric key pair in other words , you generate a public key ( used to encrypt secrets ) and a matching private key ( used to decrypt secrets encrypted by the public key ) . this can be a gp", "g , ssh , or age key pair . this is our \u201c primary key pair \u201d . you install the private key on the target machine without using sops there is no free lunch here . you can \u2019 t bootstrap secrets on the target machine out of thin air . the private key of our primary key pair needs to already be present on the machine so that the machine can decrypt secrets encrypted by the public key . you use sops to add new encrypted secrets sops is a command - line tool that makes it easy to securely edit a secrets file . you can create a new secrets file", " using just the public key , but if you want to edit an existing secrets file ( e . g . to add or remove secrets ) you will require both the public key and private key . in practice this means that only an admin can add new secrets . you use sops - nix decrypt those secrets sops - nix is a nixos module that uses the private key ( which we installed out - of - band ) to decrypt the secrets file and make those secrets available as plain text files on the machine . by default , those text files are only readable by the root user but you can customize the file", " ownership and permissions to your liking . you might wonder what is the point of using sops to distribute secrets to the machine if it requires already having a secret present on the machine ( the primary key ) . the purpose of sops is to provide a uniform interface for adding , versioning , and installing all other secrets . otherwise , you \u2019 d have to roll your own system for doing this once you realize that it \u2019 s kind of a pain to implement a secret distribution mechanism for each new secret you need . so sops doesn \u2019 t completely solve the problem of secrets management ( you still have to figure out how to install the primary", " key ) , but it does make it easier to manage all the other secrets . age keys to use the sops command - line tool we \u2019 ll need to convert our ssh primary key pair into an age key pair . this step is performed by the admin who has access to both the ssh public key and the ssh private key and requires the ssh - to - age command - line tool , which you can obtain like this : $ nix shell ' github : nixos / nixpkgs / 23 . 11 # ssh - to - age ' the public key of our age key pair will be stored", " in a . sops . yaml configuration file which lives in version control . to create the age public key , run : $ cat > . sops . yaml < < eof creation _ rules : - age : ' $ ( ssh - to - age - i id _ ed25519 . pub ) ' eof the private key of our age key pair is stored locally by the admin so that they can edit secrets . to store the age private key , run : $ # on linux $ key _ file = ~ / . config / sops / age / keys . txt $ # on mac", "os $ key _ file = ~ / library / ' application support ' / sops / age / keys . txt $ mkdir - p \" $ ( dirname \" $ key _ file \" ) \" $ ( umask 077 ; ssh - to - age - private - key - i id _ ed25519 - o \" $ key _ file \" ) now you \u2019 re ready to start reading and writing secrets ! creating the secret create a fine - grained personal access token by visiting the new fine - grained personal access token page and entering the following settings : token name : \u201c todo app - continuous", " deployment \u201d expiration : 30 days descript ion : leave empty resource owner : your personal github account repository access : choose \u201c only select repositories \u201d and select your todo - app repository repository permissions : set the \u201c contents \u201d permission to \u201c read - only \u201d account permissions : do not enable any account permissions \u2026 and then click the \u201c generate token \u201d button . keep this page with the generated token open for just a second . fetch the sops command - line tool by running : $ nix shell ' github : nixos / nixpkgs / 23 . 11 # sops ' \u2026", " and then create a new secrets file by running : $ sops secrets . yaml that will open a new file in your editor with the following contents : hello : welcome to sops ! edit this file as you please ! example _ key : example _ value # example comment example _ array : - example _ value1 - example _ value2 example _ number : 1234 . 56789 example _ booleans : - true - false we \u2019 re going to do what file says and edit the file how we please . delete the entire file and replace it with : github - access - token : ' extra -", " access - tokens = github . com = github _ pat _ \u2026 ' \u2026 replacing github _ pat _ \u2026 with the personal access token you just generated . now if you save , exit , and view the file ( without sops ) you will see something like this : github - access - token : \u2026 sops : kms : [ ] gcp _ kms : [ ] azure _ kv : [ ] hc _ vault : [ ] age : - recipient : \u2026 enc : | - - - - - begin age encrypted file - - - - - \u2026 - - -", " - - end age encrypted file - - - - - lastmodified : \" \u2026 \" mac : enc [ aes256 _ gcm , data : \u2026 , iv : \u2026 , tag : \u2026 , type : str ] pgp : [ ] unencrypted _ suffix : _ unencrypted version : 3 . 7 . 3 \u2026 and since you \u2019 re the admin you can still decrypt the file using sops to view the secret : $ sops secrets . yaml anyone who doesn \u2019 t have access to the private key would instead get an error message like", " this : failed to get the data key required to decrypt the sops file . group 0 : failed \u2026 : failed - | failed to open file : open | \u2026 / sops / age / keys . txt : no such file or directory recovery failed because no master key was able to decrypt the file . in order for sops to recover the file , at least one key has to be successful , but none were . installing the secret now we can distribute the github personal access token stored inside of secrets . yaml . first we \u2019 ll need to import the sops - nix nixos module by modifying", " our flake . nix file like this : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; sops - nix . url = \" github : mic92 / sops - nix / bd695cc4d0a5e1bead703cc1bec5fa3094820a81 \" ; } ; outputs = { nixpkgs , sops - nix , . . . } : { nixosconfigurations . default = nixpkgs .", " lib . nixossystem { system = \" x86 _ 64 - linux \" ; modules = [ . / module . nix sops - nix . nixosmodules . sops ] ; } ; } ; nixconfig = { extra - substituters = [ \" https : / / cache . garnix . io \" ] ; extra - trusted - public - keys = [ \" cache . garnix . io : ctfpykslcx5rmjkflo5eepuobba78b0yq2dtcjxqr9g = \" ] ; } ;", " } then we \u2019 ll enable continuous deployment by adding the following lines to module . nix : { modulespath , . . . } : { \u2026 sops = { defaultsopsfile = . / secrets . yaml ; age . sshkeypaths = [ \" / var / lib / id _ ed25519 \" ] ; secrets . github - access - token = { } ; } ; nix . extraoptions = \" ! include / run / secrets / github - access - token \" ; } that will : install the secret on our server that uses the / var / lib / id", " _ ed25519 private key that terraform installed to decrypt the secrets . yaml file . incorporate the secret into the nix configuration this grants our nix daemon access to our private git repository containing our nixos configuration . the autoupgrade service finally , to enable continuous deployment , we will enable system . autoupgrade : { modulespath , . . . } : { \u2026 system . autoupgrade = { enable = true ; # replace $ { username } / $ { repository } with your repository ' s address flake = \" github : $ { username } / $ { repository } # default", " \" ; # poll the ` main ` branch for changes once a minute dates = \" minutely \" ; # you need this if you poll more than once an hour flags = [ \" - - option \" \" tarball - ttl \" \" 0 \" ] ; } ; but don \u2019 t deploy this configuration just yet ! first , add all the changes we \u2019 ve made so far to version control : $ nix flake update $ git fetch origin main $ git checkout - b continuous - deployment fetch _ head $ git add . sops . yaml secrets . yaml flake . nix flake . lock module", " . nix $ git commit - - message ' enable continuous deployment ' $ git push - - set - upstream origin continuous - deployment then create a pull request from those changes and merge the pull request once it passes ci . once you \u2019 ve merged your changes , checkout the main branch of your repository : $ git checkout main $ git pull - - ff - only \u2026 and deploy those changes using terraform , the same way we did in the previous chapter : $ terraform apply once you \u2019 ve applied those changes your machine will begin automatically pulling its configuration from the main branch of your repository . testing continuous deployment there are", " some diagnostic checks you can do to verify that everything is working correctly , but first you need to log into the machine using : $ ssh - i id _ ed25519 \" root @ $ { address } \" \u2026 replacing $ { address } with the public _ dns output of the terraform deployment . then you can check that the secret was correctly picked up by the nix daemon by running : [ root @ \u2026 : ~ ] # nix - - extra - experimental - features ' nix - command flakes ' show - config | grep access - tokens access - tokens = github . com = gi", "thub _ pat _ \u2026 \u2026 and you can also monitor the upgrade service by running : [ root @ \u2026 : ~ ] # journalctl - - output cat - - unit nixos - upgrade - - follow \u2026 and if things are working then every minute you should see the service output something like this : starting nixos upgrade . . . warning : ignoring untrusted flake configuration setting ' extra - substituters ' warning : ignoring untrusted flake configuration setting ' extra - trusted - public - keys 'building the system configuration . . . warning : ignoring untrusted flake configuration setting ' extra - substituters ' warning", " : ignoring untrusted flake configuration setting ' extra - trusted - public - keys ' updating grub 2 menu . . . switching to system configuration / nix / store / \u2026 - nixos - system - unnamed - \u2026 activating the configuration . . . setting up / etc . . . sops - install - secrets : imported / etc / ssh / ssh _ host _ rsa _ key as gpg key with fingerprint \u2026 sops - install - secrets : imported / var / lib / id _ ed25519 as age key with fingerprint \u2026 reloading user units for root . . . successful", " su for root by root pam _ unix ( su : session ) : session opened for user root ( uid = 0 ) by ( uid = 0 ) pam _ unix ( su : session ) : session closed for user root setting up tmpfiles finished switching to system configuration / nix / store / \u2026 - nixos - system - unnamed - \u2026 nixos - upgrade . service : deactivated successfully . finished nixos upgrade . nixos - upgrade . service : consumed \u2026 cpu time , no ip traffic . now let \u2019 s test that our continuous deployment is working by making a small change so that we don \u2019 t need", " to add the - - extra - experimental - features option to every nix command . add the following option to module . nix : nix . settings . extra - experimental - features = [ \" nix - command \" \" flakes \" ] ; \u2026 and create and merge a pull request for that change . once your change is merged the machine will automatically pick up the change on the next minute boundary and you can verify the change worked by running : [ root @ \u2026 : ~ ] # nix show - config \u2026 which will now work without the - - extra - experimental - features option . congratulations ! you \u2019 ve now set up a continuous deployment", " system ! 10 flakes this book has leaned pretty heavily on nix \u2019 s support for \u201c flakes \u201d , but i \u2019 ve glossed over the details of how flakes work despite how much we \u2019 ve already been using them . in this chapter i \u2019 ll give a more patient breakdown of flakes . most of what this chapter will cover is information that you can already find from other resources , like the nixos wiki page on flakes or by running nix help flake . however , i \u2019 ll still try to explain flakes in my own words . motivation you can think of flakes as a package manager for nix .", " in other words , if we use nix to build and distribute packageswritten in other programming languages ( e . g . go , haskell , python ) , then flakes are how we \u201c build \u201d and distribute nix packages . here are some example nix packages that are distributed as flakes : nixpkgs this is the most widely used nix package of all . nixpkgs is a giant git repository hosted on github containing the vast majority of software packaged for nix . nixpkgs also includes several important helper functions that you \u2019 ll need forbuilding even the simplest of packages , so you pretty much can \u2019", " t get anything done in nix without using nixpkgs to some degree . flake - utils this is a nix package containing useful utilities for creating flakes and is itself distributed as a flake . sops - nix this is a flake we just used in the previous chapter to securely distribute secrets . all three of the above packages provide reusable nix code that we might want to incorporate into downstream nix projects . flakes provide a way for us to depend on and integrate nix packages like these into our own projects . flakes , step - by - step we can build a better intuition for how flakes work by starting", " from the simplest possible flake you can write : # . / flake . nix { outputs = { nixpkgs , . . . } : { # replace * both * occurrences of ` x86 _ 64 - linux ` with your machine ' s system # # you can query your current system by running : # # $ nix eval - - impure - - expr ' builtins . currentsystem ' packages . x86 _ 64 - linux . default = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; } ; } you can then build and run that flake with", " this command : $ nix run hello ,world ! flake references we could have also run the above command as : $ nix run . \u2026 or like this : $ nix run ' . # default ' \u2026 or in this fully qualified form : $ # replace x86 _ 64 - linux with your machine ' s system $ nix run ' . # packages . x86 _ 64 - linux . default ' in the above command . # packages . x86 _ 64 - linux . default uniquely identifies a \u201c flake reference \u201d and an attribute path , which are separated by a # character : the first half ( the flake reference ) specifies where", " a flake is located in the above example the flake reference is \u201c . \u201d ( a shorthand for our current directory ) . the second half ( the attribute path ) specifies which output attribute to use in the above example , it is packages . x86 _ 64 - linux . default and nix run uses that output attribute path to select which executable to run . usually we don \u2019 t want to write out something long like . # packages . x86 _ 64 - linux . default when we use flakes , so flake - enabled nix commands provide a few convenient shorthands that we can use to shorten the command", " . first off , many nix commands will automatically expand part of the flake attribute path on your behalf . for example , if you run : $ nix run ' . # default ' \u2026 then nix run will attempt to expand . # default to a fully qualified attribute path of . # apps . \" $ { system } \" . default and if the flake does not have that output attribute path then nix run will fall back to a fully qualified attribute path of . # packages . \" $ { system } \" . default . different nix commands will expand the attribute path differently . for example : nix build and nix eval expand foo to packages .", " \" $ { system } \" . foo nix run expands foo to apps . \" $ { system } \" . foo \u2026 and falls back to packages . \" $ { system } \" . foo if that \u2019 s missing nix develop expands foo to devshells . \" $ { system } \" . foo \u2026 and falls back to packages . \" $ { system } \" . foo if that \u2019 s missing nixos - rebuild \u2019 s - - flake option expands foo to nixosconfigurations . foo nix repl will not expand attribute paths at all in each case the \" $ { system } \" in the expanded attribute path", " corresponds to your current system , which you can query using this command : $ nix eval - - impure - - expr ' builtins . currentsystem ' you can even omit the attribute path , in which case it will default to an attribute path of default . for example , if you run : $ nix run . \u2026 then nix run will expand . to . # default ( which will in turn expand to . # packages . $ { system } . default for our flake ) . furthermore , you can omit the flake reference , which will default to . , so if you run : $ nix run \u2026 then", " that expands to a flake reference of . ( which will then continue to expand according to the above rules ) . flake uris so far these examples have only used a flake reference of . ( the current directory ) , but in this book we \u2019 ll be using several types of flake references , including : paths these can be relative paths ( like . or . / utils or . . / bar ) , home - anchored paths ( like ~ / workspace ) , or absolute paths ( like / etc / nixos ) . in all three cases the path must be a directory containing a flake . nix file . gi", "thub uris these take the form github : $ { owner } / $ { repository } or github : $ { owner } / $ { repository } / $ { reference } ( where $ { reference } can be a branch , tag , or revision ) . nix will take care of cloning the repository for you in a cached and temporary directory and ( by default ) look for a flake . nix file within the root directory of the repository . indirect uris an indirect uri is one that refers to an entry in nix \u2019 s \u201c flake registry \u201d . if you run nix registry list you \u2019", " ll see a list of all your currently configured indirect uris . flake inputs normally the way flakes work is that you specify both inputs and outputs , like this : { inputs = { foo . url = \" $ { flake _ reference } \" ; bar . url = \" $ { flake _ reference } \" ; } ; outputs = { self , foo , bar } : { baz = \u2026 ; qux = \u2026 ; } ; } in the above example , foo and bar would be the flake inputswhile baz and qux would be the flake outputs . in other words , the sub -", " attributes nested underneath the inputs attribute are the flake inputs and the attributes generated by the outputs function are the flake outputs . notice how the outputs function takes input arguments which share the same name as the flake inputs because the flakes machinery resolves each input and then passes each resolved input as a function argument of the same name to the outputs function . to illustrate this , if you were to build the baz output of the above flake using : $ nix build . # baz \u2026 then that would sort of be likebuilding this nix pseudocode : let flake = import . / flake . nix ; foo = resolve", "flakeuri flake . inputs . foo ; bar = resolveflakeuri flake . inputs . baz ; self = flake . outputs { inherit self foo bar ; } ; in self . baz \u2026 where resolveflakeuri would be sort of like a function from an input \u2019 s flake reference to the nix code packaged by that flake reference . if you \u2019 re curious how flake inputs and outputs are actually resolved , it \u2019 s actually implemented as a function in nix , which you can find here in the nixos / nix repository . however , if you were paying close attention you might have noticed that our", " original example flake does not have any inputs : { outputs = { nixpkgs , . . . } : { packages . x86 _ 64 - linux . default = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; } ; } \u2026 and the outputs function references a nixpkgs input which we never specified . the reason this works is because flakes automatically convert missing inputs to \u201c indirect \u201d uris that are resolved using nix \u2019 s flake registry . in other words , it \u2019 s as if we hadwritten : { inputs = { nixpkgs . url =", " \" nixpkgs \" ; # example of an indirect flake reference } ; outputs = { nixpkgs , . . . } : { packages . x86 _ 64 - linux . default = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; } ; } an indirect flake reference is resolved by doing a lookup in the flake registry , which you can query yourself like this : $ nix registry list | grep nixpkgs global flake : nixpkgs github : nixos / nixpkgs / nixpkgs - unstable \u2026 so", " we could have alsowritten : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / nixpkgs - unstable \" ; } ; outputs = { nixpkgs , . . . } : { packages . x86 _ 64 - linux . default = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; } ; } \u2026 which would have produced the same result : both flake references will attempt to fetch the nixpkgs - unstable branch of the nixpkgs repository to resolve the nixpkgs flake", " input . throughout the rest of this chapter ( and book ) i \u2019 m going to try to make flake references as pure as possible , meaning : no indirect flake references in other words , instead of nixpkgs i \u2019 ll use something like github : nixos / nixpkgs / 23 . 11 . all github flake references will include a tag in other words , i won \u2019 t use a flake reference like github : nixos / nixpkgs . neither of these precautions are strictly necessary when using flakes because flakes lock their dependencies using a flake . lock", " file which you can ( and should ) store in version control . however , it \u2019 s still a good idea to take these precautions anyway even if you include the flake . lock file alongside your flake . nix file . the more reproducible your flake references , the better you document how to regenerate or update your lock file . suppose we were to use our own local git checkout of nixpkgs instead of a remote nixpkgs branch : we \u2019 d have to change the nixpkgs input to our flake to reference the path to our local repository ( since paths are valid flake", " references ) , like this : { inputs = { nixpkgs . url = ~ / repository / nixpkgs ; } ; outputs = { nixpkgs , . . . } : { packages . x86 _ 64 - linux . default = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; } ; } \u2026 and then we also need to build the flake using the - - impure flag : $ nix build - - impure without the flag we \u2019 d get this error message : error : the path ' ~ / repository / nixpkgs ' can not", " be resolved in pure mode notice that we \u2019 re using flake references in two separate ways : on the command line e . g . nix build \" $ { flake _ reference } \" when specifying flake inputs e . g . inputs . foo . url = \" $ { flake _ reference } \" ; however , they differ in two important ways : command line flake references never require the - - impure flag in other words , nix build ~ / proj / nixpkgs # foo is fine , but if you specify ~ / proj / nixpkgs as a flake input then you have", " to add the - - impure flag on the command line . flake inputs can be specified as attribute sets instead of strings to elaborate on the latter point , instead of specifying a nixpkgs input like this : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs \" ; } ; \u2026 } we could instead specify the same input like this : { inputs = { type = \" github \" ; owner = \" nixos \" ; repo = \" nixpkgs \" ; } ; \u2026 } throughout this book i \u2019 ll consistently use the non", " - struct ured ( string ) representation for flake references to keep things simple . flake outputs we haven \u2019 t yet covered what we actually get when we resolve a flake input . for example , what nix expression does a flake reference like github : nixos / nixpkgs / 23 . 11 resolve to ? the answer is that a flake reference will resolve to the output attributes of the corresponding flake . for a flake like github : nixos / nixpkgs / 23 . 11 that means that nix will : clone the nixpkgs repository check out the 23 . 11", " tag of that repository look for a flake . nix file in the top - level directory of that repository resolve inputs for that flake for this particular flake , there are no inputs to resolve . look for an outputs attribute , which will be a function computed the fixed - point of that function return that fixed - point as the result in this case the result would be an attribute set containing five attributes : lib , checks , htmldocs , legacypackages , and nixosmodules . in other words , it would behave like this ( non - flake - enabled ) nix code : # nixpkgs . nix", " let pkgs = import < nixpkgs > { } ; nixpkgs = pkgs . fetchfromgithub { owner = \" nixos \" ; repo = \" nixpkgs \" ; rev = \" 23 . 11 \" ; hash = \" sha256 - bthn1czj6rzteecue / pnrdssqyd2nia4w48miqaflom = \" ; } ; flake = import \" $ { nixpkgs } / flake . nix \" ; self = flake . outputs { inherit self ; } ; in self \u2026", " except that with flakes we wouldn \u2019 t have to figure out what hash to use since that would be transparently managed for us by the flake machinery . if you were to load the above file into the repl : $ nix repl - - file nixpkgs . nix \u2026 you would get the exact same result as if you had loaded the equivalent flake into the repl : $ nix repl github : nixos / nixpkgs / 23 . 11 in both cases the repl would now have the lib , checks , htmldocs , legacypackages , and nixosmodules", " attributes in scope since those are the attributes returned by the outputs function : nix - repl > legacypackages . x86 _ 64 - linux . hello \u00ab derivation / nix / store / zjh5kllay6a2ws4w46267i97lrnyya9l - hello - 2 . 12 . 1 . drv \u00bb this legacypackages . x86 _ 64 - linux . hello attribute path is the same attribute path that our original flake output uses : { \u2026 outputs = { nixpkgs , . . . } : { packages . x86 _ 64 - linux . default", " = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; # ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ } ; } there \u2019 s actually one more thing you can do with a flake , which is to access the original path to the flake . the following flake shows an example of this feature in action : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; flake", " - utils . url = \" github : numtide / flake - utils / v1 . 0 . 0 \" ; } ; outputs = { flake - utils , nixpkgs , . . . } : flake - utils . lib . eachdefaultsystem ( system : let config = { } ; overlay = self : super : { hello = super . hello . overrideattrs ( _ : { docheck = false ; } ) ; } ; overlays = [ overlay ] ; pkgs = import nixpk", "gs { inherit system config overlays ; } ; in { packages . default = pkgs . hello ; } ) ; } this flake customizes nixpkgs using an overlay instead of using the \u201c stock \u201d package set , but in order to create a new package set from that overlay we have to import the original source directory for nixpkgs . in the above example , that happens here when we import nixpkgs : pkgs = import nixpkgs { inherit system config overlays ; } ; normally the import keyword expects either a file or ( in", " this case ) a directory containing a default . nix file , but here nixpkgs is neither : it \u2019 s an attribute set containing all of the nixpkgs flake \u2019 s outputs . however , the import keyword can still treat nixpkgs like a path because it also comes with an outpath attribute , so we could have alsowritten : pkgs = import nixpkgs . outpath { inherit system config overlays ; } ; all flake inputs come with this outpath attribute , meaning that you can use a flake input anywhere nix expects a path and the flake input", " will be replaced with the path to the directory containing the flake . nix file . platforms all of the above examples hard - coded a single system ( x86 _ 64 - linux ) , but usually you want to supportbuilding a package for multiple systems . people typically use the flake - utils flake for this purpose , which you can use like this ; { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; flake - utils . url = \" github : numtide / flake - utils /", " v1 . 0 . 0 \" ; } ; outputs = { flake - utils , nixpkgs , . . . } : flake - utils . lib . eachdefaultsystem ( system : { packages . default = nixpkgs . legacypackages . \" $ { system } \" . hello ; } ) ; } \u2026 and that is essentially the same thing as if we hadwritten : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; flake - utils . url =", " \" github : numtide / flake - utils / v1 . 0 . 0 \" ; } ; outputs = { nixpkgs , . . . } : { packages . x86 _ 64 - linux . default = nixpkgs . legacypackages . x86 _ 64 - linux . hello ; packages . aarch64 - linux . default = nixpkgs . legacypackages . aarch64 - linux . hello ; packages . x86 _ 64 - darwin . default = nixpkgs . legacypackages . x86 _ 64 - darwin . hello ; packages . aarch", "64 - darwin . default = nixpkgs . legacypackages . aarch64 - darwin . hello ; } ; } we \u2019 ll be using flake - utils throughout the rest of this chapter and you \u2019 ll see almost all flakes use this , too . flake - related commands the nix command - line interface provides several commands that are flake - aware , and for the purpose of this chapter we \u2019 ll focus on the following commands : nix build nix run nix shell nix develop nix flake check nix flake init nix eval nix repl nixos - rebuild we \u2019 ll be using the following fl", "ake as the running example for our commands : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 ? dir = templates / cowsay ' \u2026 which will have this struct ure : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / 23 . 11 \" ; flake - utils . url = \" github : numtide / flake - utils / v1 . 0 . 0 \" ; } ; outputs = { flake - ut", "ils , nixpkgs , self } : flake - utils . lib . eachdefaultsystem ( system : let pkgs = nixpkgs . legacypackages . \" $ { system } \" ; in { packages . default = pkgs . cowsay ; apps = \u2026 ; checks = \u2026 ; devshells = \u2026 ; } ) / / { templates . default = \u2026 ; } ; } one of the things you might notice is that the some of the output attributes are nested inside of the call to eachdefaultsystem . specifically , the packages", " , apps , checks , and devshells outputs : \u2026 flake - utils . lib . eachdefaultsystem ( system : let pkgs = nixpkgs . legacypackages . \" $ { system } \" ; in { packages . default = pkgs . cowsay ; apps = \u2026 ; checks = \u2026 ; devshells = \u2026 ; } ) / / \u2026 for each of these outputs we want to generate system - specific build products , which is why they go inside the call to eachdefaultsystem . however , some flake outputs ( like templates", " ) are not system - specific , so they would go outside of the call to eachdefaultsystem , like this : flake - utils . lib . eachdefaultsystem ( system : let pkgs = nixpkgs . legacypackages . \" $ { system } \" ; in { \u2026 } ) / / { templates . default = \u2026 ; } ; you can always consult the flake output schema if you \u2019 re not sure which outputs are system - specific and which ones are not . for example , the sample schema will show something like this : self , .", " . . } @ inputs : { checks . \" < system > \" . \" < name > \" = derivation ; \u2026 packages . \" < system > \" . \" < name > \" = derivation ; \u2026 apps . \" < system > \" . \" < name > \" = { type = \" app \" ; program = \" < store - path > \" ; } ; \u2026 devshells . \" < system > \" . \" < name > \" = derivation ; \u2026 templates . \" < name > \" = { path = \" < store - path > \" ; descript ion = \" template descript ion goes here ? \"", " ; } ; } \u2026 and . \" < system > \" . component of the first four attribute paths indicates that these outputs are system - specific , whereas the templates . \" < name > \" attribute path has no system - specific path component . the same sample schema also explains which outputs are used by which nix commands , but we \u2019 re about to cover that anyway : nix build the nix build command builds output attributes underneath the packages attribute path . for example , if we run : $ nix build \u2026 that will build the . # packages . \" $ { system } \" . default output , which in our flake is just a synonym", " for the cowsay package from nixpkgs : \u2026 flake - utils . lib . eachdefaultsystem ( system : let pkgs = nixpkgs . legacypackages . \" $ { system } \" ; in { packages . default = pkgs . cowsay ; \u2026 } ) that build will produce this result : $ tree . / result . / result\u2500\u2500 bin \u2502\u2500\u2500 cowsay \u2502\u2500\u2500 cowthink - > cowsay\u2500\u2500 share\u2500\u2500 cowsay\u2500\u2500 cows \u2502\u2500\u2500 dragonandcow . pm \u2502\u2500\u2500 example . pm \u2502\u2500", "\u2500 frogs . pm \u2502\u2500\u2500 \u2026 \u2502\u2500\u2500 vader - koala . cow \u2502\u2500\u2500 vader . cow \u2502\u2500\u2500 www . cow\u2500\u2500 site - cows 5 directories , 58 files \u2026 which we can run like this : $ . / result / bin / cowsay howdy _ _ _ _ _ _ _ < howdy > - - - - - - - \\ ^ _ _ ^ \\ ( oo ) \\ _ _ _ _ _ _ _ ( _ _ ) \\ ) \\ / \\ | | - - - - w | | | | | so far this isn \u2019 t very interesting because we", " can already build the cowsay executable from nixpkgs directly like this : $ nix build ' github : nixos / nixpkgs / 23 . 11 # cowsay ' # exact same result in fact , we don \u2019 t even need to create a local copy of the cowsay template flake . we could also have run the flake directly from the github repository where it \u2019 s hosted : $ nix build ' github : gabriella439 / nixos - in - production / 0 . 9 ? dir = templates / cowsay ' this works because flakes support gith", "ub uris , so all of the flake operations in this chapter work directly on the github repository without having to clone or template the repository locally . however , for simplicity all of the following examples will still assume you templated the flake locally . nix run typically we won \u2019 t run the command bybuilding it and then running it . instead , we \u2019 ll more commonly use nix run to do both in one go : $ nix run . - - howdy # the \" . \" is necessary if the command takes arguments _ _ _ _ _ _ _ < howdy > - - - - - - - \\ ^", " _ _ ^ \\ ( oo ) \\ _ _ _ _ _ _ _ ( _ _ ) \\ ) \\ / \\ | | - - - - w | | | | | \u2026 and if we wanted to we could run cowsay directly from nixpkgs , too : $ nix run ' github : nixos / nixpkgs / 23 . 11 # cowsay ' - - howdy # exact same result by default , nix run will expand out . to . # apps . $ { system } . default , falling back to . # packages . $ { system } . default if that \u2019 s not present", " . our flake happens to provide the former attribute path : flake - utils . lib . eachdefaultsystem ( system : let pkgs = nixpkgs . legacypackages . \" $ { system } \" ; in { packages . default = pkgs . cowsay ; apps = { default = self . apps . \" $ { system } \" . cowsay ; cowsay = { type = \" app \" ; program = \" $ { self . packages . \" $ { system } \" . default } / bin / cowsay \" ; } ; cowthink = { type =", " \" app \" ; program = \" $ { self . packages . \" $ { system } \" . default } / bin / cowthink \" ; } ; } ; \u2026 } this time our flake has three available apps ( default , cowsay , and cowthink ) and the default app is just a synonym for the cowsay app . each app has to have : a field named type whose value must be \" app \" nix flakes don \u2019 t support other types of apps , yet . a string containing the desired program to run this string cannot contain any command - line options . it can only be a path to an ex", "ecutable . notice that flake outputs can reference other flake outputs ( via the self flake input ) . all flakes get this self flake input for free . we could have also used the rec language keyword instead , like this : apps = rec { default = cowsay ; cowsay = { type = \" app \" ; program = \" $ { self . packages . \" $ { system } \" . default } / bin / cowsay \" ; } ; cowthink = { type = \" app \" ; program = \" $ { self . packages . \" $ { system } \" . default } / bin /", " cowthink \" ; } ; } ; \u2026 which would define the default attribute to match the cowsay attribute within the same record . this works in small cases , but doesn \u2019 t scale well to more complicated cases ; you should prefer using the self input to access other attribute paths . you can use output attributes other than the default one by specifying their attribute paths . for example , if we want to use the cowthink program then we can run : $ nix run . # cowthink - - howdy _ _ _ _ _ _ _ < howdy > - - - - - - - \\ ^ _ _ ^ \\", " ( oo ) \\ _ _ _ _ _ _ _ ( _ _ ) \\ ) \\ / \\ | | - - - - w | | | | | apparently , the cowthink program produces the exact same result as the cowsay program . since the cowthink app is indistinguishable from the cowsay app , let \u2019 s replace it with a more interesting kittysay app that automatically adds the - f hellokitty flag . however , we can \u2019 t do something like this : apps = { \u2026 kittysay = { type = \" app \" ; program = \" $ { self . packages . \"", " $ { system } \" . default } / bin / cowsay - f hellokitty \" ; } ; } ; if you try to do that you \u2019 ll get an error like this one : $ nix run . # kittysay - - howdy error : unable to execute ' / nix / store / \u2026 - cowsay - 3 . 7 . 0 / bin / cowsay - f hellokitty ' : no such file or directo \\ ry \u2026 because nix expects the program attribute to be an executable path , not including any command - line arguments . if you want to wrap an executable with arguments then you", " need to do something like this : { packages = { default = pkgs . cowsay ; kittysay = pkgs . writescript bin \" kittysay \" ' ' $ { self . packages . \" $ { system } \" . default } / bin / cowsay - f hellokitty \" $ @ \" ; ' ' ; } ; apps = { \u2026 kittysay = { type = \" app \" ; program = \" $ { self . packages . \" $ { system } \" . kittysay } / bin / kittysay \" ; } ; } ; here we define a kittysay package ( which wraps cowsay with", " the desired command - line option ) and a matching kittysay app . note that if the name of the app is the same as the default executable for a package then we can just omit the app entirely . in the above kittysay example , we could delete the kittysay app and the example would still work because nix will fall back to running $ { self . packages . $ { system } . kittysay } / bin / kittysay . you can use nix run - - help to see the full set of rules for how nix decides what attribute to use and what path to execute . nix shell if you plan on running", " the same command ( interactively ) over and over then you probably don \u2019 t want to have to type nix run before every use of the command . not only is this less ergonomic but it \u2019 s also slower since the flake has to be re - evaluated every time you run the command . the nix shell comes in handy for use cases like this where it will take the flake outputs that you specify and add them to your executable search path ( e . g . your $ path in bash ) for ease of repeated use . we can add our cowsay to our search path in this way : $ nix shell $", " cowsay howdy _ _ _ _ _ _ _ < howdy > - - - - - - - \\ ^ _ _ ^ \\ ( oo ) \\ _ _ _ _ _ _ _ ( _ _ ) \\ ) \\ / \\ | | - - - - w | | | | | nix shell creates a temporary subshell providing the desired commands and you can exit from this subshell by entering an exit command or typing ctrl - d . nix shell can be useful for pulling in local executables from your flake , but it \u2019 s even more useful for pulling in executables temporarily from", " nixpkgs ( since nixpkgs provides a large array of useful programs ) . for example , if you wanted to temporarily add vim and tree to your shell you could run : $ nix shell ' github : nixos / nixpkgs / 23 . 11 # ' { vim , tree } note that the { vim , tree } syntax in the previous command is a bash / zsh feature . both shells expand the previous command to : $ nix shell ' github : nixos / nixpkgs / 23 . 11 # vim ' ' github : nixos / nix", "pkgs / 23 . 11 # tree ' this feature is a convenient way to avoid having to type out the github : nixos / nixpkgs / 23 . 11 flake reference twice when adding multiple programs to your shell environment . nix develop you can even create a reusable development shell if you find yourself repeatedly using the same temporary executables . our sample flake illustrates this by providing two shells : devshells = { default = self . packages . \" $ { system } \" . default ; with - dev - tools = pkgs . mkshell { inputsfrom = [", " self . packages . \" $ { system } \" . default ] ; packages = [ pkgs . vim pkgs . tree ] ; } ; } ; you can enter the default shell by running : $ nix develop \u2026 which will expand out to . # devshells . $ { system } . default , falling back to . # packages . $ { system } . default if the former attribute path is not present . this will give us a development environment forbuilding the cowsay executable . you can use these devshells to create reusable development environments ( for yourself or others ) so that you", " don \u2019 t have to build up large nix shell commands . you can exit from this development shell by either entering exit or typing ctrl - d . you might wonder what \u2019 s the difference between nix develop and nix shell . the difference between the two is that : nix shell adds the specified programs to your executable search path nix develop adds the development dependencies of the specified programs to your executable search path as a concrete example , when you run : $ nix shell nixpkgs # vim that adds vim to your executable search path . in contrast , if you run : $ nix develop nixpk", "gs # vim that provides a development environment necessary to build the vim executable ( like a c compiler or the ncurses package ) , but does not provide vim itself . in our sample flake , we used the mkshell utility : with - dev - tools = pkgs . mkshell { inputsfrom = [ self . packages . \" $ { system } \" . default ] ; packages = [ pkgs . vim pkgs . tree ] ; } ; \u2026 which is a convenient way to create a synthetic development environment ( appropriate for use with nix develop ) . the two most", " common arguments to mkshell are : inputsfrom mkshell inherits the development dependencies of any package that you list here . since self . packages . \" $ { system } \" . default is just our cowsay package then that means that all development dependencies of the cowsay package also become development dependencies of mkshell . packages all packages listed in the packages argument to mkshell become development dependencies of mkshell . so if we add vim and tree here then those will be present on the executable search path of our synthetic environment if we call nix develop on our mkshell . this", " means that the with - dev - tools shell is essentially the same as the default shell , except also extended with the vim and tree packages added to the executable search path . nix flake check you can add tests to a flake that the nix flake check command will run . these tests go under the checks output attribute and our sample flake provides a simple functional test for the cowsay package : checks = { default = self . packages . \" $ { system } \" . default ; diff = pkgs . runcommand \" test - cowsay \" { } ' ' diff < ( $ {", " self . apps . \" $ { system } \" . default . program } howdy ) - < < ' eof ' _ _ _ _ _ _ _ < howdy > - - - - - - - \\ ^ _ _ ^ \\ ( oo ) \\ _ _ _ _ _ _ _ ( _ _ ) \\ ) \\ / \\ | | - - - - w | | | | | eof touch $ out ' ' ; } ; the default check is a synonym for our cowsay package and just runs cowsay \u2019 s ( non - existent ) test suite . the diff check is a functional test that compares", " some sample cowsay output against a golden result . we can run both checks ( the default check and the diff check ) using : $ nix flake check the nix flake check command also performs other hygiene checks on the given flake and you can learn more about the full set of checks by running : $ nix flake check - - help nix flake init you can template a project using nix flake init , which we \u2019 ve already used a few times throughout this book ( including this chapter ) . our cowsay flake contains the following templates output : } ) / / { templates . default = {", " path = . / . ; descript ion = \" a tutorial flake wrapping the cowsay package \" ; } ; } ; \u2026 so earlier when we ran : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 ? dir = templates / cowsay ' \u2026 that copied the directory pointed to by the templates . default . path flake output to our local directory . note that this flake output is not system - specific , which is why it \u2019 s not nested inside the call to eachdefaultsystems in our fl", "ake . this is because there \u2019 s nothing system - dependent about templating some text files . nix eval nix eval is another command we \u2019 ve already used a few times throughout this book to query information about our flakes withoutbuilding anything . for example , if we wanted to query the version of our cowsay package , we could run : $ nix eval ' . # default . version ' \" 3 . 7 . 0 \" this is because flake outputs are \u201c just \u201d attribute sets and nix derivations are also \u201c just \u201d attribute sets , so we can dig into useful information about them by accessing the appropriate attribute", " path . however , you might not necessarily know what attribute paths are even available to query , which brings us to the next extremely useful nix command : nix repl you can use the nix repl command to easily interactively explore what attributes are available using repl auto - completion . for example , if you run : $ nix repl . # this requires the ` repl - flake ` experimental feature that will load all of the flake outputs ( e . g . packages , apps , checks , devshells , templates ) as identifiers of the same name into the repl . then you can use tab completion", " to dig further into their available fields : nix - repl > pac < tab > nix - repl > packages . < tab > packages . x86 _ 64 - linux packages . i686 - linux packages . x86 _ 64 - linux packages . aarch64 - linux packages . x86 _ 64 - darwin nix - repl > packages . x86 _ 64 - linux . < tab > nix - repl > packages . x86 _ 64 - linux . default . < tab > packages . x86 _ 64 - linux . default . _ _ darwinallowlocalnetworking packages . x86 _ 64 -", " linux . default . _ _ ignorenulls packages . x86 _ 64 - linux . default . _ _ impurehostdeps \u2026 packages . x86 _ 64 - linux . default . updatescript packages . x86 _ 64 - linux . default . userhook packages . x86 _ 64 - linux . default . version nix - repl > packages . x86 _ 64 - linux . default . version \" 3 . 7 . 0 \" remember that flake - utils ( specifically the eachdefaultsystem function ) adds system attributes underneath each of these top - level attributes , so even though we don", " \u2019 t explicitly specify system attribute in our flake . nix file they \u2019 re still going to be there when we navigate the flake outputs in the repl . that \u2019 s why we have to specify packages . x86 _ 64 - linux . default . version in the repl instead of just packages . default . version . however , you can skip having to specify the system if you specify the package you want to load into the repl . for example , if we load the default package output like this : $ nix repl . # default \u2026 that \u2019 s the same as loading . # packages . $ { system } . default", " into the repl , meaning that all of the default package \u2019 s attributes are now top - level identifiers in the repl , including version : nix - repl > version \" 3 . 7 . 0 \" the nix repl command comes in handy if you want to explore nix code interactively , whereas the nix eval command comes more in handy for non - interactive use ( e . g . script ing ) . nixos - rebuild last , but not least , the nixos - rebuild command also accepts flake outputs that specify the system to deploy . we already saw an example of this in the deploying to aw", "s using terraform chapter where we specified our system to deploy as . # default which expands out to the . # nixosconfigurations . default flake output . similar to the templates flake outputs , nixosconfigurations are not system - specific . there \u2019 s no particular good reason why this is the case since nixos can ( in theory ) be built for multiple systems ( e . g . x86 _ 64 - linux or aarch64 - linux ) , but in practice most nixos systems are only defined for a single architecture . our sample cowsay flake doesn \u2019 t provide any nixos", "configurations output , but the flake from our terraform chapter has an example nixosconfigurations output . 11 integration testing in our first web server we covered how to test a server manually and in this chapter we \u2019 ll go over how to use nixos to automate this testing process . specifically , we \u2019 re going to be authoring a nixos test , which you can think of as the nixos - native way of doing integration testing . however , in this chapter we \u2019 re going to depart from our running \u201c todo list \u201d example1 and instead use nixos tests to automate the getting started", " instruct ions from an open source tutorial . specifically , we \u2019 re going to be testing the postgrest tutorial . you can read through the tutorial if you want , but the relevant bits are : install postgres ( the database ) nixpkgs will handle this for us because nixpkgs has already packaged postgres ( both as a package and as a nixos module for configuring postgres ) . install postgrest ( the database - to - rest conversion service ) nixpkgs also ( partially ) handles this for us because all haskell packages ( including postgrest", " ) are already packaged for us , but ( at the time of this writing ) there isn \u2019 t yet a nixos module for postgres . for this particular example , though , that \u2019 s fine because then the integration testing code will match the tutorial even more closely . set up the database \u2026 by running these commands : create schema api ; create table api . todos ( id serial primary key , done boolean not null default false , task text not null , due timestamptz ) ; insert into api . todos ( task ) values ( ' finish tutorial 0 ' ) , ( ' pat self on back", " ' ) ; create role web _ anon nologin ; grant usage on schema api to web _ anon ; grant select on api . todos to web _ anon ; create role authenticator noinherit login password ' mysecretpassword ' ; grant web _ anon to authenticator ; launch postgrest \u2026 with this configuration file : db - uri = \" postgres : / / authenticator : mysecretpassword @ localhost : 5432 / postgres \" db - schemas = \" api \" db - anon - role = \" web", " _ anon \" check that the api works \u2026 by verifying that this command : $ curl http : / / localhost : 3000 / todos [ { \" id \" : 1 , \" done \" : false , \" task \" : \" finish tutorial 0 \" , \" due \" : null } , { \" id \" : 2 , \" done \" : false , \" task \" : \" pat self on back \" , \" due \" : null } ] nixos test you can clone the equivalent nixos test by running : $ nix flake init - - template ' github : gabriella439 / nix", "os - in - production / 0 . 9 # integration - test ' one of the included files is setup . sql file which includes the database commands from the tutorial verbatim : create schema api ; create table api . todos ( id serial primary key , done boolean not null default false , task text not null , due timestamptz ) ; insert into api . todos ( task ) values ( ' finish tutorial 0 ' ) , ( ' pat self on back ' ) ; create role web _ anon nologin ; grant usage on schema api to web _ anon ; grant select on api", " . todos to web _ anon ; create role authenticator noinherit login password ' mysecretpassword ' ; grant web _ anon to authenticator ; similarly , another file is tutorial . conf which includes the postgrest configuration from the tutorial verbatim : db - uri = \" postgres : / / authenticator : mysecretpassword @ localhost : 5432 / postgres \" db - schemas = \" api \" db - anon - role = \" web _ anon \" now we need to wrap these two into a nix", "os module which runs postgres ( with those setup commands ) and postgrest ( with that configuration file ) , which is what server . nix does : { config , pkgs , . . . } : { config = { networking . firewall . allowedtcpports = [ 3000 ] ; services . postgresql = { enable = true ; initialscript = . / setup . sql ; } ; systemd . services . postgrest = { wantedby = [ \" multi - user . target \" ] ; after = [ \" postgresql . service \" ] ;", " path = [ pkgs . postgrest ] ; script = \" postgrest $ { . / tutorial . conf } \" ; serviceconfig . user = \" authenticator \" ; } ; users = { groups . database = { } ; users = { authenticator = { issystemuser = true ; group = \" database \" ; } ; } ; } ; } ; } the main extra thing we do here ( that \u2019 s not mentioned in the tutorial ) is that we created an authenticator user and database group to match the database user of the same name . additionally , we open up", " port 3000 in the firewall , which we \u2019 re going to need to do to test the postgrest api ( served on port 3000 by default ) . we \u2019 re also going to create a client . nix file containing a pretty bare nixos configuration for our test client machine : { pkgs , . . . } : { environment . defaultpackages = [ pkgs . curl ] ; } next , we \u2019 re going to write a python script ( script . py ) to orchestrate our integration test : import json start _ all ( ) expected = [ { \" id \" : 1 , \"", " done \" : false , \" task \" : \" finish tutorial 0 \" , \" due \" : none } , { \" id \" : 2 , \" done \" : false , \" task \" : \" pat self on back \" , \" due \" : none } , ] actual = json . loads ( client . wait _ until _ succeeds ( \" curl - - fail - - silent http : / / server : 3000 / todos \" , 55 , ) ) assert expected = = actual this python script logs into the client machine to run a curl command and compares the json output of the command against the expected output from the", " tutorial . finally , we tie this all together in flake . nix : { inputs = { nixpkgs . url = \" github : nixos / nixpkgs / nixpkgs - unstable \" ; flake - utils . url = \" github : numtide / flake - utils / v1 . 0 . 0 \" ; } ; outputs = { flake - utils , nixpkgs , self , . . . } : flake - utils . lib . eachdefaultsystem ( system : { packages = { inherit", " ( self . checks . $ { system } . default ) driverinteractive ; } ; checks . default = nixpkgs . legacypackages . \" $ { system } \" . nixostest { name = \" test \" ; nodes = { server = import . / server . nix ; client = import . / client . nix ; } ; testscript = builtins . readfile . / script . py ; } ; } ) ; } here we \u2019 re using the nixostest function , which is our one - stop shop for integration testing . this function takes two main arguments that we care about :", " nodes this is an attribute set with one attribute per machine that we want to test and each attribute contains a nixos configuration for the corresponding machine . here , we \u2019 re going to be testing two machines ( named \u201c server \u201d and \u201c client \u201d ) whose nixos configurations are going to be imported from server . nix and client . nix respectively . we don \u2019 t have to store these nixos configurations in separate files ( we could store them inline within this same flake . nix file ) , but the code is a bit easier to follow if we keep things separate . testscript this is our python script that we \u2019 re also going", " to store in a separate file ( script . py ) . then we can run our nixos test using : $ nix flake check - - print - build - logs if you \u2019 re on macos you will need to follow the macos - specific setup instruct ions from the setting up your development environment chapter before you can run the above command . in particular , you will need to have a linux builder running in order to build the virtual machine image for the above nixos test . interactive testing you can also interactively run a nixos test using a python repl that has access to the same commands available within our s", "cript . py test script . to do so , run : $ nix run ' . # driverinteractive ' \u2026 > > > this will then open up a python repl with autocompletion support and the first thing we \u2019 re going to do in this repl is to launch all of the machines associated with our nixos test ( server and client in this case ) : > > > start _ all ( ) note that if you do this you won \u2019 t notice the prompt ( because it will be clobbered by the log output from the server ) , but it \u2019 s still there . alternatively , you", " can prevent that by temporarily silencing the machine \u2019 s log output like this : > > > serial _ stdout _ off ( ) > > > start _ all ( ) start all vms client : starting vm mke2fs 1 . 47 . 0 ( 5 - feb - 2023 ) client : qemu running ( pid 21160 ) server : starting vm mke2fs 1 . 47 . 0 ( 5 - feb - 2023 ) server : qemu running ( pid 21169 ) ( finished : start all vms , in 0 . 38 seconds ) > > > serial", " _ stdout _ on ( ) these serial _ stdout _ { on , off } functions come in handy if you find the machine log output too noisy . once you \u2019 ve started up the machines you can begun running commands that interact with each machine by invoking methods on python objects of the same name . for example , you can run a simple echo \" hello ,world ! \" command on the server machine like this : > > > server . succeed ( ' echo \" hello ,world ! \" ' ) server : must succeed : echo \" hello ,world ! \" server : waiting for the vm to finish booting server", " : guest shell says : b ' spawning backdoor root shell . . . \\ n ' server :connected to guest root shell server : ( connecting took 0 . 00 seconds ) ( finished : waiting for the vm to finish booting , in 0 . 00 seconds ) ( finished : must succeed : echo \" hello ,world ! \" , in 0 . 04 seconds ) ' hello ,world ! \\ n ' \u2026 and the succeed method will capture the command \u2019 s output and return it as a string which you can then further process within python . now let \u2019 s step through the same logic as the original test script so we can see", " for ourselves the intermediate values computed along the way : > > > response = client . succeed ( \" curl - - fail - - silent http : / / server : 3000 / todos \" ) client : must succeed : curl - - fail - - silent http : / / server : 3000 / todos ( finished : must succeed : curl - - fail - - silent http : / / server : 3000 / todos , in 0 . 04 seconds ) > > > response ' [ { \" id \" : 1 , \" done \" : false , \" task \" : \" finish tutorial 0 \" , \" due \" : null } ,", " \\ n { \" id \" : 2 , \" done \" : false , \" task \" : \" pat sel \\ f on back \" , \" due \" : null } ] ' > > > import json > > > json . loads ( response ) [ { ' id ' : 1 , ' done ' : false , ' task ' : ' finish tutorial 0 ' , ' due ' : none } , { ' id ' : 2 , ' done ' : false , ' task ' : \\ ' pat self on back ' , ' due ' : none } ] this sort of interactive exploration really comes in handy when author", "ing the test for the first time since it helps you understand the shape of the data and figure out which commands you need to run . you can consult the nixos test section of the nixos manual if you need a full list of available methods that you can invoke on machine objects . some really common methods are : succeed ( command ) - run a command once and require it to succeed wait _ until _ succeeds ( command , timeout ) - keep running a command until it succeeds wait _ for _ open _ port ( port , address , timeout ) - wait for a service to open a port wait _ for _ unit (", " unit , user , timeout ) - wait for a systemd unit to start up \u2026 but there are also some really cool methods you can use like : block ( ) - simulate a network disconnect crash ( ) - simulate a sudden power failure wait _ for _ console _ text ( regex , timeout ) - wait for the given regex to match against any terminal output get _ screen _ text ( ) - use ocr to capture the current text on the screen shared constants there are several constants that we use repeatedly throughout our integration test , like : the postgrest port the database , schema and table the", " username , role , group , and credentials one advantage of codifying the tutorial as a nixos test is that we can define constants like these in one place instead of copying them repeatedly and hoping that they remain in sync . for example , we wouldn \u2019 t want our integration test to break just because we changed the user \u2019 s password in setup . sql and forgot to make the matching change to the password in tutorial . conf . integration tests can often be time consuming to run and debug , so we want our test to break for more meaningful reasons ( an actual bug in the system under test ) and not because", " of errors in the test code . however , we \u2019 re going to need to restruct ure things a little bit in order to share constants between the various test files . in particular , we \u2019 re going to be using nixos options to store shared constants for reuse throughout the test . to keep this example short , we won \u2019 t factor out all of the shared constants and we \u2019 ll focus on a turning a couple of representative constants into nixos options . first , we \u2019 ll factor out the \" authenticator \" username into a shared constant , which we \u2019 ll store as a tutorial . user", "name nixos option in server . nix : { lib , config , pkgs , . . . } : { options = { tutorial = { user = lib . mkoption { type = lib . types . str ; } ; } ; } ; config = { tutorial . user = \" authenticator \" ; systemd . services . postgrest = { \u2026 serviceconfig . user = config . tutorial . user ; } ; users = { users = { \" $ { config . tutorial . user } \" = { issystemuser", " = true ; group = \" database \" ; } ; } ; } ; } ; } \u2026 and that fixes all of the occurrences of the authenticator user in server . nix but what about setup . sql or tutorial . conf ? one way to do this is to inline setup . sql and tutorial . conf into our server . nix file so that we can interpolate the nixos options directly into the generated files , like this : { \u2026 config = { services . postgresql = { \u2026 initialscript = pkgs . writetext \" setup . sql \" ' ' create schema", " api ; \u2026 create role $ { config . tutorial . user } noinherit login password ' mysecretpassword ' ; grant web _ anon to $ { config . tutorial . user } ; ' ' ; } ; systemd . services . postgrest = { \u2026 script = let configurationfile = pkgs . writetext \" tutorial . conf \" ' ' db - uri = \" postgres : / / $ { config . tutorial . user } : mysecretpassword @ localhost : 5432 / post", "gres \" db - schemas = \" api \" db - anon - role = \" web _ anon \" ' ' ; in \" postgrest $ { configurationfile } \" ; \u2026 } ; \u2026 } ; } this solution isn \u2019 t great , though , because it gets cramped pretty quickly and it \u2019 s harder to edit inline nix strings than standalone files . for example , when setup . sql is a separate file many editors will enable syntax highlighting for those sql commands , but that syntax highlighting won \u2019 t work when the sql commands are instead stored within an inline nix string . alternatively , we can keep the files separate", " and use the nixpkgs substituteall utility to interpolate the nix variables into the file . the way it works is that instead of using $ { user } to interpolate a variable you use @ user @ , like this new tutorial . conf file does : db - uri = \" postgres : / / @ user @ : mysecretpassword @ localhost : 5432 / postgres \" db - schemas = \" api \" db - anon - role = \" web _ anon \" similarly , we change our setup . sql file to also substitute in @ user", " @ where necessary : create schema api ; \u2026 create role @ user @ noinherit login password ' mysecretpassword ' ; grant web _ anon to @ user @ ; once we \u2019 ve done that we can use the pkgs . substituteall utility to template those files with nix variables of the same name : { \u2026 config = { \u2026 services . postgresql = { \u2026 initialscript = pkgs . substituteall { name = \" setup . sql \" ; src = . / setup . sql ; inherit ( config . tutorial ) user ; } ;", " } ; systemd . services . postgrest = { \u2026 script = let configurationfile = pkgs . substituteall { name = \" tutorial . conf \" ; src = . / tutorial . conf ; inherit ( config . tutorial ) user ; } ; in \" postgrest $ { configurationfile } \" ; \u2026 } ; \u2026 } ; } the downside to using pkgs . substituteall is that it \u2019 s easier for there to be a mismatch between the variable names in the template and the variable names in nix . even so , this is usually the", " approach that i would recommend . we can do something fairly similar to also thread through the postgrest port everywhere it \u2019 s needed . the original postgrest tutorial doesn \u2019 t specify the port in the tutorial . conf file , but we can add it for completeness : db - uri = \" postgres : / / @ user @ : mysecretpassword @ localhost : 5432 / postgres \" db - schemas = \" api \" db - anon - role = \" web _ anon \" server - port = @ port @ \u2026 and then we can make matching", " changes to server . nix to define and use this port : { options = { tutorial = { port = lib . mkoption { type = lib . types . port ; } ; \u2026 } ; } ; config = { tutorial . port = 3000 ; \u2026 networking . firewall . allowedtcpports = [ config . tutorial . port ] ; systemd . services . postgrest = { \u2026 script = let configurationfile = pkgs . substituteall { name = \" tutorial . conf \" ; src = . / tutorial . conf ; inherit", " ( config . tutorial ) port user ; } ; in \" postgrest $ { configurationfile } \" ; \u2026 } ; \u2026 } ; } \u2026 but we \u2019 re not done ! we also need to thread this port to script . py , which references this same port in the curl command . this might seem trickier because the place where script . py is referenced ( in flake . nix ) : { \u2026 outputs = { flake - utils , nixpkgs , self , . . . } : flake - utils . lib . eachdefaultsystem", " ( system : { \u2026 checks . default = nixpkgs . legacypackages . \" $ { system } \" . nixostest { \u2026 testscript = builtins . readfile . / script . py ; } ; } ) ; } \u2026 is not inside of any nixos module . so how do we access nixos option definitions when defining our testscript ? the trick is that the testscript argument to the nixostest function can be a function : # i ' ve inlined the test script to simplify things testscript = { nodes } : let inherit ( nodes . server . config", " . tutorial ) port ; in ' ' import json start _ all ( ) expected = [ { \" id \" : 1 , \" done \" : false , \" task \" : \" finish tutorial 0 \" , \" due \" : none } , { \" id \" : 2 , \" done \" : false , \" task \" : \" pat self on back \" , \" due \" : none } , ] actual = json . loads ( client . wait _ until _ succeeds ( \" curl - - fail - - silent http : / / server : $ { tostring port } / todos \" , 7 , ) )", " assert expected = = actual ' ' ; this function takes one argument ( nodes ) which is an attribute set containing one attribute for each machine in our integration test ( e . g . server and client for our example ) . each of these attributes in turn has all of the output attributes generated by evalmodules , including : options - the option declarations for the machine config - the final option definitions for the machine this is why we can access the server \u2019 s tutorial . port nixos option using nodes . server . config . tutorial . port . moreover , every nixos configuration also has a nixpk", "gs . pkgs option storing the nixos package set used by that machine . this means that instead of adding curl to our client machine \u2019 s environment . defaultpackages , we could instead do something like this : testscript = { nodes } : let inherit ( nodes . client . config . nixpkgs . pkgs ) curl ; \u2026 in ' ' \u2026 actual = json . loads ( client . wait _ until _ succeeds ( \" $ { curl } / bin / curl - - fail - - silent http : / / server : $ { tostring port } / todos \" , 7 ,", " ) ) \u2026 ' ' ; 12 containers the previous chapter on integration testing translated the postgrest tutorial to an equivalent nixos test , but that translation left out one important detail : the original tutorial asks the user to run postgres inside of a docker container : if docker is not installed , you can get it here . next , let \u2019 s pull and start the database image : $ sudo docker run - - name tutorial - p 5432 : 5432 \\ - e postgres _ password = mysecretpassword \\ - d postgres this will run the docker instance as", " a daemon and expose port 5432 to the host system so that it looks like an ordinary postgresql server to the rest of the system . we don \u2019 t have to use docker to run postgres ; in fact , i \u2019 d normally advise against it and recommend using the postgres nixos module instead . however , we can still use this as an illustrative example of how to translate docker idioms to nixos . more generally , in this chapter we \u2019 re going to cover container management in the context of nixos and introduce a spectrum of options ranging from more docker - native to more", " nixos - native . docker registry the most docker - native approach is to fetch a container from the docker registry and to illustrate that we \u2019 re going to begin from the previous chapter \u2019 s example integration test : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # integration - test ' \u2026 but this time instead of using the nixos postgres module : # server . nix \u2026 services . postgresql = { enable = true ; initialscript = . / setup . sql ; } ; \u2026 \u2026 we \u2019 re", " going to replace that code with a nixos configuration that runs the official postgres image obtained from the docker registry in almost the same way as the tutorial : \u2026 virtualisation . oci - containers = { backend = \" docker \" ; containers = { # we really should call this container \" postgres \" but we ' re going to # call it \" tutorial \" just for fun to match the original instruct ions . tutorial = { image = \" postgres : 16 . 2 \" ; environment . postgres _ password = \" mysecretpassword \" ; extraoptions =", " [ \" - - network = host \" ] ; } ; } ; } ; \u2026 we \u2019 ve only made a few changes from the tutorial : we specify the container tag ( 16 . 2 ) explicitly by default if we omit the tag we \u2019 ll get whatever image the latest tag points to . we \u2019 d rather specify a versioned tag to improve the reproducibility of the example because the latest tag is a moving target that points to the most recent published version of the postgres image . we use host networking instead of publishing port 5432 this means that our container won \u2019 t use an isolated network and will instead", " reuse the host machine \u2019 s network for communicating between containers . this simplifies the example because at the time of this writing there isn \u2019 t a stock nixos option for declaratively managing a docker network . nixos provides a virtualisation . oci - containers option hierarchy which lets us declaratively define the same options as docker run but it also takes care of several supporting details for us , including : installing and running the docker service for our nixos machine in particular , the backend = \" docker \" ; option is what specifies to use docker as the backend for running our container", " ( instead of the default backend , which is podman ) . creating a systemd service to start and stop the container this systemd service runs essentially the same docker run command from the tutorial when starting up , and also runs the matching docker stop command when shutting down . we also still need to run the setup commands from setup . sql after our container starts up , but we no longer have a convenient services . postgresql . initialscript option that we can use for this purpose when going the docker route . instead , we \u2019 re going to create our own \u201c one shot \u201d systemd service to take", " care of this setup process for us : \u2026 systemd . services . setup - postgresql = let uri = \" postgresql : / / postgres : mysecretpassword @ localhost \" ; in { wantedby = [ \" multi - user . target \" ] ; path = [ pkgs . docker ] ; prestart = ' ' until docker exec tutorial pg _ isready - - dbname $ { uri } ; do sleep 1 done ' ' ; script = ' ' docker exec - - interactive tutorial psq", "l $ { uri } < $ { . / setup . sql } ' ' ; serviceconfig = { type = \" oneshot \" ; remainafterexit = \" yes \" ; } ; } ; \u2026 we can then sequence our postgrest service after that one by changing it to be after our setup service : systemd . services . postgrest = { \u2026 - after = [ \" postgresql . service \" ] ; + after = [ \" setup - postgresql . service \" ] ; \u2026 } ; \u2026 and if we re - run the test it still passes : $", " nix flake check the upside of this approach is that it requires the least buy - in to the nixos ecosystem . however , there \u2019 s one major downside : it only works if the system has network access to a docker registry , which can be a non - starter for a few reasons : this complicates the your deployment architecture \u2026 since now your system needs network access at runtime to some sort of docker registry ( either the public one or a private registry you host ) . this can cause problems when deploying to environments with highly restricted or no network access . this adds latency to your system startup \u2026 because", " you need to download the image the first time you deploy the system ( or upgrade the image ) . moreover , if you do any sort of integration testing ( like we are ) you have to pay that cost every time you run your integration test . podman you might notice that the nixos option hierarchy for running docker containers is called virtualisation . oci - containers and not virtualisation . docker - containers . this is because docker containers are actually oci containers ( short for \u201c open container initiative \u201d ) and oci containers can be run by any oci - compatible backend . moreover , nixos supports two oci", " - compatible backends : docker and podman . in fact , you often might prefer to use podman ( the default ) instead of docker for running containers for a few reasons : podman doesn \u2019 t require a daemon podman is distributed as a podman command line tool that encompasses all of the logic needed to run oci containers . the podman command line tool doesn \u2019 t need to delegate instruct ions to a daemon running in the background like docker does . improved security podman \u2019 s \u201c daemonless \u201d operation also implies \u201c rootless \u201d operation . in other words , you don \u2019 t need root privileges", " to run an oci container using podman . docker , on the other hand , requires elevated privileges by default to run containers ( unless you run docker in rootless mode ) , which is an enormous security risk . for example , a misconfigured or compromised dockerfile can allow a container to mount the host \u2019 s root filesystem which in the best case corrupts the host \u2019 s filesystem with the guest container \u2019 s files and in the worst case enables total compromise of the host by an attacker . switching from docker to podman is pretty easy : we only need to change the virtual", "isation . oci - containers . backend option from \" docker \" to \" podman \" ( or just delete the option , since \" podman \" is the default ) : virtualisation . oci - containers = { - backend = \" docker \" ; + backend = \" podman \" ; \u2026 and then change all command - line references from podman to docker : - path = [ pkgs . docker ] ; + path = [ pkgs . podman ] ; prestart = ' ' - until docker exec tutorial pg _ isready - - dbname", " $ { uri } ; do + until podman exec tutorial pg _ isready - - dbname $ { uri } ; do sleep 1 done ' ' ; script = ' ' - docker exec - - interactive tutorial psql $ { uri } < $ { . / setup . sql } + podman exec - - interactive tutorial psql $ { uri } < $ { . / setup . sql } ' ' ; this works because the podman command - line tool provides the exact same interface as the the docker command - line tool , so it \u2019 s", " a drop - in replacement . streamlayeredimage if you \u2019 re willing to lean more into nixos , there are even better options at your disposal . for example , you can build the docker image using nixos , too ! in fact , docker images built with nixos tend to be leaner than official docker images for two main reasons : nix - built docker images automatically prune build - time dependencies this is actually a feature of the nix language itself , which autodetects which dependencies are runtime dependencies and only includes those in built packages ( including nix - built docker images ) .", " docker images built using traditional dockerfiles usually have to do a bunch of gymnastics to avoid accidentally pulling in build - time dependencies into the image or any of its layers but in nix you get this feature for free . nix - built docker images have more cache - friendly layers for more details you can read this post but to summarize : nix \u2019 s utilities forbuilding docker images are smarter than dockerfiles and result in superior layer caching . this means that as you amend the docker image to add or remove dependencies you get fewer rebuilds and better disk utilization . nixpkgs provides several", " utilities forbuilding docker images using nix , but we \u2019 re only going to concern ourselves with one of those utilities : pkgs . dockertools . streamlayeredimage . this is the most efficient utility at our disposal that will ensure the best caching and least disk churn out of all the available options . we \u2019 ll delete the old postgrest service and instead use this streamlayeredimage utility to build an application container wrapping postgrest . we can then reference that container in virtualisation . oci - containers . containers , like this : \u2026 virtualisation . oci - containers = {", " backend = \" docker \" ; containers = { \u2026 postgrest = { image = \" postgrest : nix \" ; imagestream = pkgs . dockertools . streamlayeredimage { name = \" postgrest \" ; tag = \" nix \" ; contents = [ pkgs . postgrest ] ; config . cmd = [ \" postgrest \" . / tutorial . conf ] ; } ; extraoptions = [ \" - - network = host \" ] ; } ; } ; } ; \u2026 you can also clone an example containing all changes up to this", " point by running : $ nix flake init - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # docker ' this creates a new postgrest container that doesn \u2019 t depend on the docker registry at all . note that the docker registry does host an official postgrest image but we \u2019 re not going to use that image . instead , we \u2019 re using a postgrest docker image built entirely using nix . moreover , this nix - built docker image integrates efficiently with nix . if we add or remove dependencies from our docker image", " then we \u2019 ll only build and store what changed ( the \u201c diff \u201d ) , instead ofbuilding and storing an entirely new copy of the whole docker image archive . of course , your next thought might be : \u201c if we \u2019 re using nix / nixos to build and consume docker images , then do we still need docker ? \u201d . can we cut out docker as an intermediate and still preserve most of the same benefits of containerization ? yes ! nixos containers nixos actually supports a more nixos - native alternative to docker , known as nixos containers . under the hood , these use systemd -", " nspawn as the container engine but that \u2019 s essentially invisible to the end user ( you ) . the user interface for nixos containers is much simpler than the docker - based alternatives , so if you don \u2019 t need docker specifically but you still want some basic isolation guarantees then this is the way to go . the easiest way to illustrate how nixos containers work is to redo our postgrest example to put both postgres and postgrest in separate nixos containers . we \u2019 re going to begin by resetting our example back to the non - container example from the previous chapter : $ nix flake in", "it - - template ' github : gabriella439 / nixos - in - production / 0 . 9 # integration - test ' \u2026 and then we \u2019 ll make two changes . first , instead of running postgres on the host machine like this : \u2026 services . postgresql = { enable = true ; initialscript = . / setup . sql ; } ; \u2026 \u2026 we \u2019 re going to change that code to run it inside of a nixos container ( still named tutorial ) like this : \u2026 containers . tutorial = { autostart = true ; config = { services . post", "gresql = { enable = true ; initialscript = . / setup . sql ; } ; } ; } ; \u2026 this change illustrates what \u2019 s neat about nixos containers : we can configure them using the same nixos options that we use to configure the host machine . all we have to do is wrap the options inside containers . $ { name } . config but otherwise we configure nixos options the same way whether inside or outside of the container . this is why it \u2019 s worth trying out nixos containers if you don \u2019 t need any docker - specific functionality", " but you still want some basic isolation in place . nixos containers are significantly more ergonomic to use . we can also wrap our postgrest service in the exact same way , replacing this : systemd . services . postgrest = { wantedby = [ \" multi - user . target \" ] ; after = [ \" postgresql . service \" ] ; path = [ pkgs . postgrest ] ; script = \" postgrest $ { . / tutorial . conf } \" ; serviceconfig . user = \" authenticator \" ; } ; users = { groups . database", " = { } ; users . authenticator = { issystemuser = true ; group = \" database \" ; } ; } ; \u2026 with this : containers . postgrest = { autostart = true ; config = { systemd . services . postgrest = { wantedby = [ \" multi - user . target \" ] ; after = [ \" postgresql . service \" ] ; path = [ pkgs . postgrest ] ; script = \" postgrest $ { . / tutorial . conf } \" ; serviceconfig . user = \" authenticator \"", " ; } ; users = { groups . database = { } ; users . authenticator = { issystemuser = true ; group = \" database \" ; } ; } ; } ; } ; \u2026 and that \u2019 s it ! in both cases , we just took our existing nixos configuration options and wrapped them in something like : containers . \" $ { name } \" = { autostart = true ; config = { \u2026 } ; } ; \u2026 and we got containerization for free . just like the docker example , these nixos containers use the host network to connect to one another , meaning that they don \u2019", " t set privatenetwork = true ; ( which creates a private network for the given nixos container ) . at the time of this writing there isn \u2019 t an easy way to network nixos containers isolated in this way that doesn \u2019 t involve carefully selecting a bunch of magic strings ( ip addresses and network interfaces ) . this is a poor user experience and not one that i feel comfortable documenting or endorsing at the time of this writing . notes what is nixos for ? 1the reason why is that writing a ( meaningful ) test for our todo list example would require executing javascript using something like selenium , which", " will significantly increase the size of the example integration test . postgrest , on the other hand , is easier to test from the command line . continuous integration and deployment 1the reason why is that writing a ( meaningful ) test for our todo list example would require executing javascript using something like selenium , which will significantly increase the size of the example integration test . postgrest , on the other hand , is easier to test from the command line . 2okay , there is actually a limit to how much you can scale out build capacity . after a certain point you will begin to hit bottlenecks in", " instantiating derivations at scale , but even in this scenario hydra still has a higher performance ceiling than the the non - nix - aware alternatives . 3i have no idea why nixos - rebuild works this way and doesn \u2019 t accept the full attribute path including the nixosconfigurations attribute . 4there are some ways you can still prevent privilege escalation by the root user , like multi - factor authentication , but do you really want some other person to have to multi - factor authenticate every time one of your machines polls github for the latest configuration ? it \u2019 s much simpler to just trust your ad", "min . integration testing 1the reason why is that writing a ( meaningful ) test for our todo list example would require executing javascript using something like selenium , which will significantly increase the size of the example integration test . postgrest , on the other hand , is easier to test from the command line .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ nixpkgs overriding packages welcome to the 17th nix pill . in the previous 16th pill we have started to dive into the nixpkgs repository . nixpkgs is a function , and we ' ve looked at", " some parameters like system and config . today we ' ll talk about a special attribute : config . packageoverrides . overriding packages in a set with fixed point can be considered another design pattern in nixpkgs . overriding a package recall the override design pattern from the nix pill 14 . instead of calling a function with parameters directly , we make the call ( function + parameters ) overridable . we put the override function in the returned attribute set of the original function call . take for example graphviz . it has an input parameter xorg . if it ' s null , then graphvi", "z will build without x support . $ nix repl nix - repl > : l < nixpkgs > added 4360 variables . nix - repl > : b graphviz . override { withxorg = false ; } this will build graphviz without x support , it ' s as simple as that . however , let ' s say a package p depends on graphviz , how do we make p depend on the new graphviz without x support ? in an imperativeworld . . . . . . you could do something like this : pkgs = import < nixpkgs > {", " } ; pkgs . graphviz = pkgs . graphviz . override { withxorg = false ; } ; build ( pkgs . p ) given pkgs . p depends on pkgs . graphviz , it ' s easy to build p with the replaced graphviz . in a pure functional language it ' s not that easy because you can assign to variables only once . fixed point the fixed point with lazy evaluation is crippling but about necessary in a language like nix . it lets us achieve something similar to what we ' d do imperatively . follows the definition of", " fixed point in nixpkgs : { # take a function and evaluate it with its own returned value . fix = f : let result = f result ; in result ; } it ' s a function that accepts a function f , calls f result on the result just returned by f result and returns it . in other words it ' s f ( f ( f ( . . . . at first sight , it ' s an infinite loop . with lazy evaluation it isn ' t , because the call is done only when needed . nix - repl > fix = f : let result = f result ; in result nix - repl >", " pkgs = self : { a = 3 ; b = 4 ; c = self . a + self . b ; } nix - repl > fix pkgs { a = 3 ; b = 4 ; c = 7 ; } without the rec keyword , we were able to refer to a and b of the same set . * first pkgs gets called with an unevaluated thunk ( pkgs ( pkgs ( . . . ) * to set the value of c then self . a and self . b are evaluated . * the pkgs function gets called again to get the value of", " a and b . the trick is that c is not needed to be evaluated in the inner call , thus it doesn ' t go in an infinite loop . won ' t go further with the explanation here . a good post about fixed point and nix can be found here . overriding a set with fixed point given that self . a and self . b refer to the passed set and not to the literal set in the function , we ' re able to override both a and b and get a new value for c : nix - repl > overrides = { a = 1 ; b = 2 ; } nix - repl >", " let newpkgs = pkgs ( newpkgs / / overrides ) ; in newpkgs { a = 3 ; b = 4 ; c = 3 ; } nix - repl > let newpkgs = pkgs ( newpkgs / / overrides ) ; in newpkgs / / overrides { a = 1 ; b = 2 ; c = 3 ; } in the first case we computed pkgs with the overrides , in the second case we also included the overridden attributes in the result . overriding nixpkgs packages", " we ' ve seen how to override attributes in a set such that they get recursively picked by dependent attributes . this approach can be used for derivations too , after all nixpkgs is a giant set of attributes that depend on each other . to do this , nixpkgs offers config . packageoverrides . so nixpkgs returns a fixed point of the package set , and packageoverrides is used to inject the overrides . create a config . nix file like this somewhere : { packageoverrides = pkgs : { graphviz = pk", "gs . graphviz . override { # disable xorg support withxorg = false ; } ; } ; } now we can build e . g . asciidoc - full and it will automatically use the overridden graphviz : nix - repl > pkgs = import < nixpkgs > { config = import . / config . nix ; } nix - repl > : b pkgs . asciidoc - full note how we pass the config with packageoverrides when importing nixpkgs . then pkgs . as", "ciidoc - full is a derivation that has graphviz input ( pkgs . asciidoc is the lighter version and doesn ' t use graphviz at all ) . since there ' s no version of asciidoc with graphviz without x support in the binary cache , nix will recompile the needed stuff for you . the ~ / . config / nixpkgs / config . nix file in the previous pill we already talked about this file . the above config . nix that we just wrote could be the content of ~ / . config / nixp", "kgs / config . nix ( or the deprecated location ~ / . nixpkgs / config . nix ) . instead of passing it explicitly whenever we import nixpkgs , it will be automatically imported by nixpkgs . conclusion we ' ve learned about a new design pattern : using fixed point for overriding packages in a package set . whereas in an imperative setting , like with other package managers , a library is installed replacing the old version and applications will use it , in nix it ' s not that straight and simple . but it ' s more precise . nix applications will depend on specific versions", " of libraries , hence the reason why we have to recompile asciidoc to use the new graphviz library . the newly built asciidoc will depend on the new graphviz , and old asciidoc will keep using the old graphviz undisturbed . next pill . . . we will stop studying nixpkgs for a moment and talk about store paths . how does nix compute the path in the store where to place the result of builds ? how to add files to the store for which we have an integrity hash ?", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ callpackage design pattern welcome to the 13th nix pill . in the previous 12th pill , we introduced the first basic design pattern for organizing a repository of software . in addition , we packaged graphviz so that we had two packages", " to bundle into an example repository . the next design pattern we will examine is called the callpackage pattern . this technique is extensively used in nixpkgs , and it ' s the current de facto standard for importing packages in a repository . its purpose is to reduce the duplication of identifiers between package derivation inputs and repository derivations . the callpackage convenience in the previous pill , we demonstrated how the inputs pattern decouples packages from the repository . this allowed us to manually pass the inputs to the derivation ; the derivation declares its inputs , and the caller passes the arguments . however , as with usual programming languages ,", " there is some duplication of work : we declare parameter names and then we pass arguments , typically with the same name . for example , if we define a package derivation using the inputs pattern such as : { input1 , input2 , . . . } : . . . we would likely want to bundle that package derivation into a repository via a an attribute set defined as something like : rec { lib1 = import package1 . nix { inherit input1 input2 ; } ; program2 = import package2 . nix { inherit inputx inputy lib1 ; } ; } there are two things to note . first , that", " inputs often have the same name as attributes in the repository itself . second , that ( due to the rec keyword ) , the inputs to a package derivation may be other packages in the repository itself . rather than passing the inputs twice , we would prefer to pass those inputs from the repository automatically and allow for manually overriding defaults . to achieve this , we will define a callpackage function with the following calling convention : { lib1 = callpackage package1 . nix { } ; program2 = callpackage package2 . nix { someoverride = overriddenderivation ; } ; } we want callpack", "age to be a function of two arguments , with the following behavior : * import the given expression contained in the file of the first argument , and return a function . this function returns a package derivation that uses the inputs pattern . * determine the name of the arguments to the function ( i . e . , the names of the inputs to the package derivation ) . * pass default arguments from the repository set , and let us override those arguments if we wish to customize the package derivation . implementing callpackage in this section , we will build up the callpackages pattern from scratch . to start , we need a way to obtain the", " argument names of a function ( in this case , the function that takes \" inputs \" and produces a package derivation ) at runtime . this is because we want to automatically pass such arguments . nix provides a builtin function to do this : nix - repl > add = { a ? 3 , b } : a + b nix - repl > builtins . functionargs add { a = true ; b = false ; } in addition to returning the argument names , the attribute set returned by functionargs indicates whether or not the argument has a default value . for our purposes , we are only interested in the argument names ;", " we do not care about the default values right now . the next step is to make callpackage automatically pass inputs to our package derivations based on the argument names we ' ve just obtained with functionargs . to do this , we need two things : * a package repository set containing package derivations that match the arguments names we ' ve obtained * a way to obtain an auto - populated attribute set combining the package repository and the return value of functionargs . the former is easy : we just have to set our package derivation ' s inputs to be package names in a repository , such as nixpkgs . for the latter", " , nix provides another builtin function : nix - repl > values = { a = 3 ; b = 5 ; c = 10 ; } nix - repl > builtins . intersectattrs values ( builtins . functionargs add ) { a = true ; b = false ; } nix - repl > builtins . intersectattrs ( builtins . functionargs add ) values { a = 3 ; b = 5 ; } the intersectattrs returns an attribute set whose names are the intersection of both arguments ' attribute names , with the attribute values taken from the second argument . this is all we need to do", " : we have obtained the argument names from a function , and populated these with an existing set of attributes . this is our simple implementation of callpackage : nix - repl > callpackage = set : f : f ( builtins . intersectattrs ( builtins . functionargs f ) set ) nix - repl > callpackage values add 8 nix - repl > with values ; add { inherit a b ; } 8 let ' s dissect the above snippet : * we define a callpackage variable which is a function . * the first parameter to the callpackage function is a set", " of name - value pairs that may appear in the argument set of the function we wish to \" autocall \" . * the second parameter is the function to \" autocall \" * we take the argument names of the function and intersect with the set of all values . * finally , we call the passed function f with the resulting intersection . in the snippet above , we ' ve also demonstrated that the callpackage call is equivalent to directly calling add a b . we achieved most of what we wanted : to automatically call functions given a set of possible arguments . if an argument is not found within the set we used to call", " the function , then we receive an error ( unless the function has variadic arguments denoted with . . . , as explained in the 5th pill ) . the last missing piece is allowing users to override some of the parameters . we may not want to always call functions with values taken from the big set . thus , we add a third parameter which takes a set of overrides : nix - repl > callpackage = set : f : overrides : f ( ( builtins . intersectattrs ( builtins . functionargs f ) set ) / / overrides ) nix - repl > callpack", "age values add { } 8 nix - repl > callpackage values add { b = 12 ; } 15 apart from the increasing number of parentheses , it should be clear that we simply take a set union between the default arguments and the overriding set . using callpackage to simplify the repository given our callpackages , we can simplify the repository expression in default . nix : let nixpkgs = import < nixpkgs > { } ; allpkgs = nixpkgs / / pkgs ; callpackage = path : overrides : let f = import path ; in f", " ( ( builtins . intersectattrs ( builtins . functionargs f ) allpkgs ) / / overrides ) ; pkgs = with nixpkgs ; { mkderivation = import . / autotools . nix nixpkgs ; hello = callpackage . / hello . nix { } ; graphviz = callpackage . / graphviz . nix { } ; graphvizcore = callpackage . / graphviz . nix { gdsupport = false ; } ; } ; in pkgs let ' s examine this in detail : * the", " expression above defines our own package repository , which we call pkgs , that contains hello along with our two variants of graphviz . * in the let expression , we import nixpkgs . note that previously , we referred to this import with the variable pkgs , but now that name is taken by the repository we are creating ourselves . * we needed a way to pass pkgs to callpackage somehow . instead of returning the set of packages directly from default . nix , we first assign it to a let variable and reuse it in callpackage . * for convenience , in callpackage we first import", " the file instead of calling it directly . otherwise we would have to write the import for each package . * since our expressions use packages from nixpkgs , in callpackage we use allpkgs , which is the union of nixpkgs and our packages . * we moved mkderivation into pkgs itself , so that it also gets passed automatically . note how easily we overrode arguments in the case of graphviz without gd . in addition , note how easy it was to merge two repositories : nixpkgs and our pkgs ! the reader should notice a magic thing", " happening . we ' re defining pkgs in terms of callpackage , and callpackage in terms of pkgs . that magic is possible thanks to lazy evaluation : builtins . intersectattrs doesn ' t need to know the values in allpkgs in order to perform intersection , only the keys that do not require callpackage evaluation . conclusion the \" callpackage \" pattern has simplified our repository considerably . we were able to import packages that require named arguments and call them automatically , given the set of all packages sourced from nixpkgs . we ' ve also introduced some useful builtin functions that allows us", " to introspect nix functions and manipulate attributes . these builtin functions are not usually used when packaging software , but rather act as tools for packaging . they are documented in the nix manual . writing a repository in nix is an evolution of writing convenient functions for combining the packages . this pill demonstrates how nix can be a generic tool to build and deploy software , and how suitable it is to create software repositories with our own conventions . next pill in the next pill , we will talk about the \" override \" design pattern . the graphvizcore seems straightforward . it starts from graphviz . nix and builds it without g", "d . in the next pill , we will consider another point of view : starting from pkgs . graphviz and disabling gd ?", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ generic builders welcome to the 8th nix pill . in the previous 7th pill we successfully built a derivation . we wrote a builder script that compiled a c file and installed the binary under the nix store . in this post , we will", " generalize the builder script , write a nix expression for gnu helloworld and create a wrapper around the derivation built - in function . packaging gnu helloworld in the previous pill we packaged a simple . c file , which was being compiled with a raw gcc call . that ' s not a good example of a project . many use autotools , and since we ' re going to generalize our builder , it would be better to do it with the most used build system . gnu helloworld , despite its name , is a simple yet complete project which uses autotools . fetch the latest tarball here : https : /", " / ftp . gnu . org / gnu / hello / hello - 2 . 12 . 1 . tar . gz . let ' s create a builder script for gnu helloworld , hello _ builder . sh : export path = \" $ gnutar / bin : $ gcc / bin : $ gnumake / bin : $ coreutils / bin : $ gawk / bin : $ gzip / bin : $ gnugrep / bin : $ gnused / bin : $ bintools / bin \" tar - xzf $ src cd hello - 2 . 12 . 1 . / configur", "e - - prefix = $ out make make install and the derivation hello . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" hello \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / hello _ builder . sh ] ; inherit ( pkgs ) gnutar gzip gnumake gcc coreutils gawk gnused gnugrep ; bintools = pkgs . binutils . bintools ; src = . / hello - 2 . 12 . 1 . tar", " . gz ; system = builtins . currentsystem ; } nix on darwin darwin ( i . e . macos ) builds typically use clang rather than gcc for a c compiler . we can adapt this early example for darwin by using this modified version of hello . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" hello \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / hello _ builder . sh ] ; inherit ( pkgs ) gnutar gzip gnumake coreuti", "ls gawk gnused gnugrep ; gcc = pkgs . clang ; bintools = pkgs . clang . bintools . bintools _ bin ; src = . / hello - 2 . 12 . 1 . tar . gz ; system = builtins . currentsystem ; } later , we will show how nix can automatically handle these differences . for now , please be just aware that changes similar to the above may be needed in what follows . now build it with nix - build hello . nix and you can launch result / bin / hello . nothing easier , but do we have", " to create a builder . sh for each package ? do we always have to pass the dependencies to the derivation function ? please note the - - prefix = $ out we were talking about in the previous pill . a generic builder let ' s create a generic builder . sh for autotools projects : set - e unset path for p in $ buildinputs ; do export path = $ p / bin $ { path : + : } $ path done tar - xf $ src for d in * ; do if [ - d \" $ d \" ] ; then cd \" $ d \" break fi done . / con", "figure - - prefix = $ out make make install what do we do here ? 1 . exit the build on any error with set - e . 2 . first unset path , because it ' s initially set to a non - existent path . 3 . we ' ll see this below in detail , however for each path in $ buildinputs , we append bin to path . 4 . unpack the source . 5 . find a directory where the source has been unpacked and cd into it . 6 . once we ' re set up , compile and install . as you can see , there ' s no", " reference to \" hello \" in the builder anymore . it still makes several assumptions , but it ' s certainly more generic . now let ' s rewrite hello . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" hello \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / builder . sh ] ; buildinputs = with pkgs ; [ gnutar gzip gnumake gcc coreutils gawk gnused gnugrep binutils . bintools ] ; src", " = . / hello - 2 . 12 . 1 . tar . gz ; system = builtins . currentsystem ; } all clear , except that buildinputs . however it ' s easier than any black magic you are thinking of at this moment . nix is able to convert a list to a string . it first converts the elements to strings , and then concatenates them separated by a space : nix - repl > builtins . tostring 123 \" 123 \" nix - repl > builtins . tostring [ 123 456 ] \" 123 456 \" recall that derivations can be converted to", " a string , hence : nix - repl > : l < nixpkgs > added 3950 variables . nix - repl > builtins . tostring gnugrep \" / nix / store / g5gdylclfh6d224kqh9sja290pk186xd - gnugrep - 2 . 14 \" nix - repl > builtins . tostring [ gnugrep gnused ] \" / nix / store / g5gdylclfh6d224kqh9sja290pk186xd - gnu", "grep - 2 . 14 / nix / store / krgdc4sknzpw8iyk9p20lhqfd52kjmg0 - gnused - 4 . 2 . 2 \" simple ! the buildinputs variable is a string with out paths separated by space , perfect for bash usage in a for loop . a more convenient derivation function we managed to write a builder that can be used for multiple autotools projects . but in the hello . nix expression we are specifying tools that are common to more projects ; we don ' t want to pass them every time . a natural approach would be", " to create a function that accepts an attribute set , similar to the one used by the derivation function , and merge it with another attribute set containing values common to many projects . create autotools . nix : pkgs : attrs : let defaultattrs = { builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / builder . sh ] ; baseinputs = with pkgs ; [ gnutar gzip gnumake gcc coreutils gawk gnused gnugrep binutils . bintools ] ; buildinputs =", " [ ] ; system = builtins . currentsystem ; } ; in derivation ( defaultattrs / / attrs ) ok now we have to remember a little about nix functions . the whole nix expression of this autotools . nix file will evaluate to a function . this function accepts a parameter pkgs , then returns a function which accepts a parameter attrs . the body of the function is simple , yet at first sight it might be hard to grasp : 1 . first drop in the scope the magic pkgs attribute set . 2 . within a let expression we define a helper variable , defaultattrs ,", " which serves as a set of common attributes used in derivations . 3 . finally we create the derivation with that strange expression , ( defaultattrs / / attrs ) . the / / operator is an operator between two sets . the result is the union of the two sets . in case of conflict s between attribute names , the value on the right set is preferred . so we use defaultattrs as base set , and add ( or override ) the attributes from attrs . a couple of examples ought to be enough to clear out the behavior of the operator : nix - repl > { a = \" b \"", " ; } / / { c = \" d \" ; } { a = \" b \" ; c = \" d \" ; } nix - repl > { a = \" b \" ; } / / { a = \" c \" ; } { a = \" c \" ; } exercise : complete the new builder . sh by adding $ baseinputs in the for loop together with $ buildinputs . as you noticed , we passed that new variable in the derivation . instead of merging buildinputs with the base ones , we prefer to preserve buildinputs as seen by the caller , so we keep them separated", " . just a matter of choice . then we rewrite hello . nix as follows : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name = \" hello \" ; src = . / hello - 2 . 12 . 1 . tar . gz ; } finally ! we got a very simple descript ion of a package ! below are a couple of remarks that you may find useful as you ' re continuing to understand the nix language : * we assigned to pkgs the import that we did in the", " previous expressions in the \" with \" . don ' t be afraid , it ' s that straightforward . * the mkderivation variable is a nice example of partial application , look at it as ( import . / autotools . nix ) pkgs . first we import the expression , then we apply the pkgs parameter . that will give us a function that accepts the attribute set attrs . * we create the derivation specifying only name and src . if the project eventually needed other dependencies to be in path , then we would simply add those to buildinputs ( not specified in hello . nix because empty", " ) . note we didn ' t use any other library . special c flags may be needed to find include files of other libraries at compile time , and ld flags at link time . conclusion nix gives us the bare metal tools for creating derivations , setting up a build environment and storing the result in the nix store . out of this pill we managed to create a generic builder for autotools projects , and a function mkderivation that composes by default the common components used in autotools projects instead of repeating them in all the packages we would write . we are familiarizing ourselves with the way a nix system grows up : it", " ' s about creating and composing derivations with the nix language . analogy : in c you create objects in the heap , and then you compose them inside new objects . pointers are used to refer to other objects . in nix you create derivations stored in the nix store , and then you compose them by creating new derivations . store paths are used to refer to other derivations . next pill . . . we will talk a little about runtime dependencies . is the gnu helloworld package self - contained ? what are its runtime dependencies ? we only specified build dependencies by means of using other derivations in the \" hello", " \" derivation .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ our first derivation welcome to the sixth nix pill . in the previous fifth pill we introduced functions and imports . functions and imports are very simple concepts that allow forbuilding complex abstractions and composition of modules to build a flexible nix system .", " in this post we finally arrived to writing a derivation . derivations are thebuilding blocks of a nix system , from a file system view point . the nix language is used to describe such derivations . i remind you how to enter the nix environment : source ~ / . nix - profile / etc / profile . d / nix . sh the derivation function the derivation built - in function is used to create derivations . i invite you to read the link in the nix manual about the derivation built - in . a derivation from a nix language view point is simply a set , with some attributes . therefore you can pass the derivation around with variables", " like anything else . that ' s where the real power comes in . the derivation function receives a set as its first argument . this set requires at least the following three attributes : * name : the name of the derivation . in the nix store the format is hash - name , that ' s the name . * system : is the name of the system in which the derivation can be built . for example , x86 _ 64 - linux . * builder : is the binary program that builds the derivation . first of all , what ' s the name of our system as seen by nix ? nix - repl > builtins . currentsystem", " \" x86 _ 64 - linux \" let ' s try to fake the name of the system : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system = \" mysystem \" ; } nix - repl > d \u00ab derivation / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv \u00bb oh oh , what ' s that ? did it build the derivation ? no it didn ' t , but it did create the . drv", " file . nix repl does not build derivations unless you tell it to do so . digression about . drv files what ' s that . drv file ? it is the specification of how to build the derivation , without all the nix language fuzz . before continuing , some analogies with the c language : * . nix files are like . c files . * . drv files are intermediate files like . o files . the . drv describe s how to build a derivation ; it ' s the bare minimum information . * out paths are then the product of the build . both drv paths and out paths are", " stored in the nix store as you can see . what ' s in that . drv file ? you can read it , but it ' s better to pretty print it : note : if your version of nix doesn ' t have nix derivation show , use nix show - derivation instead . $ nix derivation show / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv { \" / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754", "p - myname . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" } } , \" inputsrcs \" : [ ] , \" inputdrvs \" : { } , \" platform \" : \" mysystem \" , \" builder \" : \" mybuilder \" , \" args \" : [ ] , \" env \" : { \" builder \" : \" mybuilder \" , \" name \" : \"", " myname \" , \" out \" : \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" , \" system \" : \" mysystem \" } } } ok , we can see there ' s an out path , but it does not exist yet . we never told nix to build it , but we know beforehand where the build output will be . why ? think , if nix ever built the derivation just because we accessed it in nix , we would have to wait a long time if it was , say , firefox . that", " ' s why nix let us know the path beforehand and kept evaluating the nix expressions , but it ' s still empty because no build was ever made . important : the hash of the out path is based solely on the input derivations in the current version of nix , not on the contents of the build product . it ' s possible however to have content - addressable derivations for e . g . tarballs as we ' ll see later on . many things are empty in that . drv , however i ' ll write a summary of the . drv format for you : 1 . the output paths ( there can be multiple ones )", " . by default nix creates one out path called \" out \" . 2 . the list of input derivations . it ' s empty because we are not referring to any other derivation . otherwise , there would be a list of other . drv files . 3 . the system and the builder executable ( yes , it ' s a fake one ) . 4 . then a list of environment variables passed to the builder . that ' s it , the minimum necessary information to build our derivation . important note : the environment variables passed to the builder are just those you see in the . drv plus some other nix related configuration ( number of cores", " , temp dir , . . . ) . the builder will not inherit any variable from your running shell , otherwise builds would suffer from non - determinism . back to our fake derivation . let ' s build our really fake derivation : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system = \" mysystem \" ; } nix - repl > : b d [ . . . ] these derivations will be built : / nix / store / z3hhlxbckx4g3n9sw91nnvlkj", "vyw754p - myname . drvbuilding path ( s ) ` / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname ' error : a ` mysystem ' is required to build ` / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv ' , but i am a ` x86 _ 64 - linux ' the : b is a nix repl specific command to build a derivation . you can", " see more commands with : ? . so in the output you can see that it takes the . drv as information on how to build the derivation . then it says it ' s trying to produce our out path . finally the error we were waiting for : that derivation can ' t be built on our system . we ' re doing the build inside nix repl , but what if we don ' t want to use nix repl ? you can realise a . drv with : $ nix - store - r / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvy", "w754p - myname . drv you will get the same output as before . let ' s fix the system attribute : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system = builtins . currentsystem ; } nix - repl > : b d [ . . . ] build error : invalid file name ` mybuilder ' a step forward : of course , that mybuilder executable does not really exist . stop for a moment . what ' s in a derivation set it is useful to start by inspecting the return", " value from the derivation function . in this case , the returned value is a plain set : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system = \" mysystem \" ; } nix - repl > builtins . isattrs d true nix - repl > builtins . attrnames d [ \" all \" \" builder \" \" drvattrs \" \" drvpath \" \" name \" \" out \" \" outpath \" \" outputname \" \" system \" \" type \" ] you can guess what builtins . isattrs", " does ; it returns true if the argument is a set . while builtins . attrnames returns a list of keys of the given set . some kind of reflection , you might say . start from drvattrs : nix - repl > d . drvattrs { builder = \" mybuilder \" ; name = \" myname \" ; system = \" mysystem \" ; } that ' s basically the input we gave to the derivation function . also the d . name , d . system and d . builder attributes are exactly the ones we gave as input . nix - repl > ( d =", " = d . out ) true so out is just the derivation itself , it seems weird but the reason is that we only have one output from the derivation . that ' s also the reason why d . all is a singleton . we ' ll see multiple outputs later . the d . drvpath is the path of the . drv file : / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv . something interesting is the type attribute . it ' s \" derivation \" . nix does add a little of magic to", " sets with type derivation , but not that much . to help you understand , you can create yourself a set with that type , it ' s a simple set : nix - repl > { type = \" derivation \" ; } \u00ab derivation ? ? ? \u00bb of course it has no other information , so nix doesn ' t know what to say : - ) but you get it , the type = \" derivation \" is just a convention for nix and for us to understand the set is a derivation . when writing packages , we are interested in the outputs . the other metadata is needed for nix to know how to create the drv path and the", " out path . the outpath attribute is the build path in the nix store : / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname . referring to other derivations just like dependencies in other package managers , how do we refer to other packages ? how do we refer to other derivations in terms of files on the disk ? we use the outpath . the outpath describe s the location of the files of that derivation . to make it more convenient , nix is able to do a conversion from a derivation set to a string . nix -", " repl > d . outpath \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" nix - repl > builtins . tostring d \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" nix does the \" set to string conversion \" as long as there is the outpath attribute ( much like a tostring method in other languages ) : nix - repl > builtins . tostring { outpath = \"", " foo \" ; } \" foo \" nix - repl > builtins . tostring { a = \" b \" ; } error : cannot coerce a set to a string , at ( string ) : 1 : 1 say we want to use binaries from coreutils ( ignore the nixpkgs etc . ) : nix - repl > : l < nixpkgs > added 3950 variables . nix - repl > coreutils \u00ab derivation / nix / store / 1zcs1y4n27lqs0gw4v038i303pb89rw6", " - coreutils - 8 . 21 . drv \u00bb nix - repl > builtins . tostring coreutils \" / nix / store / 8w4cbiy7wqvaqsnsnb3zvabq1cp2zhyz - coreutils - 8 . 21 \" apart from the nixpkgs stuff , just think we added to the scope a series of variables . one of them is coreutils . it is the derivation of the coreutils package you all know of from other linux distributions . it contains basic binaries for gnu / linux systems ( you may have multiple", " derivations of coreutils in the nix store , no worries ) : $ ls / nix / store / * coreutils * / bin [ . . . ] i remind you , inside strings it ' s possible to interpolate nix expressions with $ { . . . } : nix - repl > \" $ { d } \" \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" nix - repl > \" $ { coreutils } \" \" / nix / store / 8w4cbiy7wq", "vaqsnsnb3zvabq1cp2zhyz - coreutils - 8 . 21 \" that ' s very convenient , because then we could refer to e . g . the bin / true binary like this : nix - repl > \" $ { coreutils } / bin / true \" \" / nix / store / 8w4cbiy7wqvaqsnsnb3zvabq1cp2zhyz - coreutils - 8 . 21 / bin / true \" an almost working derivation in the previous attempt we used a fake builder , mybuilder which", " obviously does not exist . but we can use for example bin / true , which always exits with 0 ( success ) . nix - repl > : l < nixpkgs > nix - repl > d = derivation { name = \" myname \" ; builder = \" $ { coreutils } / bin / true \" ; system = builtins . currentsystem ; } nix - repl > : b d [ . . . ] builder for ` / nix / store / qyfrcd53wmc0v22ymhhd5r6sz5xmdc8a - myname . drv", " ' failed to produce output path ` / nix / store / ly2k1vswbfmswr33hw0kf0ccilrpisnk - myname ' another step forward , it executed the builder ( bin / true ) , but the builder did not create the out path of course , it just exited with 0 . obvious note : every time we change the derivation , a new hash is created . let ' s examine the new . drv now that we referred to another derivation : $ nix derivation show / nix / store / qyfrcd53wmc0v22ymhhd5r6sz", "5xmdc8a - myname . drv { \" / nix / store / qyfrcd53wmc0v22ymhhd5r6sz5xmdc8a - myname . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / ly2k1vswbfmswr33hw0kf0ccilrpisnk - myname \" } } , \" inputsrcs \" : [ ] , \" inputdrvs \" : { \" / nix / store / hixdnzz2w", "p75x1jy65cysq06yl74vx7q - coreutils - 8 . 29 . drv \" : [ \" out \" ] } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / qrxs7sabhqcr3j9ai0j0cp58zfnny0jz - coreutils - 8 . 29 / bin / true \" , \" args \" : [ ] , \" env \" : { \" builder \" : \" / nix / store / qrx", "s7sabhqcr3j9ai0j0cp58zfnny0jz - coreutils - 8 . 29 / bin / true \" , \" name \" : \" myname \" , \" out \" : \" / nix / store / ly2k1vswbfmswr33hw0kf0ccilrpisnk - myname \" , \" system \" : \" x86 _ 64 - linux \" } } } aha ! nix added a dependency to our myname . drv , it ' s the coreutils . drv . before doing our build , nix", " should build the coreutils . drv . but since coreutils is already in our nix store , no build is needed , it ' s already there with out path / nix / store / qrxs7sabhqcr3j9ai0j0cp58zfnny0jz - coreutils - 8 . 29 . when is the derivation built nix does not build derivations during evaluation of nix expressions . in fact , that ' s why we have to do \" : b drv \" in nix repl , or use nix - store - r in the first place . an important separation", " is made in nix : * instantiate / evaluation time : the nix expression is parsed , interpreted and finally returns a derivation set . during evaluation , you can refer to other derivations because nix will create . drv files and we will know out paths beforehand . this is achieved with nix - instantiate . * realise / build time : the . drv from the derivation set is built , firstbuilding . drv inputs ( build dependencies ) . this is achieved with nix - store - r . think of it as of compile time and link time like with c / c + + projects . you first compile all source files", " to object files . then link object files in a single executable . in nix , first the nix expression ( usually in a . nix file ) is compiled to . drv , then each . drv is built and the product is installed in the relative out paths . conclusion is it that complicated to create a package for nix ? no , it ' s not . we ' re walking through the fundamentals of nix derivations , to understand how they work , how they are represented . packaging in nix is certainly easier than that , but we ' re not there yet in this post . more nix pills are needed . with the derivation function", " we provide a set of information on how to build a package , and we get back the information about where the package was built . nix converts a set to a string when there ' s an outpath ; that ' s very convenient . with that , it ' s easy to refer to other derivations . when nix builds a derivation , it first creates a . drv file from a derivation expression , and uses it to build the output . it does so recursively for all the dependencies ( inputs ) . it \" executes \" the . drv files like a machine . not much magic after all . next pill . . .", " we will finally write our first working derivation . yes , this post is about \" our first derivation \" , but i never said it was a working one ; )", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the garbage collector welcome to the 11th nix pill . in the previous 10th pill , we drew a parallel between the isolated build environment provided by nix - build and the isolated development shell provided by nix - shell . using nix - shell allowed", " us to debug , modify , and manually build software using an environment that is almost identical to the one provided by nix - build . today , we will stop focusing on packaging and instead look at a critical component of nix : the garbage collector . when we use nix tools , we are oftenbuilding derivations . this includes . drv files as well as out paths . these artifacts go in the nix store and take up space in our storage . eventually we may wish to free up some space by removing derivations we no longer need . this is the focus of the 11th pill . by default , nix takes a relatively conservative approach when automatically", " deciding which derivations are \" needed \" . in this pill , we will also see a technique to conduct more destruct ive upgrade and deletion operations . how does garbage collection work ? programming languages with garbage collectors use the concept of a set of \" garbage collector ( or ' gc ' ) roots \" to keep track of \" live \" objects . a gc root is an object that is always considered \" live \" ( unless explicitly removed as gc root ) . the garbage collection process starts from the gc roots and proceeds by recursively marking object references as \" live \" . all other objects can be collected and deleted", " . instead of objects , nix ' s garbage collection operates on store paths , with the gc roots themselves being store paths . . this approach is much more principled than traditional package managers such as dpkg or rpm , which may leave around unused packages or dangling files . the implementation is very simple and transparent to the user . the primary gc roots are stored under / nix / var / nix / gcroots . if there is a symlink to a store path , then the linked store path is a gc root . nix allows this directory to have subdirectories : it will simply recursively", " traverse the subdirectories in search of symlinks to store paths . when a symlink is encountered , its target is added to the list of live store paths . in summary , nix maintains a list of gc roots . these roots can then be used to compute a list of all live store paths . any other store paths are considered dead . deleting these paths is now straightforward . nix first moves dead store paths to / nix / store / trash , which is an atomic operation . afterwards , the trash is emptied . playing with the gc before we begin we first run the nix garbage collector so that we", " have a clean setup for our experiments : $ nix - collect - garbage finding garbage collector roots . . . [ . . . ] deleting unused links . . . note : currently hard linking saves - 0 . 00 mib 1169 store paths deleted , 228 . 43 mib freed if we run the garbage collector again it won ' t find anything new to delete , as we expect . after running the garbage collector , the nix store only contains paths with references from the gc roots . we now install a new program , bsd - games , inspect its store path , and examine its gc root . the nix - store", " - q - - roots command is used to query the gc roots that refer to a given derivation . in this case , our current user environment refers to bsd - games : $ nix - env - ia nixpkgs . bsdgames $ readlink - f ` which fortune ` / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 . 17 / bin / fortune $ nix - store - q - - roots ` which fortune ` / nix / var / nix / profiles / default - 9 -", " link $ nix - env - - list - generations [ . . . ] 9 2014 - 08 - 20 12 : 44 : 14 ( current ) now we remove it and run the garbage collector , and note that bsd - games is still in the nix store : $ nix - env - e bsd - games uninstalling ` bsd - games - 2 . 17 ' $ nix - collect - garbage [ . . . ] $ ls / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games -", " 2 . 17 bin share the old generation is still in the nix store because it is a gc root . as we will see below , all profiles and their generations are automatically gc roots . removing a gc root is simple . in our case , we delete the generation that refers to bsd - games , run the garbage collector , and note that bsd - games is no longer in the nix store : $ rm / nix / var / nix / profiles / default - 9 - link $ nix - env - - list - generations [ . . . ] 8 2014 - 07 - 28 10 : 23 : 24 10 2014", " - 08 - 20 12 : 47 : 16 ( current ) $ nix - collect - garbage [ . . . ] $ ls / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 . 17 ls : cannot access / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 . 17 : no such file or directory note : nix - env - - list - generations does not rely on", " any particular metadata . it is able to list generations based solely on the file names under the profiles directory . note that we removed the link from / nix / var / nix / profiles , not from / nix / var / nix / gcroots . in addition to the latter , nix treats / nix / var / nix / profiles as a gc root . this is useful because it means that any profile and its generations are gc roots . other paths are considered gc roots as well ; for example , / run / booted - system on nixos . the command nix - store - - gc - - print - roots", " prints all paths considered as gc roots when running the garbage collector . indirect roots recall thatbuilding the gnu hello package with nix - build produces a result symlink in the current directory . despite the garbage collection done above , the hello program is still working . therefore , it has not been garbage collected . since there is no other derivation that depends upon the gnu hello package , it must be a gc root . in fact , nix - build automatically adds the result symlink as a gc root . note that this is not the built derivation , but the symlink itself . these gc roots are added under / nix /", " var / nix / gcroots / auto . $ ls - l / nix / var / nix / gcroots / auto / total 8 drwxr - xr - x 2 nix nix 4096 aug 20 10 : 24 . / drwxr - xr - x 3 nix nix 4096 jul 24 10 : 38 . . / lrwxrwxrwx 1 nix nix 16 jul 31 10 : 51 xlgz5x2ppa0m72z5qfc78b8wlciwvgiz - > / home / nix /", " result / the name of the gc root symlink is not important to us at this time . what is important is that such a symlink exists and points to / home / nix / result . this is called an indirect gc root . a gc root is considered indirect if its specification is outside of / nix / var / nix / gcroots . in this case , this means that the target of the result symlink will not be garbage collected . to remove a derivation considered \" live \" by an indirect gc root , there are two possibilities : * remove the indirect gc root from / nix /", " var / nix / gcroots / auto . * remove the result symlink . in the first case , the derivation will be deleted from the nix store during garbage collection , and result becomes a dangling symlink . in the second case , the derivation is removed as well as the indirect root in / nix / var / nix / gcroots / auto . running nix - collect - garbage after deleting the gc root or the indirect gc root will remove the derivation from the store . cleanup everything the main source of software duplication in the nix store comes from gc roots , due to nix - build", " and profile generations . running nix - build results in a gc root for the build that refers to a specific version of specific libraries , such as glibc . after an upgrade , we must delete the previous build if we want the garbage collector to remove the corresponding derivation , as well as if we want old dependencies cleaned up . the same holds for profiles . manipulating the nix - env profile will create further generations . old generations refer to old software , thus increasing duplication in the nix store after an upgrade . other systems typically \" forget \" everything about their previous state after an upgrade . with nix , we can perform this type", " of upgrade ( having nix remove all old derivations , including old generations ) , but we do so manually . there are four steps to doing this : * first , we download a new version of the nixpkgs channel , which holds the descript ion of all the software . this is done via nix - channel - - update . * then we upgrade our installed packages with nix - env - u . this will bring us into a new generation with updated software . * then we remove all the indirect roots generated by nix - build : beware , as this will result in dangling symlinks . a smarter strategy would also", " remove the target of those symlinks . * finally , the - d option of nix - collect - garbage is used to delete old generations of all profiles , then collect garbage . after this , you lose the ability to rollback to any previous generation . it is important to ensure the new generation is working well before running this command . the four steps are shown below : $ nix - channel - - update $ nix - env - u - - always $ rm / nix / var / nix / gcroots / auto / * $ nix - collect - garbage - d conclusion garbage collection in nix is a powerful mechanism to", " clean up your system . the nix - store commands allow us to know why a certain derivation is present in the nix store , and whether or not it is eligible for garbage collection . we also saw how to conduct more destruct ive deletion and upgrade operations . next pill in the next pill , we will package another project and introduce the \" inputs \" design pattern . we ' ve only played with a single derivation until now ; however we ' d like to start organizing a small repository of software . the \" inputs \" pattern is widely used in nixpkgs ; it allows us to decouple derivations from the repository itself", " and increase customization opportunities .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ package repositories and the inputs design pattern welcome to the 12th nix pill . in the previous 11th pill , we stopped packaging and cleaned up the system with the garbage collector . this time , we will resume packaging and improve different", " aspects of it . we will also demonstrate how to create a repository of multiple packages . repositories in nix package repositories in nix arose naturally from the need to organize packages . there is no preset directory struct ure or packaging policy prescribe d by nix itself ; nix , as a full , functional programming language , is powerful enough to support multiple different repository formats . over time , the nixpkgs repository evolved a particular struct ure . this struct ure reflects the history of nix as well as the design patterns adopted by its users as useful tools inbuilding and organizing packages . below , we", " will examine some of these patterns in detail . the single repository pattern different operating system distributions have different opinions about how package repositories should be organized . systems like debian scatter packages in several small repositories ( which tends to make tracking interdependent changes more difficult , and hinders contributions to the repositories ) ,while systems like gentoo put all package descript ions in a single repository . nix follows the \" single repository \" pattern by placing all descript ions of all packages into nixpkgs . this approach has proven natural and attractive for new contributions . for the rest of this pill", " , we will adopt the single repository pattern . the natural implementation in nix is to create a top - level nix expression , followed by one expression for each package . the top - level expression imports and combines all package expressions in an attribute set mapping names to packages . in some programming languages , such an approach - - including every possible package descript ion in a single data struct ure - - would be untenable due to the language needing to load the entire data struct ure into memory before operating on it . nix , however , is a lazy language and only evaluates what is needed . packaging graphviz we have already", " packaged gnu hello . next , we will package a graph - drawing program called graphviz so that we can create a repository containing multiple packages . the graphviz package was selected because it uses the standard autotools build system and requires no patching . it also has optional dependencies , which will give us an opportunity to illustrate a technique to configure builds to a particular situation . first , we download graphviz from gitlab . the graphviz . nix expression is straightforward : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools .", " nix pkgs ; in mkderivation { name = \" graphviz \" ; src = . / graphviz - 2 . 49 . 3 . tar . gz ; } if we build the project with nix - build graphviz . nix , we will get runnable binaries under result / bin . notice how we reused the same autotools . nix of hello . nix . by default , graphviz does not compile with the ability to produce png files . thus , the derivation above will build a binary supporting only the native output formats , as we see below : $ echo ' graph test {", " a - - b } ' | result / bin / dot - tpng - o test . png format : \" png \" not recognized . use one of : canon cmap [ . . . ] if we want to produce a png file with graphviz , we must add it to our derivation . the place to do so is in autotools . nix , where we created a buildinputs variable that gets concatenated to baseinputs . this is the exact reason for this variable : to allow users of autotools . nix to add additional inputs from package expressions . version 2 . 49", " of graphviz has several plugins to output png . for simplicity , we will use libgd . passing library information to pkg - config via environment variables the graphviz configuration script uses pkg - config to specify which flags are passed to the compiler . since there is no global location for libraries , we need to tell pkg - config where to find its descript ion files , which tell the configuration script where to find headers and libraries . in classic posix systems , pkg - config just finds the . pc files of", " all installed libraries in system folders like / usr / lib / pkgconfig . however , these files are not present in the isolated environments presented to nix . as an alternative , we can inform pkg - config about the location of libraries via the pkg _ config _ path environment variable . we can populate this environment variable using the same trick we used for path : automatically filling the variables from buildinputs . this is the relevant snippet of setup . sh : for p in $ baseinputs $ buildinputs ; do if [ - d $", " p / bin ] ; then export path = \" $ p / bin $ { path : + : } $ path \" fi if [ - d $ p / lib / pkgconfig ] ; then export pkg _ config _ path = \" $ p / lib / pkgconfig $ { pkg _ config _ path : + : } $ pkg _ config _ path \" fi done now if we add derivations to buildinputs , their lib / pkgconfig and bin paths are automatically added in setup . sh", " . completing graphviz with gd below , we finish the expression for graphviz with gd support . note the use of the with expression in buildinputs to avoid repeating pkgs : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name = \" graphviz \" ; src = . / graphviz - 2 . 49 . 3 . tar . gz ; buildinputs = with pkgs ; [ pkg - config ( pkgs", " . lib . getlib gd ) ( pkgs . lib . getdev gd ) ] ; } we add pkg - config to the derivation to make this tool available for the configure script . as gd is a package with split outputs , we need to add both the library and development outputs . afterbuilding , graphviz can now create pngs . the repository expression now that we have two packages , we want to combine them into a single repository . to do so , we ' ll mimic what nixpkgs does : we will create a single attribute set containing", " derivations . this attribute set can then be imported , and derivations can be selected by accessing the top - level attribute set . using this technique we are able to abstract from the file names . instead of referring to a package by repo / some / sub / dir / package . nix , this technique allows us to select a derivation as importedrepo . package ( or pkgs . package in our examples ) . to begin , create a default . nix in the current directory : { hello = import . / hello . nix ; graphviz = import . / graphviz . nix ; } this file is ready to", " use with nix repl : $ nix repl nix - repl > : l default . nix added 2 variables . nix - repl > hello \u00ab derivation / nix / store / dkib02g54fpdqgpskswgp6m7bd7mgx89 - hello . drv \u00bb nix - repl > graphviz \u00ab derivation / nix / store / zqv520v9mk13is0w980c91z7q1vkhhil - graphviz . drv \u00bb with nix - build , we can pass the - a option to", " access an attribute of the set from the given . nix expression : $ nix - build default . nix - a hello [ . . . ] $ result / bin / hello hello ,world ! the default . nix file is special . when a directory contains a default . nix file , it is used as the implicit nix expression of the directory . this , for example , allows us to run nix - build - a hello without specifying default . nix explicitly . we can now use nix - env to install the package into our user environment : $ nix - env - f . - ia graphviz [ . . . ] $ dot", " - v taking a closer look at the above command , we see the following options : * the - f option is used to specify the expression to use . in this case , the expression is the . / default . nix of the current directory . * the - i option stands for \" installation \" . * the - a is the same as above for nix - build . we reproduced the very basic behavior of nixpkgs : combining multiple derivations into a single , top - level attribute set . the inputs pattern the approach we ' ve taken so far has a few problems : * first , hello . nix and graphviz . nix", " are dependent on nixpkgs , which they import directly . a better approach would be to pass in nixpkgs as an argument , as we did in autotools . nix . * second , we don ' t have a straightforward way to compile different variants of the same software , such as graphviz with or without libgd support . * third , we don ' t have a way to test graphviz with a particular libgd version . until now , our approach to addressing the above problems has been inadequate and required changing the nix expression to match our needs . with the inputs pattern , we", " provide another answer : let the user change the inputs of the expression . when we talk about \" the inputs of an expression \" , we are referring to the set of derivations needed to build that expression . in this case : * mkderivation from autotools . recall that mkderivation has an implicit dependency on the toolchain . * libgd and its dependencies . the . / src directory is also an input , but we wouldn ' t change the source from the caller . in nixpkgs we prefer to write another expression for version bumps ( e . g . because patches or different inputs are needed", " ) . our goal is to make package expressions independent of the repository . to achieve this , we use functions to declare inputs for a derivation . for example , with graphviz . nix , we make the following changes to make the derivation independent of the repository and customizable : { mkderivation , lib , gdsupport ? true , gd , pkg - config } : mkderivation { name = \" graphviz \" ; src = . / graphviz - 2 . 49 . 3 . tar . gz ; buildinputs = if gdsupport then [ p", "kg - config ( lib . getlib gd ) ( lib . getdev gd ) ] else [ ] ; } recall that \" { . . . } : . . . \" is the syntax for defining functions accepting an attribute set as argument ; the above snippet just defines a function . we made gd and its dependencies optional . if gdsupport is true ( which it is by default ) , we will fill buildinputs and graphviz will be built with gd support . otherwise , if an attribute set is passed with gdsupport = false ; , the", " build will be completed without gd support . going back to back to default . nix , we modify our expression to utilize the inputs pattern : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in with pkgs ; { hello = import . / hello . nix { inherit mkderivation ; } ; graphviz = import . / graphviz . nix { inherit mkderivation lib gd pkg - config ; } ; graphvizcore = import . / graphviz . nix { inherit", " mkderivation lib gd pkg - config ; gdsupport = false ; } ; } we factorized the import of nixpkgs and mkderivation , and also added a variant of graphviz with gd support disabled . the result is that both hello . nix ( left as an exercise for the reader ) and graphviz . nix are independent of the repository and customizable by passing specific inputs . if we wanted to build graphviz with a specific version of gd , it would suffice to pass gd = . . . ; . if we wanted to change", " the toolchain , we would simply pass a different mkderivation function . let ' s talk a closer look at the snippet and dissect the syntax : * the entire expression in default . nix returns an attribute set with the keys hello , graphviz , and graphvizcore . * with \" let \" , we define some local variables . * we bring pkgs into the scope when defining the package set . this saves us from having to type pkgs \" repeatedly . * we import hello . nix and graphviz . nix , which each return a function . we call the functions with a set", " of inputs to get back the derivation . * the \" inherit x \" syntax is equivalent to \" x = x \" . this means that the \" inherit gd \" here , combined with the above \" with pkgs ; \" , is equivalent to \" gd = pkgs . gd \" . the entire repository of this can be found at the pill 12 gist . conclusion the \" inputs \" pattern allows our expressions to be easily customizable through a set of arguments . these arguments could be flags , derivations , or any other customizations enabled by the nix language . our package expressions are simply functions : there is no", " extra magic present . the \" inputs \" pattern also makes the expressions independent of the repository . given that we pass all needed information through arguments , it is possible to use these expressions in any other context . next pill in the next pill , we will talk about the \" callpackage \" design pattern . this removes the tedium of specifying the names of the inputs twice : once in the top - level default . nix , and once in the package expression . with callpackage , we will implicitly pass the necessary inputs from the top - level expression .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ automatic runtime dependencies welcome to the 9th nix pill . in the previous 8th pill we wrote a generic builder for autotools projects . we fed in build dependencies and a source tarball , and we received a nix derivation", " as a result . today we stop by the gnu hello program to analyze build and runtime dependencies , and we enhance our builder to eliminate unnecessary runtime dependencies . build dependencies let ' s start analyzing build dependencies for our gnu hello package : $ nix - instantiate hello . nix / nix / store / z77vn965a59irqnrrjvbspiyl2rph0jp - hello . drv $ nix - store - q - - references / nix / store / z77vn965a59irqnrrjvbspiyl2rph0j", "p - hello . drv / nix / store / 0q6pfasdma4as22kyaknk4kwx4h58480 - hello - 2 . 10 . tar . gz / nix / store / 1zcs1y4n27lqs0gw4v038i303pb89rw6 - coreutils - 8 . 21 . drv / nix / store / 2h4b30hlfw4fhqx10wwi71mpim4wr877 - gnused - 4 . 2 . 2 .", " drv / nix / store / 39bgdjissw9gyi4y5j9wanf4dbjpbl07 - gnutar - 1 . 27 . 1 . drv / nix / store / 7qa70nay0if4x291rsjr7h9lfl6pl7b1 - builder . sh / nix / store / g6a0shr58qvx2vi6815acgp9lnfh9yy8 - gnugrep - 2 . 14 . drv / nix / store / jdggv3q1sb15", "140qdx0apvyrps41m4lr - bash - 4 . 2 - p45 . drv / nix / store / pglhiyp1zdbmax4cglkpz98nspfgbnwr - gnumake - 3 . 82 . drv / nix / store / q9l257jn9lndbi3r9ksnvf4dr8cwxzk7 - gawk - 4 . 1 . 0 . drv / nix / store / rgyrqxz1ilv90r01zxl0sq", "5nq0cq7v3v - binutils - 2 . 23 . 1 . drv / nix / store / qzxhby795niy6wlagfpbja27dgsz43xk - gcc - wrapper - 4 . 8 . 3 . drv / nix / store / sk590g7fv53m3zp0ycnxsc41snc2kdhp - gzip - 1 . 6 . drv it has precisely the derivations referenced in the derivation function ; nothing more , nothing less . of course , we", " may not use some of them at all . however , given that our generic mkderivation function always pulls such dependencies ( think of it like build - essential from debian ) , we will already have these packages in the nix store for any future packages that need them . why are we looking at . drv files ? because the hello . drv file is the representation of the build action that builds the hello out path . as such , it contains the input derivations needed beforebuilding hello . digression about nar files the nar format is the \" nix archive \" . this format was designed due to existing archive formats ,", " such as tar , being insufficient . nix benefits from deterministic build tools , but commonly used archivers lack this property : they add padding , they do not sort files , they add timestamps , and so on . this can result in directories containing bit - identical files turning into non - bit - identical archives , which leads to different hashes . thus the nar format was developed as a simple , deterministic archive format . nars are used extensively within nix , as we will see below . for more rationale and implementation details behind nar see dolstra ' s phd thesis . to create nar archives", " from store paths , we can use nix - store - - dump and nix - store - - restore . runtime dependencies we now note that nix automatically recognized build dependencies once our derivation call referred to them , but we never specified the runtime dependencies . nix handles runtime dependencies for us automatically . the technique it uses to do so may seem fragile at first glance , but it works so well that the nixos operating system is built off of it . the underlying mechanism relies on the hash of the store paths . it proceeds in three steps : 1 . dump the derivation as a nar . recall that this is a serial", "ization of the derivation output - - meaning this works fine whether the output is a single file or a directory . 2 . for each build dependency . drv and its relative out path , search the contents of the nar for this out path . 3 . if the path is found , then it ' s a runtime dependency . the snippet below shows the dependencies for hello . $ nix - instantiate hello . nix / nix / store / z77vn965a59irqnrrjvbspiyl2rph0jp - hello . drv $ nix - store - r / nix /", " store / z77vn965a59irqnrrjvbspiyl2rph0jp - hello . drv / nix / store / a42k52zwv6idmf50r9lps1nzwq9khvpf - hello $ nix - store - q - - references / nix / store / a42k52zwv6idmf50r9lps1nzwq9khvpf - hello / nix / store / 94n64qy99ja0vgbkf675nyk39g9b9", "78n - glibc - 2 . 19 / nix / store / 8jm0wksask7cpf85miyakihyfch1y21q - gcc - 4 . 8 . 3 / nix / store / a42k52zwv6idmf50r9lps1nzwq9khvpf - hello we see that glibc and gcc are runtime dependencies . intuitively , gcc shouldn ' t be in this list ! displaying the printable strings in the hello binary shows that the out path of gcc does indeed appear : $ strings result /", " bin / hello | grep gcc / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib : / nix / store / 8jm0wksask7cpf85miyakihyfch1y21q - gcc - 4 . 8 . 3 / lib64 this is why nix added gcc . but why is that path present in the first place ? the answer is that it is the ld rpath : the list of directories where libraries can be found at", " runtime . in other distributions , this is usually not abused . but in nix , we have to refer to particular versions of libraries , and thus the rpath has an important role . the build process adds the gcc lib path thinking it may be useful at runtime , but this isn ' t necessary . to address issues like these , nix provides a tool called patchelf , which reduces the rpath to the paths that are actually used by the binary . even after reducing the rpath , the hello binary would still depend upon gcc because of some debugging information . this unnecessarily increases the size of", " our runtime dependencies . we ' ll explore how strip can help us with that in the next section . another phase in the builder we will add a new phase to our autotools builder . the builder has six phases already : 1 . the \" environment setup \" phase 2 . the \" unpack phase \" : we unpack the sources in the current directory ( remember , nix changes to a temporary directory first ) 3 . the \" change directory \" phase , where we change source root to the directory that has been unpacked 4 . the \" configure \" phase : . / configure 5 . the \"", " build \" phase : make 6 . the \" install \" phase : make install now we will add a new phase after the installation phase , which we call the \" fixup \" phase . at the end of the builder . sh , we append : find $ out - type f - exec patchelf - - shrink - rpath ' { } ' \\ ; - exec strip ' { } ' \\ ; 2 > / dev / null that is , for each file we run patchelf - - shrink - rpath and strip . note that we used two new commands here , find and patchelf . these must be", " added to our derivation . exercise : add findutils and patchelf to the baseinputs of autotools . nix . now , we rebuild hello . nix . . . $ nix - build hello . nix [ . . . ] $ nix - store - q - - references result / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / nix / store / md4a3zv0ipqzsybhjb8ndjhhga1dj88x", " - hello and we see that glibc is a runtime dependency . this is exactly what we wanted . the package is self - contained . this means that we can copy its closure onto another machine and we will be able to run it . remember , only a very few components under the / nix / store are required to run nix . the hello binary will use the exact version of glibc library and interpreter referred to in the binary , rather than the system one : $ ldd result / bin / hello linux - vdso . so . 1 ( 0x00007fff11294000 ) libc .", " so . 6 = > / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib / libc . so . 6 ( 0x00007f7ab7362000 ) / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib / ld - linux - x86 - 64 . so . 2 ( 0x00007f", "7ab770f000 ) of course , the executable will run fine as long as everything is under the / nix / store path . conclusion we saw some of the tools nix provides , along with their features . in particular , we saw how nix is able to compute runtime dependencies automatically . this is not limited to only shared libraries , but can also reference executables , script s , python libraries , and so forth . approaching builds in this way makes packages self - contained , ensuring ( apart from data and configuration ) that copying the runtime closure onto another machine is sufficient to run the program . this", " enables us to run programs without installation using nix - shell , and forms the basis for reliable deployment in the cloud . next pill the next pill will introduce nix - shell . with nix - build , we ' ve always built derivations from scratch : the source gets unpacked , configured , built , and installed . but this can take a long time for large packages . what if we want to apply some small changes and compile incrementally instead , yet still want to keep a self - contained environment similar to nix - build ? nix - shell enables this .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ nix search paths welcome to the 15th nix pill . in the previous 14th pill we have introduced the \" override \" pattern , useful for writing variants of derivations by passing different inputs . assuming you followed the previous posts , i hope", " you are now ready to understand nixpkgs . but we have to find nixpkgs in our system first ! so this is the step : introducing some options and environment variables used by nix tools . the nix _ path the nix _ path environment variable is very important . it ' s very similar to the path environment variable . the syntax is similar , several paths are separated by a colon : . nix will then search for something in those paths from left to right . who uses nix _ path ? the nix expressions ! yes , nix _ path is not of much use by the nix tools themselves , rather it ' s used when writing", " nix expressions . in the shell for example , when you execute the command ping , it ' s being searched in the path directories . the first one found is the one being used . in nix it ' s exactly the same , however the syntax is different . instead of just typing ping you have to type < ping > . yes , i know . . . you are already thinking of < nixpkgs > . however , don ' t stop reading here , let ' s keep going . what ' s nix _ path good for ? nix expressions may refer to an \" abstract \" path such as < nixpkgs > , and", " it ' s possible to override it from the command line . for ease we will use nix - instantiate - - eval to do our tests . i remind you , nix - instantiate is used to evaluate nix expressions and generate the . drv files . here we are not interested inbuilding derivations , so evaluation is enough . it can be used for one - shot expressions . fake it a little it ' s useless from a nix view point , but i think it ' s useful for your own understanding . let ' s use path itself as nix _ path , and try to locate ping ( or another binary if you don '", " t have it ) . $ nix - instantiate - - eval - e ' < ping > ' error : file ` ping ' was not found in the nix search path ( add it using $ nix _ path or - i ) $ nix _ path = $ path nix - instantiate - - eval - e ' < ping > ' / bin / ping $ nix - instantiate - i / bin - - eval - e ' < ping > ' / bin / ping great . at first attempt nix obviously said could not be found anywhere in the search path . note that the - i option accepts a single directory . paths added", " with - i take precedence over nix _ path . the nix _ path also accepts a different yet very handy syntax : \" somename = somepath \" . that is , instead of searching inside a directory for a name , we specify exactly the value of that name . $ nix _ path = \" ping = / bin / ping \" nix - instantiate - - eval - e ' < ping > ' / bin / ping $ nix _ path = \" ping = / bin / foo \" nix - instantiate - - eval - e ' < ping > ' error : file ` ping ' was not found in the nix search path (", " add it using $ n note in the second case how nix checks whether the path exists or not . the path to repository you are out of curiosity , right ? $ nix - instantiate - - eval - e ' < nixpkgs > ' / home / nix / . nix - defexpr / channels / nixpkgs $ echo $ nix _ path nixpkgs = / home / nix / . nix - defexpr / channels / nixpkgs you may have a different path , depending on how you added channels etc . . anyway that ' s the whole point . the < nixpkgs", " > stranger that we used in our nix expressions , is referring to a path in the filesystem specified by nix _ path . you can list that directory and realize it ' s simply a checkout of the nixpkgs repository at a specific commit ( hint : . version - suffix ) . the nix _ path variable is exported by nix . sh , and that ' s the reason why i always asked you to source nix . sh at the beginning of my posts . you may wonder : then i can also specify a different nixpkgs path to , e . g . , a git checkout of nixpkgs", " ? yes , you can and i encourage doing that . we ' ll talk about this in the next pill . let ' s define a path for our repository , then ! let ' s say all the default . nix , graphviz . nix etc . are under / home / nix / mypkgs : $ export nix _ path = mypkgs = / home / nix / mypkgs : $ nix _ path $ nix - instantiate - - eval ' < mypkgs > ' { graphviz = < code > ; graphvizcore = < code > ; hello = < code >", " ; mkderivation = < code > ; } yes , nix - build also accepts paths with angular brackets . we first evaluate the whole repository ( default . nix ) and then pick the graphviz attribute . a big word about nix - env the nix - env command is a little different than nix - instantiate and nix - build . whereas nix - instantiate and nix - build require a starting nix expression , nix - env does not . you may be crippled by this concept at the beginning , you may think nix - env uses nix _ path to find the nixpkgs repository . but that ' s not", " it . the nix - env command uses ~ / . nix - defexpr , which is also part of nix _ path by default , but that ' s only a coincidence . if you empty nix _ path , nix - env will still be able to find derivations because of ~ / . nix - defexpr . so if you run nix - env - i graphviz inside your repository , it will install the nixpkgs one . same if you set nix _ path to point to your repository . in order to specify an alternative to ~ / . nix - defexpr it ' s possible to use", " the - f option : $ nix - env - f ' < mypkgs > ' - i graphviz warning : there are multiple derivations named ` graphviz ' ; using the first one replacing old ` graphviz ' installing ` graphviz ' oh why did it say there ' s another derivation named graphviz ? because both graphviz and graphvizcore attributes in our repository have the name \" graphviz \" for the derivation : $ nix - env - f ' < mypkgs > ' - qap graphviz graphviz graphvizcore graphviz", " hello hello by default nix - env parses all derivations and uses the derivation names to interpret the command line . so in this case \" graphviz \" matched two derivations . alternatively , like for nix - build , one can use - a to specify an attribute name instead of a derivation name : $ nix - env - f ' < mypkgs > ' - i - a graphviz replacing old ` graphviz ' installing ` graphviz ' this form , other than being more precise , it ' s also faster because nix - env does not have to parse all the derivations . for", " completeness : you must install graphvizcore with - a , since without the - a switch it ' s ambiguous . in summary , it may happen when playing with nix that nix - env picks a different derivation than nix - build . in that case you probably specified nix _ path , but nix - env is instead looking into ~ / . nix - defexpr . why is nix - env having this different behavior ? i don ' t know specifically by myself either , but the answers could be : * nix - env tries to be generic , thus it does not look for nixpkgs in nix _ path", " , rather it looks in ~ / . nix - defexpr . * nix - env is able to merge multiple trees in ~ / . nix - defexpr by looking at all the possible derivations it may also happen to you that you cannot match a derivation name when installing , because of the derivation name vs - a switch describe d above . maybe nix - env wanted to be more friendly in this case for default user setups . it may or may not make sense for you , or it ' s like that for historical reasons , but that ' s how it works currently , unless somebody comes up with a better idea", " . conclusion the nix _ path variable is the search path used by nix when using the angular brackets syntax . it ' s possible to refer to \" abstract \" paths inside nix expressions and define the \" concrete \" path by means of nix _ path , or the usual - i flag in nix tools . we ' ve also explained some of the uncommon nix - env behaviors for newcomers . the nix - env tool does not use nix _ path to search for packages , but rather for ~ / . nix - defexpr . beware of that ! in general do not abuse nix _ path , when possible use relative paths when writing your own", " nix expressions . of course , in the case of < nixpkgs > in our repository , that ' s a perfectly fine usage of nix _ path . instead , inside our repository itself , refer to expressions with relative paths like . / hello . nix . next pill . . . we will finally dive into nixpkgs . most of the techniques we have developed in this series are already in nixpkgs , like mkderivation , callpackage , override , etc . , but of course better . with time , those base utilities get enhanced by the community with more features in order to handle more and more use cases", " and in a more general way .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ preface this is a ported version of the nix pills , a series of blog postswritten by luca bruno ( aka lethalman ) and originally published in 2014 and 2015 . it provides a tutorial introduction into the nix package manager and nix", "pkgs package collection , in the form of short chapters called ' pills ' . since the nix pills are considered a classic introduction to nix , an effort to port them to the current format was led by graham christensen ( aka grahamc / gchristensen ) and other contributors in 2017 . for an up - to - date version , please visit https : / / nixos . org / guides / nix - pills / . an epub version is also available . if you encounter problems , please report them on the nixos / nix - pills issue tracker .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ developing with nix - shell welcome to the 10th nix pill . in the previous 9th pill we saw one of the powerful features of nix : automatic discovery of runtime dependencies . we also finalized the gnu hello package . in this pill", " , we will introduce the nix - shell tool and use it to hack on the gnu hello program . we will see how nix - shell gives us an isolated environmentwhile we modify the source files of the project , similar to how nix - build gave us an isolated environmentwhilebuilding the derivation . finally , we will modify our builder to work more ergonomically with a nix - shell - focused workflow . what is nix - shell ? the nix - shell tool drops us in a shell after setting up the environment variables necessary to hack on a derivation . it does not build the derivation ; it only serves as a preparation so that we can", " run the build steps manually . recall that in a nix environment , we don ' t have access to libraries or programs unless they have been installed with nix - env . however , installing libraries with nix - env is not good practice . we prefer to have isolated environments for development , which nix - shell provides for us . we can call nix - shell on any nix expression which returns a derivation , but the resulting bash shell ' s path does not have the utilities we want : $ nix - shell hello . nix [ nix - shell ] $ make bash : make : command not found [ nix - shell ] $ echo $ baseinput", "s / nix / store / jff4a6zqi0yrladx3kwy4v6844s3swpc - gnutar - 1 . 27 . 1 [ . . . ] this shell is rather useless . it would be reasonable to expect that the gnu hello build inputs are available in path , including gnu make , but this is not the case . however , we do have the environment variables that we set in the derivation , like $ baseinputs , $ buildinputs , $ src , and so on . this means that we can source our builder . sh , and it will build", " the derivation . you may get an error in the installation phase , because your user may not have the permission to write to / nix / store : [ nix - shell ] $ source builder . sh . . . the derivation didn ' t install , but it did build . note the following : * we sourced builder . sh and it ran all of the build steps , including setting up the path for us . * the working directory is no longer a temp directory created by nix - build , but is instead the directory in which we entered the shell . therefore , hello - 2 . 10 has been unpacked in the current directory . we", " are able to cd into hello - 2 . 10 and type make , because make is now available . the take - away is that nix - shell drops us in a shell with the same ( or very similar ) environment used to run the builder . a builder for nix - shell the previous steps require some manual commands to be run and are not optimized for a workflow centered on nix - shell . we will now improve our builder to be more nix - shell friendly . there are a few things that we would like to change . first , when we sourced the builder . sh file , we obtained the file in the current directory . what", " we really wanted was the builder . sh that is stored in the nix store , as this is the file that would be used by nix - build . to achieve this , the correct technique is to pass an environment variable through the derivation . ( note that $ builder is already defined , but it points to the bash executable rather than our builder . sh . our builder . sh is passed as an argument to bash . ) second , we don ' t want to run the whole builder : we only want to setup the necessary environment for manuallybuilding the project . thus , we can break builder . sh into two files : a setup . sh", " for setting up the environment , and the real builder . sh that nix - build expects . during our refactoring , we will wrap the build phases in functions to give more struct ure to our design . additionally , we ' ll move the set - e to the builder file instead of the setup file . the set - e is annoying in nix - shell , as it will terminate the shell if an error is encountered ( such as a mistyped command . ) here is our modified autotools . nix . noteworthy is the setup = . / setup . sh ; attribute in the derivation , which adds setup . sh to the", " nix store and correspondingly adds a $ setup environment variable in the builder . pkgs : attrs : let defaultattrs = { builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / builder . sh ] ; setup = . / setup . sh ; baseinputs = with pkgs ; [ gnutar gzip gnumake gcc coreutils gawk gnused gnugrep binutils . bintools patchelf findutils ] ; buildinputs = [ ] ; system = builtins . currentsystem ;", " } ; in derivation ( defaultattrs / / attrs ) thanks to that , we can split builder . sh into setup . sh and builder . sh . what builder . sh does is source $ setup and call the genericbuild function . everything else is just some changes to the bash script . here is the modified builder . sh : set - e source $ setup genericbuild here is the newly added setup . sh : unset path for p in $ baseinputs $ buildinputs ; do export path = $ p / bin $ { path : + : } $ path done function unpack", "phase ( ) { tar - xzf $ src for d in * ; do if [ - d \" $ d \" ] ; then cd \" $ d \" break fi done } function configurephase ( ) { . / configure - - prefix = $ out } function buildphase ( ) { make } function installphase ( ) { make install } function fixupphase ( ) { find $ out - type f - exec patchelf - - shrink - rpath ' { } ' \\ ; - exec strip ' { } ' \\ ; 2 > / dev /", " null } function genericbuild ( ) { unpackphase configurephase buildphase installphase fixupphase } finally , here is hello . nix : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name = \" hello \" ; src = . / hello - 2 . 12 . 1 . tar . gz ; } now back to nix - shell : $ nix - shell hello . nix [ nix - shell ] $ source $ setup [ nix - shell ]", " $ now , for example , you can run unpackphase which unpacks $ src and enters the directory . and you can run commands like . / configure , make , and so forth manually , or run phases with their respective functions . the process is that straightforward . nix - shell builds the . drv file and its input dependencies , then drops into a shell by setting up the environment variables necessary to build the . drv . in particular , the environment variables in the shell match those passed to the derivation function . conclusion with nix - shell we are able to drop into an isolated environment suitable for developing a", " project . this environment provides the necessary dependencies for the development shell , similar to how nix - build provides the necessary dependencies to a builder . additionally , we can build and debug the project manually , executing step - by - step like we would in any other operating system . note that we never installed tools such gcc or make system - wide ; these tools and libraries are isolated and available per - build . next pill in the next pill , we will clean up the nix store . we havewritten and built derivations which add to the nix store , but until now we haven ' t worried about cleaning up the used space in", " the store .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ working derivation introduction welcome to the seventh nix pill . in the previous sixth pill we introduced the notion of derivation in the nix language - - - how to define a raw derivation and how to ( try to ) build it . in this", " post we continue along the path , by creating a derivation that actually builds something . then , we try to package a real program : we compile a simple c file and create a derivation out of it , given a blessed toolchain . i remind you how to enter the nix environment : source ~ / . nix - profile / etc / profile . d / nix . sh using a script as a builder what ' s the easiest way to run a sequence of commands forbuilding something ? a bash script . we write a custom bash script , and we want it to be our builder . given a builder . sh , we want", " the derivation to run bash builder . sh . we don ' t use hash bangs in builder . sh , because at the time we are writing it we do not know the path to bash in the nix store . yes , even bash is in the nix store , everything is there . we don ' t even use / usr / bin / env , because then we lose the cool stateless property of nix . not to mention that path gets cleared whenbuilding , so it wouldn ' t find bash anyway . in summary , we want the builder to be bash , and pass it an argument , builder . sh . turns out the derivation function", " accepts an optional args attribute which is used to pass arguments to the builder executable . first of all , let ' s write our builder . sh in the current directory : declare - xp echo foo > $ out the command declare - xp lists exported variables ( declare is a builtin bash function ) . as we covered in the previous pill , nix computes the output path of the derivation . the resulting . drv file contains a list of environment variables passed to the builder . one of these is $ out . what we have to do is create something in the path $ out , be it a file or a directory . in this", " case we are creating a file . in addition , we print out the environment variables during the build process . we cannot use env for this , because env is part of coreutils and we don ' t have a dependency to it yet . we only have bash for now . like for coreutils in the previous pill , we get a blessed bash for free from our magic nixpkgs stuff : nix - repl > : l < nixpkgs > added 3950 variables . nix - repl > \" $ { bash } \" \" / nix / store / ihmkc7z2wqk", "3bbipfnlh0yjrlfkkgnv6 - bash - 4 . 2 - p45 \" so with the usual trick , we can refer to bin / bash and create our derivation : nix - repl > d = derivation { name = \" foo \" ; builder = \" $ { bash } / bin / bash \" ; args = [ . / builder . sh ] ; system = builtins . currentsystem ; } nix - repl > : b d [ 1 built , 0 . 0 mib dl ] this derivation produced the following outputs : out - > / nix / store / gcz", "b4qrag22harvv693wwnflqy7lx5pb - foo we did it ! the contents of / nix / store / w024zci0x1hh1wj6gjq0jagkc1sgrf5r - foo is really foo . we ' ve built our first derivation . note that we used . / builder . sh and not \" . / builder . sh \" . this way , it is parsed as a path , and nix performs some magic which we will cover later . try using the string version and you will find that it", " cannot find builder . sh . this is because it tries to find it relative to the temporary build directory . the builder environment we can use nix - store - - read - log to see the logs our builder produced : $ nix - store - - read - log / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo declare - x home = \" / homeless - shelter \" declare - x nix _ build _ cores = \" 4 \" declare - x nix _ build _ top = \" / tmp / nix - build - foo . drv", " - 0 \" declare - x nix _ log _ fd = \" 2 \" declare - x nix _ store = \" / nix / store \" declare - x oldpwd declare - x path = \" / path - not - set \" declare - x pwd = \" / tmp / nix - build - foo . drv - 0 \" declare - x shlvl = \" 1 \" declare - x temp = \" / tmp / nix - build - foo . drv - 0 \" declare - x tempdir = \" / tmp / nix - build - foo . drv - 0 \" declare", " - x tmp = \" / tmp / nix - build - foo . drv - 0 \" declare - x tmpdir = \" / tmp / nix - build - foo . drv - 0 \" declare - x builder = \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" declare - x name = \" foo \" declare - x out = \" / nix / store / gczb4qrag22harvv693w", "wnflqy7lx5pb - foo \" declare - x system = \" x86 _ 64 - linux \" let ' s inspect those environment variables printed during the build process . * $ home is not your home directory , and / homeless - shelter doesn ' t exist at all . we force packages not to depend on $ home during the build process . * $ path plays the same game as $ home * $ nix _ build _ cores and $ nix _ store are nix configuration options * $ pwd and $ tmp clearly show that nix created a temporary build directory * then $ builder , $ name , $ out ,", " and $ system are variables set due to the . drv file ' s contents . and that ' s how we were able to use $ out in our derivation and put stuff in it . it ' s like nix reserved a slot in the nix store for us , and we must fill it . in terms of autotools , $ out will be the - - prefix path . yes , not the make destdir , but the - - prefix . that ' s the essence of stateless packaging . you don ' t install the package in a global common path under / , you install it in a local isolated path under your nix", " store slot . the . drv contents we added something else to the derivation this time : the args attribute . let ' s see how this changed the . drv compared to the previous pill : $ nix derivation show / nix / store / i76pr1cz0za3i9r6xq518bqqvd2raspw - foo . drv { \" / nix / store / i76pr1cz0za3i9r6xq518bqqvd2raspw - foo . drv \" : { \" outputs \" : { \" out \" : { \"", " path \" : \" / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo \" } } , \" inputsrcs \" : [ \" / nix / store / lb0n38r2b20r8rl1k45a7s4pj6ny22f7 - builder . sh \" ] , \" inputdrvs \" : { \" / nix / store / hcgwbx42mcxr7ksnv0i1fg7kw6jvxshb - bash - 4", " . 4 - p19 . drv \" : [ \" out \" ] } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" , \" args \" : [ \" / nix / store / lb0n38r2b20r8rl1k45a7s4pj6ny22f7 - builder . sh \" ] , \" env \"", " : { \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" , \" name \" : \" foo \" , \" out \" : \" / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo \" , \" system \" : \" x86 _ 64 - linux \" } } } much like the usual . drv , except that there ' s a list", " of arguments in there passed to the builder ( bash ) with builder . sh . . . in the nix store . . ? nix automatically copies files or directories needed for the build into the store to ensure that they are not changed during the build process and that the deployment is stateless and independent of thebuilding machine . builder . sh is not only in the arguments passed to the builder , it ' s also in the input sources . given that builder . sh is a plain file , it has no . drv associated with it . the store path is computed based on the filename and on the hash of its contents . store paths are", " covered in detail in a later pill . packaging a simple c program start off by writing a simple c program called simple . c : void main ( ) { puts ( \" simple ! \" ) ; } and its simple _ builder . sh : export path = \" $ coreutils / bin : $ gcc / bin \" mkdir $ out gcc - o $ out / simple $ src don ' t worry too much about where those variables come from yet ; let ' s write the derivation and build it : nix - repl > : l < nixpkgs > nix - repl > simple = derivation { name", " = \" simple \" ; builder = \" $ { bash } / bin / bash \" ; args = [ . / simple _ builder . sh ] ; gcc = gcc ; coreutils = coreutils ; src = . / simple . c ; system = builtins . currentsystem ; } nix - repl > : b simple this derivation produced the following outputs : out - > / nix / store / ni66p4jfqksbmsl616llx3fbs1d232d4 - simple now you can run / nix / store / ni66p4jfq", "ksbmsl616llx3fbs1d232d4 - simple / simple in your shell . explanation we added two new attributes to the derivation call , gcc and coreutils . in gcc = gcc ; , the name on the left is the name in the derivation set , and the name on the right refers to the gcc derivation from nixpkgs . the same applies for coreutils . we also added the src attribute , nothing magical - - - it ' s just a name , to which the path . / simple . c is assigned . like simple - builder . sh ,", " simple . c will be added to the store . the trick : every attribute in the set passed to derivation will be converted to a string and passed to the builder as an environment variable . this is how the builder gains access to coreutils and gcc : when converted to strings , the derivations evaluate to their output paths , and appending / bin to these leads us to their binaries . the same goes for the src variable . $ src is the path to simple . c in the nix store . as an exercise , pretty print the . drv file . you ' ll see simple _ builder . sh and simple .", " c listed in the input derivations , along with bash , gcc and coreutils . drv files . the newly added environment variables describe d above will also appear . in simple _ builder . sh we set the path for gcc and coreutils binaries , so that our build script can find the necessary utilities like mkdir and gcc . we then create $ out as a directory and place the binary inside it . note that gcc is found via the path environment variable , but it could equivalently be referenced explicitly using $ gcc / bin / gcc . enough of nix repl drop out of", " nix repl and write a file simple . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" simple \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / simple _ builder . sh ] ; gcc = pkgs . gcc ; coreutils = pkgs . coreutils ; src = . / simple . c ; system = builtins . currentsystem ; } now you can build it with nix - build simple . nix . this will create a symlink result in", " the current directory , pointing to the out path of the derivation . nix - build does two jobs : * nix - instantiate : parse and evaluate simple . nix and return the . drv file corresponding to the parsed derivation set * nix - store - r : realise the . drv file , which actually builds it . finally , it creates the symlink . in the second line of simple . nix , we have an import function call . recall that import accepts one argument , a nix file to load . in this case , the contents of the file evaluate to a function . afterwards , we call the function with the empty set", " . we saw this already in the fifth pill . to reiterate : import < nixpkgs > { } is calling two functions , not one . reading it as ( import < nixpkgs > ) { } makes this clearer . the value returned by the nixpkgs function is a set ; more specifically , it ' s a set of derivations . calling import < nixpkgs > { } into a let - expression creates the local variable pkgs and brings it into scope . this has an effect similar to the : l < nixpkgs > we used in nix repl , in that", " it allows us to easily access derivations such as bash , gcc , and coreutils , but those derivations will have to be explicitly referred to as members of the pkgs set ( e . g . , pkgs . bash instead of just bash ) . below is a revised version of the simple . nix file , using the inherit keyword : let pkgs = import < nixpkgs > { } ; in derivation { name = \" simple \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / simple _ builder . sh ] ;", " inherit ( pkgs ) gcc coreutils ; src = . / simple . c ; system = builtins . currentsystem ; } here we also take the opportunity to introduce the inherit keyword . inherit foo ; is equivalent to foo = foo ; . similarly , inherit gcc coreutils ; is equivalent to gcc = gcc ; coreutils = coreutils ; . lastly , inherit ( pkgs ) gcc coreutils ; is equivalent to gcc = pkgs . gcc ; coreutils = pkgs . coreutils ; . this syntax only makes sense inside", " sets . there ' s no magic involved , it ' s simply a convenience to avoid repeating the same name for both the attribute name and the value in scope . next pill we will generalize the builder . you may have noticed that we wrote two separate builder . sh script s in this post . we would like to have a generic builder script instead , especially since each build script goes in the nix store : a bit of a waste . is it really that hard to package stuff in nix ? no , here we ' re studying the fundamentals of nix .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ why you should give it a try introduction welcome to the first post of the \" nix in pills \" series . nix is a purely functional package manager and deployment system for posix . there ' s a lot of documentation that de", "scribe s what nix , nixos and related projects are . but the purpose of this post is to convince you to give nix a try . installing nixos is not required , but sometimes i may refer to nixos as a realworld example of nix usage forbuilding a whole operating system . rationale for this series the nix , nixpkgs , and nixos manuals along with the wiki are excellent resources for explaining how nix / nixos works , how you can use it , and how cool things are being done with it . however , at the beginning you may feel that some of the magic which happens behind the scenes is", " hard to grasp . this series aims to complement the existing explanations from the more formal documents . the following is a descript ion of nix . just as with pills , i ' ll try to be as short as possible . not being purely functional most , if not all , widely used package managers ( dpkg , rpm , . . . ) mutate the global state of the system . if a package foo - 1 . 0 installs a program to / usr / bin / foo , you cannot install foo - 1 . 1 as well , unless you change the installation paths or the binary name . but changing the binary names means", " breaking users of that binary . there are some attempts to mitigate this problem . debian , for example , partially solves the problem with the alternatives system . sowhile in theory it ' s possible with some current systems to install multiple versions of the same package , in practice it ' s very painful . let ' s say you need an nginx service and also an nginx - openresty service . you have to create a new package that changes all the paths to have , for example , an - openresty suffix . or suppose that you want to run two different instances of mysql : 5 . 2", " and 5 . 5 . the same thing applies , plus you have to also make sure the two mysqlclient libraries do not collide . this is not impossible but it is very inconvenient . if you want to install two whole stacks of software like gnome 3 . 10 and gnome 3 . 12 , you can imagine the amount of work . from an administrator ' s point of view : you can use containers . the typical solution nowadays is to create a container per service , especially when different versions are needed . that somewhat solves the problem , but at a different level and with other drawbacks . for example , needing", " orchestration tools , setting up a shared cache of packages , and new machines to monitor rather than simple services . from a developer ' s point of view : you can use virtualenv for python , or jhbuild for gnome , or whatever else . but then how do you mix the two stacks ? how do you avoid recompiling the same thing when it could instead be shared ? also you need to set up your development tools to point to the different directories where libraries are installed . not only that , there ' s the risk that some of the software incorrectly uses system libraries . and so on . nix solves all", " this at the packaging level and solves it well . a single tool to rule them all . being purely functional nix makes no assumptions about the global state of the system . this has many advantages , but also some drawbacks of course . the core of a nix system is the nix store , usually installed under / nix / store , and some tools to manipulate the store . in nix there is the notion of a derivation rather than a package . the difference can be subtle at the beginning , so i will often use the words interchangeably . derivations / packages are stored in the nix store as follows : / nix / store / \u00ab hash -", " name \u00bb , where the hash uniquely identifies the derivation ( this isn ' t quite true , it ' s a little more complex ) , and the name is the name of the derivation . let ' s take a bash derivation as an example : / nix / store / s4zia7hhqkin1di0f187b79sa2srhv6k - bash - 4 . 2 - p45 / . this is a directory in the nix store which contains bin / bash . what that means is that there ' s no / bin / bash , there ' s only that self - contained build output in the store", " . the same goes for coreutils and everything else . to make them convenient to use from the shell , nix will arrange for binaries to appear in your path as appropriate . what we have is basically a store of all packages ( with different versions occupying different locations ) , and everything in the nix store is immutable . in fact , there ' s no ldconfig cache either . so where does bash find libc ? $ ldd ` which bash ` libc . so . 6 = > / nix / store / 94n64qy99ja0vgbkf675nyk39g9", "b978n - glibc - 2 . 19 / lib / libc . so . 6 ( 0x00007f0248cce000 ) it turns out that when bash was built , it was built against that specific version of glibc in the nix store , and at runtime it will require exactly that glibc version . don ' t be confused by the version in the derivation name : it ' s only a name for us humans . you may end up having two derivations with the same name but different hashes : it ' s the hash that really matters . what does", " all this mean ? it means that you could run mysql 5 . 2 with glibc - 2 . 18 , and mysql 5 . 5 with glibc - 2 . 19 . you could use your python module with python 2 . 7 compiled with gcc 4 . 6 and the same python module with python 3 compiled with gcc 4 . 8 , all in the same system . in other words : no dependency hell , not even a dependency resolution algorithm . straight dependencies from derivations to other derivations . from an administrator ' s point of view : if you want an old php version for one application", " , but want to upgrade the rest of the system , that ' s not painful any more . from a developer ' s point of view : if you want to develop webkit with llvm 3 . 4 and 3 . 3 , that ' s not painful any more . mutable vs . immutable when upgrading a library , most package managers replace it in - place . all new applications run afterwards with the new library without being recompiled . after all , they all refer dynamically to libc6 . so . since nix derivations are immutable , upgrading a library like glibc means recompiling all applications", " , because the glibc path to the nix store has been hardcoded . so how do we deal with security updates ? in nix we have some tricks ( still pure ) to solve this problem , but that ' s another story . another problem is that unless software has in mind a pure functional model , or can be adapted to it , it can be hard to compose applications at runtime . let ' s take firefox for example . on most systems , you install flash , and it starts working in firefox because firefox looks in a global path for plugins . in nix , there ' s no such global", " path for plugins . firefox therefore must know explicitly about the path to flash . the way we handle this problem is to wrap the firefox binary so that we can setup the necessary environment to make it find flash in the nix store . that will produce a new firefox derivation : be aware that it takes a few seconds , and it makes composition harder at runtime . there are no upgrade / downgrade script s for your data . it doesn ' t make sense with this approach , because there ' s no real derivation to be upgraded . with nix you switch to using other software with its own stack of dependencies", " , but there ' s no formal notion of upgrade or downgrade when doing so . if there is a data format change , then migrating to the new data format remains your own responsibility . conclusion nix lets you compose software at build time with maximum flexibility , and with builds being as reproducible as possible . not only that , due to its nature deploying systems in the cloud is so easy , consistent , and reliable that in the nixworld all existing self - containment and orchestration tools are deprecated by nixops . it however currently falls short when working with dynamic composition at runtime or replacing low level libraries , due to the need", " to rebuild dependencies . that may sound scary , however after running nixos on both a server and a laptop desktop , i ' m very satisfied so far . some of the architectural problems just need some man - power , other design problems still need to be solved as a community . considering nixpkgs ( github link ) is a completely new repository of all the existing software , with a completely fresh concept , and with few core developers but overall year - over - year increasing contributions , the current state is more than acceptable and beyond the experimental stage . in other words , it ' s worth your investment . next pill . . .", " . . . we will install nix on top of your current system ( i assume gnu / linux , but we also have osx users ) and start inspecting the installed software .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ fundamentals of stdenv welcome to the 19th nix pill . in the previous 18th pill we dived into the algorithm used by nix to compute the store paths , and also introduced fixed - output store paths . this time we will", " instead look into nixpkgs , in particular one of its core derivations : stdenv . the stdenv is not treated as a special derivation by nix , but it ' s very important for the nixpkgs repository . it serves as a base for packaging software . it is used to pull in dependencies such as the gcc toolchain , gnu make , core utilities , patch and diff utilities , and so on : basic tools needed to compile a huge pile of software currently present in nixpkgs . what is stdenv ? first of all , stdenv is a derivation , and", " it ' s a very simple one : $ nix - build ' < nixpkgs > ' - a stdenv / nix / store / k4jklkcag4zq4xkqhkpy156mgfm34ipn - stdenv $ ls - r result / result / : nix - support / setup result / nix - support : propagated - user - env - packages it has just two files : / setup and / nix - support / propagated - user - env - packages . don ' t worry about the latter . it ' s empty , in fact", " . the important file is / setup . how can this simple derivation pull in all of the toolchain and basic tools needed to compile packages ? let ' s look at the runtime dependencies : $ nix - store - q - - references result / nix / store / 3a45nb37s0ndljp68228snsqr3qsyp96 - bzip2 - 1 . 0 . 6 / nix / store / a457ywa1haa0sgr9g7a1pgldrg3s798d - coreutils - 8 . 24 /", " nix / store / zmd4jk4db5lgxb8l93mhkvr3x92g2sx2 - bash - 4 . 3 - p39 / nix / store / 47sfpm2qclpqvrzijizimk4md1739b1b - gcc - wrapper - 4 . 9 . 3 . . . how can it be ? the package must be referring to those other packages somehow . in fact , they are hardcoded in the / setup file : $ head result / setup export shell = / nix / store / zmd4", "jk4db5lgxb8l93mhkvr3x92g2sx2 - bash - 4 . 3 - p39 / bin / bash initialpath = \" / nix / store / a457ywa1haa0sgr9g7a1pgldrg3s798d - coreutils - 8 . 24 . . . \" defaultnativebuildinputs = \" / nix / store / sgwq15xg00xnm435gjicspm048rqg9y6 - patchelf - 0 .", " 8 . . . \" the setup file remember our generic builder . sh in pill 8 ? it sets up a basic path , unpacks the source and runs the usual autotools commands for us . the stdenv setup file is exactly that . it sets up several environment variables like path and creates some helper bash functions to build a package . i invite you to read it . the hardcoded toolchain and utilities are used to initially fill up the environment variables so that it ' s more pleasant to run common commands , similar to what we did with our builder with baseinputs and buildinputs . the", " build with stdenv works in phases . phases are like unpackphase , configurephase , buildphase , checkphase , installphase , fixupphase . you can see the default list in the genericbuild function . what genericbuild does is just run these phases . default phases are just bash functions . you can easily read them . every phase has hooks to run commands before and after the phase has been executed . phases can be overwritten , reordered , whatever , it ' s just bash code . how to use this file ? like our old builder . to test", " it , we enter a fake empty derivation , source the stdenv setup , unpack the hello sources and build it : $ nix - shell - e ' derivation { name = \" fake \" ; builder = \" fake \" ; system = \" x86 _ 64 - linux \" ; } ' nix - shell $ unset path nix - shell $ source / nix / store / k4jklkcag4zq4xkqhkpy156mgfm34ipn - stdenv / setup nix - shell $ tar - xf hello - 2 . 10 . tar . gz nix - shell $ cd", " hello - 2 . 10 nix - shell $ configurephase . . . nix - shell $ buildphase . . . i unset path to further show that the stdenv is sufficiently self - contained to build autotools packages that have no other dependencies . so we ran the configurephase function and buildphase function and they worked . these bash functions should be self - explanatory . you can read the code in the setup file . how the setup file is built until now we worked with plain bash script s . what about the nix side ? the nixpkgs", " repository offers a useful function , like we did with our old builder . it is a wrapper around the raw derivation function which pulls in the stdenv for us , and runs genericbuild . it ' s stdenv . mkderivation . note how stdenv is a derivation but it ' s also an attribute set which contains some other attributes , like mkderivation . nothing fancy here , just convenience . let ' s write a hello . nix expression using this newly discovered stdenv : with import < nixpkgs > { } ; stdenv . mkderivation { name = \" hello \" ;", " src = . / hello - 2 . 10 . tar . gz ; } don ' t be scared by the with expression . it pulls the nixpkgs repository into scope , so we can directly use stdenv . it looks very similar to the hello expression in pill 8 . it builds , and runs fine : $ nix - build hello . nix . . . / nix / store / 6y0mzdarm5qxfafvn2zm9nr01d1j0a72 - hello $ result / bin / hello hello ,world ! the stdenv . mkderivation builder let", " ' s take a look at the builder used by mkderivation . you can read the code here in nixpkgs : { # . . . builder = attrs . realbuilder or shell ; args = attrs . args or [ \" - e \" ( attrs . builder or . / default - builder . sh ) ] ; stdenv = result ; # . . . } also take a look at our old derivation wrapper in previous pills ! the builder is bash ( that shell variable ) , the argument to the builder ( bash ) is default - builder . sh , and then", " we add the environment variable $ stdenv in the derivation which is the stdenv derivation . you can open default - builder . sh and see what it does : source $ stdenv / setup genericbuild it ' s what we did in pill 10 to make the derivations nix - shell friendly . when entering the shell , the setup file only sets up the environment withoutbuilding anything . when doing nix - build , it actually runs the build process . to get a clear understanding of the environment variables , look at the . drv of the hello derivation : $ nix derivation show $ ( nix - instantiate hello . nix", " ) warning : you did not specify ' - - add - root ' ; the result might be removed by the garbage collector { \" / nix / store / abwj50lycl0m515yblnrvwyydlhhqvj2 - hello . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / 6y0mzdarm5qxfafvn2zm9nr01d1j0a72 - hello \" } } , \" inputsrcs \" : [ \" / nix / store / 9krlz", "vny65gdc8s7kpb6lkx8cd02c25b - default - builder . sh \" , \" / nix / store / svc70mmzrlgq42m9acs0prsmci7ksh6h - hello - 2 . 10 . tar . gz \" ] , \" inputdrvs \" : { \" / nix / store / hcgwbx42mcxr7ksnv0i1fg7kw6jvxshb - bash - 4 . 4 - p19 . drv \" : [ \" out", " \" ] , \" / nix / store / sfxh3ybqh97cgl4s59nrpi78kgcc8f3d - stdenv - linux . drv \" : [ \" out \" ] } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" , \" args \" : [ \" - e \" , \" /", " nix / store / 9krlzvny65gdc8s7kpb6lkx8cd02c25b - default - builder . sh \" ] , \" env \" : { \" buildinputs \" : \" \" , \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" , \" configureflags \" : \" \" , \" depsbuildbuild \" : \" \" ,", " \" depsbuildbuildpropagated \" : \" \" , \" depsbuildtarget \" : \" \" , \" depsbuildtargetpropagated \" : \" \" , \" depshostbuild \" : \" \" , \" depshostbuildpropagated \" : \" \" , \" depstargettarget \" : \" \" , \" depstargettargetpropagated \" : \" \" , \" name \" : \" hello \" , \" nativebuildinputs \" : \" \" , \" out \" : \" / nix", " / store / 6y0mzdarm5qxfafvn2zm9nr01d1j0a72 - hello \" , \" propagatedbuildinputs \" : \" \" , \" propagatednativebuildinputs \" : \" \" , \" src \" : \" / nix / store / svc70mmzrlgq42m9acs0prsmci7ksh6h - hello - 2 . 10 . tar . gz \" , \" stdenv \" : \" / nix / store / 6kz2vbh98", "s2r1pfshidkzhiy2s2qdw0a - stdenv - linux \" , \" system \" : \" x86 _ 64 - linux \" } } } it ' s so short i decided to paste it entirely above . the builder is bash , with - e default - builder . sh arguments . then you can see the src and stdenv environment variables . the last bit , the unpackphase in the setup , is used to unpack the sources and enter the directory . again , like we did in our old builder . conclusion the stdenv is the core of the", " nixpkgs repository . all packages use the stdenv . mkderivation wrapper instead of the raw derivation . it does a bunch of operations for us and also sets up a pleasant build environment . the overall process is simple : * nix - build * bash - e default - builder . sh * source $ stdenv / setup * genericbuild that ' s it . everything you need to know about the stdenv phases is in the setup file . really , take your time to read that file . don ' t forget that juicy docs are also available in the nixpkgs manual . next pill .", " . . . . . we will talk about how to add dependencies to our packages with buildinputs and propagatedbuildinputs , and influence downstream builds with setup hooks and env hooks . these concepts are crucial to how nixpkgs packages are composed .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ functions and imports welcome to the fifth nix pill . in the previous fourth pill we touched the nix language for a moment . we introduced basic types and values of the nix language , and basic expressions such as if , with and let .", " i invite you to re - read about these expressions and play with them in the repl . functions help to build reusable components in a big repository like nixpkgs . the nix manual has a great explanation of functions . let ' s go : pill on one hand , nix manual on the other hand . i remind you how to enter the nix environment : source ~ / . nix - profile / etc / profile . d / nix . sh nameless and single parameter functions are anonymous ( lambdas ) , and only have a single parameter . the syntax is extremely simple . type the parameter name , then \" : \" , then", " the body of the function . nix - repl > x : x * 2 \u00ab lambda \u00bb so here we defined a function that takes a parameter x , and returns x * 2 . the problem is that we cannot use it in any way , because it ' s unnamed . . . joke ! we can store functions in variables . nix - repl > double = x : x * 2 nix - repl > double \u00ab lambda \u00bb nix - repl > double 3 6 as usual , please ignore the special syntax for assignments inside nix repl . so , we defined a function x : x * 2 that takes one parameter x , and", " returns x * 2 . this function is then assigned to the variable double . finally we did our first function call : double 3 . big note : it ' s not like many other programming languages where you write double ( 3 ) . it really is double 3 . in summary : to call a function , name the variable , then space , then the argument . nothing else to say , it ' s as easy as that . more than one parameter how do we create a function that accepts more than one parameter ? for people not used to functional programming , this may take awhile to grasp . let ' s do it step by step . nix -", " repl > mul = a : ( b : a * b ) nix - repl > mul \u00ab lambda \u00bb nix - repl > mul 3 \u00ab lambda \u00bb nix - repl > ( mul 3 ) 4 12 we defined a function that takes the parameter a , the body returns another function . this other function takes a parameter b and returns a * b . therefore , calling mul 3 returns this kind of function : b : 3 * b . in turn , we call the returned function with 4 , and get the expected result . you don ' t have to use parentheses at all , nix has sane priorities when", " parsing the code : nix - repl > mul = a : b : a * b nix - repl > mul \u00ab lambda \u00bb nix - repl > mul 3 \u00ab lambda \u00bb nix - repl > mul 3 4 12 nix - repl > mul ( 6 + 7 ) ( 8 + 9 ) 221 much more readable , you don ' t even notice that functions only receive one argument . since the argument is separated by a space , to pass more complex expressions you need parentheses . in other common languages you would write mul ( 6 + 7 , 8 + 9 ) . given that functions have", " only one parameter , it is straightforward to use partial application : nix - repl > foo = mul 3 nix - repl > foo 4 12 nix - repl > foo 5 15 we stored the function returned by mul 3 into a variable foo , then reused it . argument set now this is a very cool feature of nix . it is possible to pattern match over a set in the parameter . we write an alternative version of mul = a : b : a * b first by using a set as argument , then using pattern matching . nix - repl > mul = s : s . a * s . b nix", " - repl > mul { a = 3 ; b = 4 ; } 12 nix - repl > mul = { a , b } : a * b nix - repl > mul { a = 3 ; b = 4 ; } 12 in the first case we defined a function that accepts a single parameter . we then access attributes a and b from the given set . note how the parentheses - less syntax for function calls is very elegant in this case , instead of doing mul ( { a = 3 ; b = 4 ; } ) in other languages . in the second case we defined an argument set . it '", " s like defining a set , except without values . we require that the passed set contains the keys a and b . then we can use those a and b in the function body directly . nix - repl > mul = { a , b } : a * b nix - repl > mul { a = 3 ; b = 4 ; c = 6 ; } error : anonymous function at ( string ) : 1 : 2 called with unexpected argument ` c ' , at ( string ) : 1 : 1 nix - repl > mul { a = 3 ; } error : anonymous function at ( string ) : 1 : 2", " called without required argument ` b ' , at ( string ) : 1 : 1 only a set with exactly the attributes required by the function is accepted , nothing more , nothing less . default and variadic attributes it is possible to specify default values of attributes in the argument set : nix - repl > mul = { a , b ? 2 } : a * b nix - repl > mul { a = 3 ; } 6 nix - repl > mul { a = 3 ; b = 4 ; } 12 also you can allow passing more attributes ( variadic ) than the expected ones : nix - repl", " > mul = { a , b , . . . } : a * b nix - repl > mul { a = 3 ; b = 4 ; c = 2 ; } however , in the function body you cannot access the \" c \" attribute . the solution is to give a name to the given set with the @ - pattern : nix - repl > mul = s @ { a , b , . . . } : a * b * s . c nix - repl > mul { a = 3 ; b = 4 ; c = 2 ; } 24 that ' s it , you give a name", " to the whole parameter with name @ before the set pattern . advantages of using argument sets : * named unordered arguments : you don ' t have to remember the order of the arguments . * you can pass sets , that adds a whole new layer of flexibility and convenience . disadvantages : * partial application does not work with argument sets . you have to specify the whole attribute set , not part of it . you may find similarities with python * * kwargs . imports the import function is built - in and provides a way to parse a . nix file . the natural approach is to define each component in a . nix file ,", " then compose by importing these files . let ' s start with the bare metal . a . nix : 3 b . nix : 4 mul . nix : a : b : a * b nix - repl > a = import . / a . nix nix - repl > b = import . / b . nix nix - repl > mul = import . / mul . nix nix - repl > mul a b 12 yes it ' s really that simple . you import a file , and it gets parsed as an expression . note that the scope of the imported file does not inherit the scope of the import", "er . test . nix : x nix - repl > let x = 5 ; in import . / test . nix error : undefined variable ` x ' at / home / lethal / test . nix : 1 : 1 so how do we pass information to the module ? use functions , like we did with mul . nix . a more complex example : test . nix : { a , b ? 3 , truemsg ? \" yes \" , falsemsg ? \" no \" } : if a > b then builtins . trace truemsg true else builtins . trace falsemsg false nix - repl > import", " . / test . nix { a = 5 ; truemsg = \" ok \" ; } trace : ok true explaining : * in test . nix we return a function . it accepts a set , with default attributes b , truemsg and falsemsg . * builtins . trace is a built - in function that takes two arguments . the first is the message to display , the second is the value to return . it ' s usually used for debugging purposes . * then we import test . nix , and call the function with that set . so when is the message shown ? only when it needs to be evaluated . next", " pill . . . we will finally write our first derivation .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ override design pattern welcome to the 14th nix pill . in the previous 13th pill , we introduced the callpackage pattern and used it to simplify the composition of software in a repository . the next design pattern is less necessary ,", " but is useful in many cases and is a good exercise to learn more about nix . about composability functional languages are known for being able to compose functions . in particular , these languages gain expressivity from functions that manipulate an original value into a new value having the same struct ure . this allows us to compose multiple functions to perform the desired modifications . in nix , we mostly talk about functions that accept inputs in order to return derivations . in ourworld , we want utility functions that are able to manipulate those struct ures . these utilities add some useful properties to the original value , and we ' d like to be", " able to apply more utilities on top of the result . for example , let ' s say we have an initial derivation drv and we want to transform it into a drv with debugging information and custom patches : debugversion ( applypatches [ . / patch1 . patch . / patch2 . patch ] drv ) the final result should be the original derivation with some changes . this is both interesting and very different from other packaging approaches , which is a consequence of using a functional language to describe packages . designing such utilities is not trivial in a functional language without static typing , because understanding what can or cannot", " be composed is difficult . but we try to do our best . the override pattern in pill 12 we introduced the inputs design pattern . we do not return a derivation picking dependencies directly from the repository ; rather we declare the inputs and let the callers pass the necessary arguments . in our repository we have a set of attributes that import the expressions of the packages and pass these arguments , getting back a derivation . let ' s take for example the graphviz attribute : graphviz = import . / graphviz . nix { inherit mkderivation gd fontconfig libjpeg bzip2 ; }", " ; if we wanted to produce a derivation of graphviz with a customized gd version , we would have to repeat most of the above plus specifying an alternative gd : { mygraphviz = import . / graphviz . nix { inherit mkderivation fontconfig libjpeg bzip2 ; gd = customgd ; } ; } that ' s hard to maintain . using callpackage would be easier : mygraphviz = callpackage . / graphviz . nix { gd = customgd ; } ; but we may still be diverging from the", " original graphviz in the repository . we would like to avoid specifying the nix expression again . instead , we would like to reuse the original graphviz attribute in the repository and add our overrides like so : mygraphviz = graphviz . override { gd = customgd ; } ; the difference is obvious , as well as the advantages of this approach . note : that . override is not a \" method \" in the oo sense as you may think . nix is a functional language . the . override is simply an attribute of a set . the override implementation recall that the", " graphviz attribute in the repository is the derivation returned by the function imported from graphviz . nix . we would like to add a further attribute named \" override \" to the returned set . let ' s start by first creating a function \" makeoverridable \" . this function will take two arguments : a function ( that must return a set ) and the set of original arguments to be passed to the function . we will put this function in a lib . nix : { makeoverridable = f : origargs : let origres = f origargs ; in origres / / {", " override = newargs : f ( origargs / / newargs ) ; } ; } makeoverridable takes a function and a set of original arguments . it returns the original returned set , plus a new override attribute . this override attribute is a function taking a set of new arguments , and returns the result of the original function called with the original arguments unified with the new arguments . this is admittedly somewhat confusing , but the examples below should make it clear . let ' s try it with nix repl : $ nix repl nix - repl > : l lib . nix added 1 variables", " . nix - repl > f = { a , b } : { result = a + b ; } nix - repl > f { a = 3 ; b = 5 ; } { result = 8 ; } nix - repl > res = makeoverridable f { a = 3 ; b = 5 ; } nix - repl > res { override = \u00ab lambda \u00bb ; result = 8 ; } nix - repl > res . override { a = 10 ; } { result = 15 ; } note that , as we specified above , the function f does not return the plain sum . instead , it returns", " a set with the sum bound to the name result . the variable res contains the result of the function call without any override . it ' s easy to see in the definition of makeoverridable . in addition , you can see that the new override attribute is a function . calling res . override with a set will invoke the original function with the overrides , as expected . this is a good start , but we can ' t override again ! this is because the returned set ( with result = 15 ) does not have an override attribute of its own . this is bad ; it breaks further composition .", " the solution is simple : the . override function should make the result overridable again : rec { makeoverridable = f : origargs : let origres = f origargs ; in origres / / { override = newargs : makeoverridable f ( origargs / / newargs ) ; } ; } please note the rec keyword . it ' s necessary so that we can refer to makeoverridable from makeoverridable itself . now let ' s try overriding twice : nix - repl > : l lib . nix added 1", " variables . nix - repl > f = { a , b } : { result = a + b ; } nix - repl > res = makeoverridable f { a = 3 ; b = 5 ; } nix - repl > res2 = res . override { a = 10 ; } nix - repl > res2 { override = \u00ab lambda \u00bb ; result = 15 ; } nix - repl > res2 . override { b = 20 ; } { override = \u00ab lambda \u00bb ; result = 30 ; } success ! the result is 30 ( as expected ) because a is overridden", " to 10 in the first override , and b is overridden to 20 in the second . now it would be nice if callpackage made our derivations overridable . this is an exercise for the reader . conclusion the \" override \" pattern simplifies the way we customize packages starting from an existing set of packages . this opens aworld of possibilities for using a central repository like nixpkgs and defining overrides on our local machine without modifying the original package . we can dream of a custom , isolated nix - shell environment for testing graphviz with a custom gd : debugversion (", " graphviz . override { gd = customgd ; } ) once a new version of the overridden package comes out in the repository , the customized package will make use of it automatically . the key in nix is to find powerful yet simple abstractions in order to let the user customize their environment with highest consistency and lowest maintenance time , by using predefined composable components . next pill in the next pill , we will talk about nix search paths . by \" search path \" , we mean a place in the file system where nix looks for expressions . this answers the question of where < nixpk", "gs > comes from .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ nixpkgs parameters welcome to the 16th nix pill . in the previous 15th pill we ' ve realized how nix finds expressions with the angular brackets syntax , so that we finally know where < nixpkgs > is located on", " our system . we can start diving into the nixpkgs repository , through all the various tools and design patterns . please note that also nixpkgs has its own manual , underlying the difference between the general nix language and the nixpkgs repository . the default . nix expression we will not start inspecting packages at the beginning , rather the general struct ure of nixpkgs . in our custom repository we created a default . nix which composed the expressions of the various packages . also nixpkgs has its own default . nix , which is the one being loaded when referring to < nixpkgs > .", " it does a simple thing : check whether the nix version is at least 1 . 7 ( at the time of writing this blog post ) . then import pkgs / top - level / all - packages . nix . from now on , we will refer to this set of packages as pkgs . the all - packages . nix is then the file that composes all the packages . note the pkgs / subdirectory ,while nixos is in the nixos / subdirectory . the all - packages . nix is a bit contrived . first of all , it ' s a function .", " it accepts a couple of interesting parameters : * system : defaults to the current system * config : defaults to null * others . . . the system parameter , as per comment in the expression , it ' s the system for which the packages will be built . it allows for example to install i686 packages on amd64 machines . the config parameter is a simple attribute set . packages can read some of its values and change the behavior of some derivations . the system parameter you will find this parameter in many other . nix expressions ( e . g . release expressions ) . the reason is that , given p", "kgs accepts a system parameter , then whenever you want to import pkgs you also want to pass through the value of system . e . g . : myrelease . nix : { system ? builtins . currentsystem } : let pkgs = import < nixpkgs > { inherit system ; } ; . . . why is it useful ? with this parameter it ' s very easy to select a set of packages for a particular system . for example : nix - build - a psmisc - - argstr system i686 - linux this will build the psmisc derivation for i686", " - linux instead of x86 _ 64 - linux . this concept is very similar to multi - arch of debian . the setup for cross compiling is also in nixpkgs , however it ' s a little contrived to talk about it and i don ' t know much of it either . the config parameter i ' m sure on the wiki or other manuals you ' ve read about ~ / . config / nixpkgs / config . nix ( previously ~ / . nixpkgs / config . nix ) and i ' m sure you ' ve wondered whether that '", " s hardcoded in nix . it ' s not , it ' s in nixpkgs . the all - packages . nix expression accepts the config parameter . if it ' s null , then it reads the nixpkgs _ config environment variable . if not specified , nixpkgs will pick $ home / . config / nixpkgs / config . nix . after determining config . nix , it will be imported as a nix expression , and that will be the value of config ( in case it hasn ' t been passed as parameter to import < nixp", "kgs > ) . the config is available in the resulting repository : $ nix repl nix - repl > pkgs = import < nixpkgs > { } nix - repl > pkgs . config { } nix - repl > pkgs = import < nixpkgs > { config = { foo = \" bar \" ; } ; } nix - repl > pkgs . config { foo = \" bar \" ; } what attributes go in config is a matter of convenience and conventions . for example , config . allowunfree", " is an attribute that forbidsbuilding packages that have an unfree license by default . the config . pulseaudio setting tells whether to build packages with pulseaudio support or not where applicable and when the derivation obeys to the setting . about . nix functions a . nix file contains a nix expression . thus it can also be a function . i remind you that nix - build expects the expression to return a derivation . therefore it ' s natural to return straight a derivation from a . nix file . however , it ' s also very natural for the . nix file to accept some parameters , in order to tweak the derivation", " being returned . in this case , nix does a trick : * if the expression is a derivation , build it . * if the expression is a function , call it and build the resulting derivation . for example you can nix - build the . nix file below : { pkgs ? import < nixpkgs > { } } : pkgs . psmisc nix is able to call the function because the pkgs parameter has a default value . this allows you to pass a different value for pkgs using the - - arg option . does it work if you have a function returning a function that returns a derivation", " ? no , nix only calls the function it encounters once . conclusion we ' ve unleashed the < nixpkgs > repository . it ' s a function that accepts some parameters , and returns the set of all packages . due to laziness , only the accessed derivations will be built . you can use this repository to build your own packages as we ' ve seen in the previous pill when creating our own repository . lately i ' m a little busy with the nixos 14 . 11 release and other stuff , and i ' m also looking toward migrating from blogger to a more coder - oriented blogging platform . so sorry for the", " delayed and shorter pills : ) next pill . . . we will talk about overriding packages in the nixpkgs repository . what if you want to change some options of a library and let all other packages pick the new library ? one possibility is to use , like describe d above , the config parameter when applicable . the other possibility is to override derivations .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the basics of the language welcome to the fourth nix pill . in the previous article we learned about nix environments . we installed software as a user , managed their profile , switched between generations , and queried the nix store . those are", " the very basics of system administration using nix . the nix language is used to write expressions that produce derivations . the nix - build tool is used to build derivations from an expression . even as a system administrator that wants to customize the installation , it ' s necessary to master nix . using nix for your jobs means you get the features we saw in the previous articles for free . the syntax of nix is quite unfamiliar , so looking at existing examples may lead you to think that there ' s a lot of magic happening . in reality , it ' s mostly about writing utility functions to make things convenient . on the other hand , the same", " syntax is great for describing packages , so learning the language itself will pay off when writing package expressions . important : in nix , everything is an expression , there are no statements . this is common in functional languages . important : values in nix are immutable . value types nix 2 . 0 contains a command named nix repl which is a simple command line tool for playing with the nix language . in fact , nix is a pure , lazy , functional language , not only a set of tools to manage derivations . the nix repl syntax is slightly different to nix syntax when it comes to assigning variables , but it shouldn ' t be", " confusing so long as you bear it in mind . i prefer to start with nix repl before cluttering your mind with more complex expressions . launch nix repl . first of all , nix supports basic arithmetic operations : + , - , * and / . ( to exit nix repl , use the command : q . help is available through the : ? command . ) nix - repl > 1 + 3 4 nix - repl > 7 - 4 3 nix - repl > 3 * 2 6 attempting to perform division in nix can lead to some surprises . nix - repl > 6 / 3 / home / nix / 6", " / 3 what happened ? recall that nix is not a general purpose language , it ' s a domain - specific language for writing packages . integer division isn ' t actually that useful when writing package expressions . nix parsed 6 / 3 as a relative path to the current directory . to get nix to perform division instead , leave a space after the / . alternatively , you can use builtins . div . nix - repl > 6 / 3 2 nix - repl > builtins . div 6 3 2 other operators are | | , & & and ! for booleans , and relational operators such as ! = , = =", " , < , > , < = , > = . in nix , < , > , < = and > = are not much used . there are also other operators we will see in the course of this series . nix has integer , floating point , string , path , boolean and null simple types . then there are also lists , sets and functions . these types are enough to build an operating system . nix is strongly typed , but it ' s not statically typed . that is , you cannot mix strings and integers , you must first do the conversion . as demonstrated above , expressions will be parsed as paths as long as there '", " s a slash not followed by a space . therefore to specify the current directory , use . / . in addition , nix also parses urls specially . not all urls or paths can be parsed this way . if a syntax error occurs , it ' s still possible to fallback to plain strings . literal urls and paths are convenient for additional safety . identifier there ' s not much to say here , except that dash ( - ) is allowed in identifiers . that ' s convenient since many packages use dash in their names . in fact : nix - repl > a - b error : undefined variable `", " a - b ' at ( string ) : 1 : 1 nix - repl > a - b error : undefined variable ` a ' at ( string ) : 1 : 1 as you can see , a - b is parsed as identifier , not as a subtraction . strings it ' s important to understand the syntax for strings . when learning to read nix expressions , you may find dollars ( $ ) ambiguous , but they are very important . strings are enclosed by double quotes ( \" ) , or two single quotes ( ' ' ) . nix - repl > \" foo \" \" foo \" nix - repl >", " ' ' foo ' ' \" foo \" in other languages like python you can also use single quotes for strings ( e . g . ' foo ' ) , but not in nix . it ' s possible to interpolate whole nix expressions inside strings with the $ { . . . } syntax and only that syntax , not $ foo or { $ foo } or anything else . nix - repl > foo = \" strval \" nix - repl > \" $ foo \" \" $ foo \" nix - repl > \" $ { foo } \" \" strval \" nix - repl > \" $ { 2 + 3 } \" error", " : cannot coerce an integer to a string , at ( string ) : 1 : 2 note : ignore the foo = \" strval \" assignment , special syntax in nix repl . as said previously , you cannot mix integers and strings . you need to explicitly include conversions . we ' ll see this later : function calls are another story . using the syntax with two single quotes is useful for writing double quotes inside strings without needing to escape them : nix - repl > ' ' test \" test ' ' \" test \\ \" test \" nix - repl > ' ' $ { foo } ' ' \" strval \" escaping $ { .", " . . } within double quoted strings is done with the backslash . within two single quotes , it ' s done with ' ' : nix - repl > \" \\ $ { foo } \" \" $ { foo } \" nix - repl > ' ' test ' ' $ { foo } test ' ' \" test $ { foo } test \" lists lists are a sequence of expressions delimited by space ( not comma ) : nix - repl > [ 2 \" foo \" true ( 2 + 3 ) ] [ 2 \" foo \" true 5 ] lists , like everything else in nix , are immutable . adding or", " removing elements from a list is possible , but will return a new list . attribute sets an attribute set is an association between string keys and nix values . keys can only be strings . when writing attribute sets you can also use unquoted identifiers as keys . nix - repl > s = { foo = \" bar \" ; a - b = \" baz \" ; \" 123 \" = \" num \" ; } nix - repl > s { \" 123 \" = \" num \" ; a - b = \" baz \" ; foo = \" bar \" ; } for those reading nix expressions from nixpkgs", " : do not confuse attribute sets with argument sets used in functions . to access elements in the attribute set : nix - repl > s . a - b \" baz \" nix - repl > s . \" 123 \" \" num \" yes , you can use strings to address keys which aren ' t valid identifiers . inside an attribute set you cannot normally refer to elements of the same attribute set : nix - repl > { a = 3 ; b = a + 4 ; } error : undefined variable ` a ' at ( string ) : 1 : 10 to do so , use recursive attribute sets : nix", " - repl > rec { a = 3 ; b = a + 4 ; } { a = 3 ; b = 7 ; } this is very convenient when defining packages , which tend to be recursive attribute sets . if expressions these are expressions , not statements . nix - repl > a = 3 nix - repl > b = 4 nix - repl > if a > b then \" yes \" else \" no \" \" no \" you can ' t have only the then branch , you must specify also the else branch , because an expression must have a value in all cases . let expressions this kind of expression is used to", " define local variables for inner expressions . nix - repl > let a = \" foo \" ; in a \" foo \" the syntax is : first assign variables , then in , then an expression which can use the defined variables . the value of the whole let expression will be the value of the expression after the in . nix - repl > let a = 3 ; b = 4 ; in a + b 7 let ' s write two let expressions , one inside the other : nix - repl > let a = 3 ; in let b = 4 ; in a + b 7 with let you cannot assign twice to the same variable . however", " , you can shadow outer variables : nix - repl > let a = 3 ; a = 8 ; in a error : attribute ` a ' at ( string ) : 1 : 12 already defined at ( string ) : 1 : 5 nix - repl > let a = 3 ; in let a = 8 ; in a 8 you cannot refer to variables in a let expression outside of it : nix - repl > let a = ( let c = 3 ; in c ) ; in c error : undefined variable ` c ' at ( string ) : 1 : 31 you can refer to variables in the let expression when assigning variables", " , like with recursive attribute sets : nix - repl > let a = 4 ; b = a + 5 ; in b 9 so beware when you want to refer to a variable from the outer scope , but it ' s also defined in the current let expression . the same applies to recursive attribute sets . with expression this kind of expression is something you rarely see in other languages . you can think of it like a more granular version of using from c + + , or from module import * from python . you decide per - expression when to include symbols into the scope . nix - repl > longname =", " { a = 3 ; b = 4 ; } nix - repl > longname . a + longname . b 7 nix - repl > with longname ; a + b 7 that ' s it , it takes an attribute set and includes symbols from it in the scope of the inner expression . of course , only valid identifiers from the keys of the set will be included . if a symbol exists in the outer scope and would also be introduced by the with , it will not be shadowed . you can however still refer to the attribute set : nix - repl > let a = 10 ; in with longname ; a", " + b 14 nix - repl > let a = 10 ; in with longname ; longname . a + b 7 laziness nix evaluates expressions only when needed . this is a great feature when working with packages . nix - repl > let a = builtins . div 4 0 ; b = 6 ; in b 6 since a is not needed , there ' s no error about division by zero , because the expression is not in need to be evaluated . that ' s why we can have all the packages defined on demand , yet have access to specific packages very quickly . next pill . . . we will talk about", " functions and imports . in this pill i ' ve tried to avoid function calls as much as possible , otherwise the post would have been too long .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ preface this is a ported version of the nix pills , a series of blog postswritten by luca bruno ( aka lethalman ) and originally published in 2014 and 2015 . it provides a tutorial introduction into the nix package manager and nix", "pkgs package collection , in the form of short chapters called ' pills ' . since the nix pills are considered a classic introduction to nix , an effort to port them to the current format was led by graham christensen ( aka grahamc / gchristensen ) and other contributors in 2017 . for an up - to - date version , please visit https : / / nixos . org / guides / nix - pills / . an epub version is also available . if you encounter problems , please report them on the nixos / nix - pills issue tracker . why you should give it a try introduction welcome to the first post of the", " \" nix in pills \" series . nix is a purely functional package manager and deployment system for posix . there ' s a lot of documentation that describe s what nix , nixos and related projects are . but the purpose of this post is to convince you to give nix a try . installing nixos is not required , but sometimes i may refer to nixos as a realworld example of nix usage forbuilding a whole operating system . rationale for this series the nix , nixpkgs , and nixos manuals along with the wiki are excellent resources for explaining how nix / nixos works , how you can use", " it , and how cool things are being done with it . however , at the beginning you may feel that some of the magic which happens behind the scenes is hard to grasp . this series aims to complement the existing explanations from the more formal documents . the following is a descript ion of nix . just as with pills , i ' ll try to be as short as possible . not being purely functional most , if not all , widely used package managers ( dpkg , rpm , . . . ) mutate the global state of the system . if a package foo - 1 . 0 installs a program to / usr / bin", " / foo , you cannot install foo - 1 . 1 as well , unless you change the installation paths or the binary name . but changing the binary names means breaking users of that binary . there are some attempts to mitigate this problem . debian , for example , partially solves the problem with the alternatives system . sowhile in theory it ' s possible with some current systems to install multiple versions of the same package , in practice it ' s very painful . let ' s say you need an nginx service and also an nginx - openresty service . you have to create a new package that changes all the paths to", " have , for example , an - openresty suffix . or suppose that you want to run two different instances of mysql : 5 . 2 and 5 . 5 . the same thing applies , plus you have to also make sure the two mysqlclient libraries do not collide . this is not impossible but it is very inconvenient . if you want to install two whole stacks of software like gnome 3 . 10 and gnome 3 . 12 , you can imagine the amount of work . from an administrator ' s point of view : you can use containers . the typical solution nowadays is to create a container per", " service , especially when different versions are needed . that somewhat solves the problem , but at a different level and with other drawbacks . for example , needing orchestration tools , setting up a shared cache of packages , and new machines to monitor rather than simple services . from a developer ' s point of view : you can use virtualenv for python , or jhbuild for gnome , or whatever else . but then how do you mix the two stacks ? how do you avoid recompiling the same thing when it could instead be shared ? also you need to set up your development tools to point to the different directories where", " libraries are installed . not only that , there ' s the risk that some of the software incorrectly uses system libraries . and so on . nix solves all this at the packaging level and solves it well . a single tool to rule them all . being purely functional nix makes no assumptions about the global state of the system . this has many advantages , but also some drawbacks of course . the core of a nix system is the nix store , usually installed under / nix / store , and some tools to manipulate the store . in nix there is the notion of a derivation rather than a package . the difference can be subtle at the beginning ,", " so i will often use the words interchangeably . derivations / packages are stored in the nix store as follows : / nix / store / \u00ab hash - name \u00bb , where the hash uniquely identifies the derivation ( this isn ' t quite true , it ' s a little more complex ) , and the name is the name of the derivation . let ' s take a bash derivation as an example : / nix / store / s4zia7hhqkin1di0f187b79sa2srhv6k - bash - 4 . 2 - p45 / . this is a directory in the nix store which contains", " bin / bash . what that means is that there ' s no / bin / bash , there ' s only that self - contained build output in the store . the same goes for coreutils and everything else . to make them convenient to use from the shell , nix will arrange for binaries to appear in your path as appropriate . what we have is basically a store of all packages ( with different versions occupying different locations ) , and everything in the nix store is immutable . in fact , there ' s no ldconfig cache either . so where does bash find libc ? $ ldd ` which bash ` libc", " . so . 6 = > / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib / libc . so . 6 ( 0x00007f0248cce000 ) it turns out that when bash was built , it was built against that specific version of glibc in the nix store , and at runtime it will require exactly that glibc version . don ' t be confused by the version in the derivation name : it ' s only a name for", " us humans . you may end up having two derivations with the same name but different hashes : it ' s the hash that really matters . what does all this mean ? it means that you could run mysql 5 . 2 with glibc - 2 . 18 , and mysql 5 . 5 with glibc - 2 . 19 . you could use your python module with python 2 . 7 compiled with gcc 4 . 6 and the same python module with python 3 compiled with gcc 4 . 8 , all in the same system . in other words : no dependency hell , not even a dependency resolution algorithm", " . straight dependencies from derivations to other derivations . from an administrator ' s point of view : if you want an old php version for one application , but want to upgrade the rest of the system , that ' s not painful any more . from a developer ' s point of view : if you want to develop webkit with llvm 3 . 4 and 3 . 3 , that ' s not painful any more . mutable vs . immutable when upgrading a library , most package managers replace it in - place . all new applications run afterwards with the new library without being recompiled . after all , they all refer", " dynamically to libc6 . so . since nix derivations are immutable , upgrading a library like glibc means recompiling all applications , because the glibc path to the nix store has been hardcoded . so how do we deal with security updates ? in nix we have some tricks ( still pure ) to solve this problem , but that ' s another story . another problem is that unless software has in mind a pure functional model , or can be adapted to it , it can be hard to compose applications at runtime . let ' s take firefox for example . on most systems , you install flash", " , and it starts working in firefox because firefox looks in a global path for plugins . in nix , there ' s no such global path for plugins . firefox therefore must know explicitly about the path to flash . the way we handle this problem is to wrap the firefox binary so that we can setup the necessary environment to make it find flash in the nix store . that will produce a new firefox derivation : be aware that it takes a few seconds , and it makes composition harder at runtime . there are no upgrade / downgrade script s for your data . it doesn ' t make", " sense with this approach , because there ' s no real derivation to be upgraded . with nix you switch to using other software with its own stack of dependencies , but there ' s no formal notion of upgrade or downgrade when doing so . if there is a data format change , then migrating to the new data format remains your own responsibility . conclusion nix lets you compose software at build time with maximum flexibility , and with builds being as reproducible as possible . not only that , due to its nature deploying systems in the cloud is so easy , consistent , and reliable that in the nixworld all existing self - containment and orchestration tools", " are deprecated by nixops . it however currently falls short when working with dynamic composition at runtime or replacing low level libraries , due to the need to rebuild dependencies . that may sound scary , however after running nixos on both a server and a laptop desktop , i ' m very satisfied so far . some of the architectural problems just need some man - power , other design problems still need to be solved as a community . considering nixpkgs ( github link ) is a completely new repository of all the existing software , with a completely fresh concept , and with few core developers but overall year - over - year increasing", " contributions , the current state is more than acceptable and beyond the experimental stage . in other words , it ' s worth your investment . next pill . . . . . . we will install nix on top of your current system ( i assume gnu / linux , but we also have osx users ) and start inspecting the installed software . install on your running system welcome to the second nix pill . in the first pill we briefly describe d nix . now we ' ll install nix on our running system and understand what changed in our system after the installation . if you ' re using nixos , nix is already installed ; you can skip to the", " next pill . for installation instruct ions , please refer to the nix reference manual on installing nix . installation these articles are not a tutorial on using nix . instead , we ' re going to walk through the nix system to understand the fundamentals . the first thing to note : derivations in the nix store refer to other derivations which are themselves in the nix store . they don ' t use libc from our system or anywhere else . it ' s a self - contained store of all the software we need to bootstrap up to any particular package . note : in a multi - user installation , such as the one used in", " nixos , the store is owned by root and multiple users can install and build software through a nix daemon . you can read more about multi - user installations here . the beginnings of the nix store start looking at the output of the install command : copying nix to / nix / store . . . . . . . . . . . . . . . . . . . . . . . . . . that ' s the / nix / store we were talking about in the first article . we ' re copying in the necessary software to bootstrap a nix system . you can see bash , coreutils , the c compiler tool", "chain , perl libraries , sqlite and nix itself with its own tools and libnix . you may have noticed that / nix / store can contain not only directories , but also files , still always in the form \u00ab hash - name \u00bb . the nix database right after copying the store , the installation process initializes a database : initialising nix database . . . yes , nix also has a database . it ' s stored under / nix / var / nix / db . it is a sqlite database that keeps track of the dependencies between derivations . the schema is very simple : there ' s a table of", " valid paths , mapping from an auto increment integer to a store path . then there ' s a dependency relation from path to paths upon which they depend . you can inspect the database by installing sqlite ( nix - env - ia sqlite - f ' < nixpkgs > ' ) and then running sqlite3 / nix / var / nix / db / db . sqlite . note : if this is the first time you ' re using nix after the initial installation , remember you must close and open your terminals first , so that your shell environment will be updated . important : never change / nix / store manually .", " if you do , then it will no longer be in sync with the sqlite db , unless you really know what you are doing . the first profile next in the installation , we encounter the concept of the profile : creating / home / nix / . nix - profile installing ' nix - 2 . 1 . 3 'building path ( s ) ` / nix / store / a7p1w3z2h8pl00ywvw6icr3g5l9vm5r7 - user - environment ' created 7 symlinks in user environment a profile in nix is a general and convenient concept for", " realizing rollbacks . profiles are used to compose components that are spread among multiple paths under a new unified path . not only that , but profiles are made up of multiple \" generations \" : they are versioned . whenever you change a profile , a new generation is created . generations can be switched and rolled back atomically , which makes them convenient for managing changes to your system . let ' s take a closer look at our profile : $ ls - l ~ / . nix - profile / bin - > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr", " - nix - 2 . 1 . 3 / bin [ . . . ] manifest . nix - > / nix / store / q8b5238akq07lj9gfb3qb5ycq4dxxiwm - env - manifest . nix [ . . . ] share - > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / share that nix - 2 . 1 . 3 derivation in the nix store is nix itself , with binaries and libraries . the", " process of \" installing \" the derivation in the profile basically reproduces the hierarchy of the nix - 2 . 1 . 3 store derivation in the profile by means of symbolic links . the contents of this profile are special , because only one program has been installed in our profile , therefore e . g . the bin directory points to the only program which has been installed ( nix itself ) . but that ' s only the contents of the latest generation of our profile . in fact , ~ / . nix - profile itself is a symbolic link to / nix / var / nix / profiles / default . in turn , that ' s a symlink to", " default - 1 - link in the same directory . yes , that means it ' s the first generation of the default profile . finally , default - 1 - link is a symlink to the nix store \" user - environment \" derivation that you saw printed during the installation process . we ' ll talk about manifest . nix more in the next article . nixpkgs expressions more output from the installer : downloading nix expressions from ` http : / / releases . nixos . org / nixpkgs / nixpkgs - 14 . 10pre46060 . a1a2851 / nixexprs . tar", " . xz ' . . . unpacking channels . . . created 2 symlinks in user environment modifying / home / nix / . profile . . . nix expressions arewritten in the nix language and used to describe packages and how to build them . nixpkgs is the repository containing all of the expressions : https : / / github . com / nixos / nixpkgs . the installer downloaded the package descript ions from commit a1a2851 . the second profile we discover is the channels profile . ~ / . nix - defexpr / channels points to / nix / var /", " nix / profiles / per - user / nix / channels which points to channels - 1 - link which points to a nix store directory containing the downloaded nix expressions . channels are a set of packages and expressions available for download . similar to debian stable and unstable , there ' s a stable and unstable channel . in this installation , we ' re tracking nixpkgs - unstable . don ' t worry about nix expressions yet , we ' ll get to them later . finally , for your convenience , the installer modified ~ / . profile to automatically enter the nix environment . what ~ / . nix - profile / etc / profile . d /", " nix . sh really does is simply to add ~ / . nix - profile / bin to path and ~ / . nix - defexpr / channels / nixpkgs to nix _ path . we ' ll discuss nix _ path later . read nix . sh , it ' s short . faq : can i change / nix to something else ? you can , but there ' s a good reason to keep using / nix instead of a different directory . all the derivations depend on other derivations by using absolute paths . we saw in the first article that bash referenced a glibc under a specific absolute path in / nix /", " store . you can see for yourself , don ' t worry if you see multiple bash derivations : $ ldd / nix / store / * bash * / bin / bash [ . . . ] keeping the store in / nix means we can grab the binary cache from nixos . org ( just like you grab packages from debian mirrors ) otherwise : * glibc would be installed under / foo / store * thus bash would need to point to glibc under / foo / store , instead of under / nix / store * so the binary cache can ' t help , because we need a different bash , and so we '", " d have to recompile everything ourselves . after all / nix is a sensible place for the store . conclusion we ' ve installed nix on our system , fully isolated and owned by the nix user as we ' re still coming to terms with this new system . we learned some new concepts like profiles and channels . in particular , with profiles we ' re able to manage multiple generations of a composition of packages ,while with channels we ' re able to download binaries from nixos . org . the installation put everything under / nix , and some symlinks in the nix user home . that ' s because every user is able to install", " and use software in her own environment . i hope i left nothing uncovered so that you think there ' s some kind of magic going on behind the scenes . it ' s all about putting components in the store and symlinking these components together . next pill . . . . . . we will enter the nix environment and learn how to interact with the store . enter the environment welcome to the third nix pill . in the second pill we installed nix on our running system . now we can finally play with it a little , these things also apply to nixos users . enter the environment if you ' re using nixos , you can skip to", " the next step . in the previous article we created a nix user , so let ' s start by switching to it with su - nix . if your ~ / . profile got evaluated , then you should now be able to run commands like nix - env and nix - store . if that ' s not the case : $ source ~ / . nix - profile / etc / profile . d / nix . sh to remind you , ~ / . nix - profile / etc points to the nix - 2 . 1 . 3 derivation . at this point , we are in our nix user profile . install something finally something practical ! installation into the nix", " environment is an interesting process . let ' s install hello , a simple cli tool which prints helloworld and is mainly used to test compilers and package installations . back to the installation : $ nix - env - i hello installing ' hello - 2 . 10 ' [ . . . ]building ' / nix / store / 0vqw0ssmh6y5zj48yg34gc6macr883xk - user - environment . drv ' . . . created 36 symlinks in user environment now you can run hello . things to notice : * we installed software as a user", " , and only for the nix user . * it created a new user environment . that ' s a new generation of our nix user profile . * the nix - env tool manages environments , profiles and their generations . * we installed hello by derivation name minus the version . i repeat : we specified the derivation name ( minus the version ) to install it . we can list generations without walking through the / nix hierarchy : $ nix - env - - list - generations 1 2014 - 07 - 24 09 : 23 : 30 2 2014 - 07 - 25 08 : 45 : 01 ( current ) listing installed derivations : $ nix - env", " - q nix - 2 . 1 . 3 hello - 2 . 10 so , where did hello really get installed ? which hello is ~ / . nix - profile / bin / hello which points to the store . we can also list the derivation paths with nix - env - q - - out - path . so that ' s what those derivation paths are called : the output of a build . path merging at this point you probably want to run man to get some documentation . even if you already have man system - wide outside of the nix environment , you can install and use it within nix with nix - env - i man - db", " . as usual , a new generation will be created , and ~ / . nix - profile will point to it . let ' s inspect the profile a bit : $ ls - l ~ / . nix - profile / dr - xr - xr - x 2 nix nix 4096 jan 1 1970 bin lrwxrwxrwx 1 nix nix 55 jan 1 1970 etc - > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / etc [ . . . ] now that '", " s interesting . when only nix - 2 . 1 . 3 was installed , bin was a symlink to nix - 2 . 1 . 3 . now that we ' ve actually installed some things ( man , hello ) , it ' s a real directory , not a symlink . $ ls - l ~ / . nix - profile / bin / [ . . . ] man - > / nix / store / 83cn9ing5sc6644h50dqzzfxcs07r2jn - man - 1 . 6g / bin / man [ . . . ] nix - env -", " > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env [ . . . ] hello - > / nix / store / 58r35bqb4f3lxbnbabq718svq9i2pda3 - hello - 2 . 10 / bin / hello [ . . . ] okay , that ' s clearer now . nix - env merged the paths from the installed derivations . which man points to the nix profile , rather than", " the system man , because ~ / . nix - profile / bin is at the head of $ path . rolling back and switching generation the last command installed man . we should be at generation 3 , unless you changed something in the middle . let ' s say we want to rollback to the old generation : $ nix - env - - rollback switching from generation 3 to 2 now nix - env - q does not list man anymore . ls - l ` which man ` should now be your system copy . enough with the rollback , let ' s go back to the most recent generation : $ nix - env - g", " 3 switching from generation 2 to 3 i invite you to read the manpage of nix - env . nix - env requires an operation to perform , then there are common options for all operations , as well as options specific to each operation . you can of course also uninstall and upgrade packages . querying the store so far we learned how to query and manipulate the environment . but all of the environment components point to the store . to query and manipulate the store , there ' s the nix - store command . we can do some interesting things , but we ' ll only see some queries for now . to show the direct", " runtime dependencies of hello : $ nix - store - q - - references ` which hello ` / nix / store / fg4yq8i8wd08xg3fy58l6q73cjy8hjr2 - glibc - 2 . 27 / nix / store / 58r35bqb4f3lxbnbabq718svq9i2pda3 - hello - 2 . 10 the argument to nix - store can be anything as long as it points to the nix store . it will follow symlinks . it may", " not make sense to you right now , but let ' s print reverse dependencies of hello : $ nix - store - q - - referrers ` which hello ` / nix / store / 58r35bqb4f3lxbnbabq718svq9i2pda3 - hello - 2 . 10 / nix / store / fhvy2550cpmjgcjcx5rzz328i0kfv3z3 - env - manifest . nix / nix / store / yzdk0xvr0b8dcwhi2nns", "6d75k2ha5208 - env - manifest . nix / nix / store / mp987abm20c70pl8p31ljw1r5by4xwfw - user - environment / nix / store / ppr3qbq7fk2m2pa49i2z3i32cvfhsv7p - user - environment was it what you expected ? it turns out that our environments depend upon hello . yes , that means that the environments are in the store , and since they contain symlinks to hello , therefore the environment depends", " upon hello . two environments were listed , generation 2 and generation 3 , since these are the ones that had hello installed in them . the manifest . nix file contains metadata about the environment , such as which derivations are installed . so that nix - env can list , upgrade or remove them . and yet again , the current manifest . nix can be found at ~ / . nix - profile / manifest . nix . closures the closures of a derivation is a list of all its dependencies , recursively , including absolutely everything necessary to use that derivation . $ nix - store - qr ` which man ` [ . . .", " ] copying all those derivations to the nix store of another machine makes you able to run man out of the box on that other machine . that ' s the base of deployment using nix , and you can already foresee the potential when deploying software in the cloud ( hint : nix - copy - closures and nix - store - - export ) . a nicer view of the closure : $ nix - store - q - - tree ` which man ` [ . . . ] with the above command , you can find out exactly why a runtime dependency , be it direct or indirect , exists for a given derivation . the same applies", " to environments . as an exercise , run nix - store - q - - tree ~ / . nix - profile , and see that the first children are direct dependencies of the user environment : the installed derivations , and the manifest . nix . dependency resolution there isn ' t anything like apt which solves a sat problem in order to satisfy dependencies with lower and upper bounds on versions . there ' s no need for this because all the dependencies are static : if a derivation x depends on a derivation y , then it always depends on it . a version of x which depended on z would be a different derivation . recovering the hard way", " $ nix - env - e ' * ' uninstalling ' hello - 2 . 10 ' uninstalling ' nix - 2 . 1 . 3 ' [ . . . ] oops , that uninstalled all derivations from the environment , including nix . that means we can ' t even run nix - env , what now ? previously we got nix - env from the environment . environments are a convenience for the user , but nix is still there in the store ! first , pick one nix - 2 . 1 . 3 derivation : ls / nix / store / * nix - 2 . 1 .", " 3 , say / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 . the first option is to rollback : $ / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env - - rollback the second option is to install nix , thus creating a new generation : $ / nix / store / ig31y9gfpp8pf3szdd7d", "4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env - i / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env channels so where are we getting packages from ? we said something about this already in the second article . there ' s a list of channels from which we get packages , although usually we use a single channel . the tool to manage channels is nix - channel . $ nix - channel - - list nixpk", "gs http : / / nixos . org / channels / nixpkgs - unstable if you ' re using nixos , you may not see any output from the above command ( if you ' re using the default ) , or you may see a channel whose name begins with \" nixos - \" instead of \" nixpkgs \" . that ' s essentially the contents of ~ / . nix - channels . note : ~ / . nix - channels is not a symlink to the nix store ! to update the channel run nix - channel - - update . that will download the new nix expressions ( descript ions of the", " packages ) , create a new generation of the channels profile and unpack it under ~ / . nix - defexpr / channels . this is quite similar to apt - get update . ( see this table for a rough mapping between ubuntu and nixos package management . ) conclusion we learned how to query the user environment and to manipulate it by installing and uninstalling software . upgrading software is also straightforward , as you can read in the manual ( nix - env - u will upgrade all packages in the environment ) . every time we change the environment , a new generation is created . switching between generations is easy and immediate", " . then we learned how to query the store . we inspected the dependencies and reverse dependencies of store paths . we saw how symlinks are used to compose paths from the nix store , a useful trick . a quick analogy with programming languages : you have the heap with all the objects , that corresponds to the nix store . you have objects that point to other objects , those correspond to derivations . this is a suggestive metaphor , but will it be the right path ? next pill . . . we will learn the basics of the nix language . the nix language is used to describe how to build derivations , and it", " ' s the basis for everything else , including nixos . therefore it ' s very important to understand both the syntax and the semantics of the language . the basics of the language welcome to the fourth nix pill . in the previous article we learned about nix environments . we installed software as a user , managed their profile , switched between generations , and queried the nix store . those are the very basics of system administration using nix . the nix language is used to write expressions that produce derivations . the nix - build tool is used to build derivations from an expression . even as a system administrator that wants to customize the installation , it '", " s necessary to master nix . using nix for your jobs means you get the features we saw in the previous articles for free . the syntax of nix is quite unfamiliar , so looking at existing examples may lead you to think that there ' s a lot of magic happening . in reality , it ' s mostly about writing utility functions to make things convenient . on the other hand , the same syntax is great for describing packages , so learning the language itself will pay off when writing package expressions . important : in nix , everything is an expression , there are no statements . this is common in functional languages . important : values in nix are immutable .", " value types nix 2 . 0 contains a command named nix repl which is a simple command line tool for playing with the nix language . in fact , nix is a pure , lazy , functional language , not only a set of tools to manage derivations . the nix repl syntax is slightly different to nix syntax when it comes to assigning variables , but it shouldn ' t be confusing so long as you bear it in mind . i prefer to start with nix repl before cluttering your mind with more complex expressions . launch nix repl . first of all , nix supports basic arithmetic operations : + , - , * and / .", " ( to exit nix repl , use the command : q . help is available through the : ? command . ) nix - repl > 1 + 3 4 nix - repl > 7 - 4 3 nix - repl > 3 * 2 6 attempting to perform division in nix can lead to some surprises . nix - repl > 6 / 3 / home / nix / 6 / 3 what happened ? recall that nix is not a general purpose language , it ' s a domain - specific language for writing packages . integer division isn ' t actually that useful when writing package expressions . nix parsed 6 / 3 as a relative path to the", " current directory . to get nix to perform division instead , leave a space after the / . alternatively , you can use builtins . div . nix - repl > 6 / 3 2 nix - repl > builtins . div 6 3 2 other operators are | | , & & and ! for booleans , and relational operators such as ! = , = = , < , > , < = , > = . in nix , < , > , < = and > = are not much used . there are also other operators we will see in the course of this series . nix has integer , floating point , string ,", " path , boolean and null simple types . then there are also lists , sets and functions . these types are enough to build an operating system . nix is strongly typed , but it ' s not statically typed . that is , you cannot mix strings and integers , you must first do the conversion . as demonstrated above , expressions will be parsed as paths as long as there ' s a slash not followed by a space . therefore to specify the current directory , use . / . in addition , nix also parses urls specially . not all urls or paths can be parsed this way . if a syntax error occurs , it '", " s still possible to fallback to plain strings . literal urls and paths are convenient for additional safety . identifier there ' s not much to say here , except that dash ( - ) is allowed in identifiers . that ' s convenient since many packages use dash in their names . in fact : nix - repl > a - b error : undefined variable ` a - b ' at ( string ) : 1 : 1 nix - repl > a - b error : undefined variable ` a ' at ( string ) : 1 : 1 as you can see , a - b is parsed as identifier ,", " not as a subtraction . strings it ' s important to understand the syntax for strings . when learning to read nix expressions , you may find dollars ( $ ) ambiguous , but they are very important . strings are enclosed by double quotes ( \" ) , or two single quotes ( ' ' ) . nix - repl > \" foo \" \" foo \" nix - repl > ' ' foo ' ' \" foo \" in other languages like python you can also use single quotes for strings ( e . g . ' foo ' ) , but not in nix . it ' s possible to interpolate whole nix expressions inside strings with the $", " { . . . } syntax and only that syntax , not $ foo or { $ foo } or anything else . nix - repl > foo = \" strval \" nix - repl > \" $ foo \" \" $ foo \" nix - repl > \" $ { foo } \" \" strval \" nix - repl > \" $ { 2 + 3 } \" error : cannot coerce an integer to a string , at ( string ) : 1 : 2 note : ignore the foo = \" strval \" assignment , special syntax in nix repl . as said previously , you cannot mix integers and strings . you need to explicitly", " include conversions . we ' ll see this later : function calls are another story . using the syntax with two single quotes is useful for writing double quotes inside strings without needing to escape them : nix - repl > ' ' test \" test ' ' \" test \\ \" test \" nix - repl > ' ' $ { foo } ' ' \" strval \" escaping $ { . . . } within double quoted strings is done with the backslash . within two single quotes , it ' s done with ' ' : nix - repl > \" \\ $ { foo } \" \" $ { foo } \" nix - repl > ' '", " test ' ' $ { foo } test ' ' \" test $ { foo } test \" lists lists are a sequence of expressions delimited by space ( not comma ) : nix - repl > [ 2 \" foo \" true ( 2 + 3 ) ] [ 2 \" foo \" true 5 ] lists , like everything else in nix , are immutable . adding or removing elements from a list is possible , but will return a new list . attribute sets an attribute set is an association between string keys and nix values . keys can only be strings . when writing attribute sets you can also use unquoted identifiers as keys", " . nix - repl > s = { foo = \" bar \" ; a - b = \" baz \" ; \" 123 \" = \" num \" ; } nix - repl > s { \" 123 \" = \" num \" ; a - b = \" baz \" ; foo = \" bar \" ; } for those reading nix expressions from nixpkgs : do not confuse attribute sets with argument sets used in functions . to access elements in the attribute set : nix - repl > s . a - b \" baz \" nix - repl > s . \" 123 \" \" num \" yes , you", " can use strings to address keys which aren ' t valid identifiers . inside an attribute set you cannot normally refer to elements of the same attribute set : nix - repl > { a = 3 ; b = a + 4 ; } error : undefined variable ` a ' at ( string ) : 1 : 10 to do so , use recursive attribute sets : nix - repl > rec { a = 3 ; b = a + 4 ; } { a = 3 ; b = 7 ; } this is very convenient when defining packages , which tend to be recursive attribute sets . if expressions these are expressions , not", " statements . nix - repl > a = 3 nix - repl > b = 4 nix - repl > if a > b then \" yes \" else \" no \" \" no \" you can ' t have only the then branch , you must specify also the else branch , because an expression must have a value in all cases . let expressions this kind of expression is used to define local variables for inner expressions . nix - repl > let a = \" foo \" ; in a \" foo \" the syntax is : first assign variables , then in , then an expression which can use the defined variables . the value of the whole let expression", " will be the value of the expression after the in . nix - repl > let a = 3 ; b = 4 ; in a + b 7 let ' s write two let expressions , one inside the other : nix - repl > let a = 3 ; in let b = 4 ; in a + b 7 with let you cannot assign twice to the same variable . however , you can shadow outer variables : nix - repl > let a = 3 ; a = 8 ; in a error : attribute ` a ' at ( string ) : 1 : 12 already defined at ( string ) : 1 : 5 nix - repl >", " let a = 3 ; in let a = 8 ; in a 8 you cannot refer to variables in a let expression outside of it : nix - repl > let a = ( let c = 3 ; in c ) ; in c error : undefined variable ` c ' at ( string ) : 1 : 31 you can refer to variables in the let expression when assigning variables , like with recursive attribute sets : nix - repl > let a = 4 ; b = a + 5 ; in b 9 so beware when you want to refer to a variable from the outer scope , but it ' s also defined in the", " current let expression . the same applies to recursive attribute sets . with expression this kind of expression is something you rarely see in other languages . you can think of it like a more granular version of using from c + + , or from module import * from python . you decide per - expression when to include symbols into the scope . nix - repl > longname = { a = 3 ; b = 4 ; } nix - repl > longname . a + longname . b 7 nix - repl > with longname ; a + b 7 that ' s it , it takes an attribute set and includes symbols from", " it in the scope of the inner expression . of course , only valid identifiers from the keys of the set will be included . if a symbol exists in the outer scope and would also be introduced by the with , it will not be shadowed . you can however still refer to the attribute set : nix - repl > let a = 10 ; in with longname ; a + b 14 nix - repl > let a = 10 ; in with longname ; longname . a + b 7 laziness nix evaluates expressions only when needed . this is a great feature when working with packages . nix - repl > let", " a = builtins . div 4 0 ; b = 6 ; in b 6 since a is not needed , there ' s no error about division by zero , because the expression is not in need to be evaluated . that ' s why we can have all the packages defined on demand , yet have access to specific packages very quickly . next pill . . . we will talk about functions and imports . in this pill i ' ve tried to avoid function calls as much as possible , otherwise the post would have been too long . functions and imports welcome to the fifth nix pill . in the previous fourth pill we touched the nix language for a moment", " . we introduced basic types and values of the nix language , and basic expressions such as if , with and let . i invite you to re - read about these expressions and play with them in the repl . functions help to build reusable components in a big repository like nixpkgs . the nix manual has a great explanation of functions . let ' s go : pill on one hand , nix manual on the other hand . i remind you how to enter the nix environment : source ~ / . nix - profile / etc / profile . d / nix . sh nameless and single parameter functions are anonymous ( lambdas ) , and", " only have a single parameter . the syntax is extremely simple . type the parameter name , then \" : \" , then the body of the function . nix - repl > x : x * 2 \u00ab lambda \u00bb so here we defined a function that takes a parameter x , and returns x * 2 . the problem is that we cannot use it in any way , because it ' s unnamed . . . joke ! we can store functions in variables . nix - repl > double = x : x * 2 nix - repl > double \u00ab lambda \u00bb nix - repl > double 3 6 as usual , please ignore the special syntax for assignments", " inside nix repl . so , we defined a function x : x * 2 that takes one parameter x , and returns x * 2 . this function is then assigned to the variable double . finally we did our first function call : double 3 . big note : it ' s not like many other programming languages where you write double ( 3 ) . it really is double 3 . in summary : to call a function , name the variable , then space , then the argument . nothing else to say , it ' s as easy as that . more than one parameter how do we create a function that accepts more than one parameter ? for people not used", " to functional programming , this may take awhile to grasp . let ' s do it step by step . nix - repl > mul = a : ( b : a * b ) nix - repl > mul \u00ab lambda \u00bb nix - repl > mul 3 \u00ab lambda \u00bb nix - repl > ( mul 3 ) 4 12 we defined a function that takes the parameter a , the body returns another function . this other function takes a parameter b and returns a * b . therefore , calling mul 3 returns this kind of function : b : 3 * b . in turn , we call the returned function with 4", " , and get the expected result . you don ' t have to use parentheses at all , nix has sane priorities when parsing the code : nix - repl > mul = a : b : a * b nix - repl > mul \u00ab lambda \u00bb nix - repl > mul 3 \u00ab lambda \u00bb nix - repl > mul 3 4 12 nix - repl > mul ( 6 + 7 ) ( 8 + 9 ) 221 much more readable , you don ' t even notice that functions only receive one argument . since the argument is separated by a space , to pass more complex expressions you need parentheses .", " in other common languages you would write mul ( 6 + 7 , 8 + 9 ) . given that functions have only one parameter , it is straightforward to use partial application : nix - repl > foo = mul 3 nix - repl > foo 4 12 nix - repl > foo 5 15 we stored the function returned by mul 3 into a variable foo , then reused it . argument set now this is a very cool feature of nix . it is possible to pattern match over a set in the parameter . we write an alternative version of mul = a : b : a * b first by using a set as argument ,", " then using pattern matching . nix - repl > mul = s : s . a * s . b nix - repl > mul { a = 3 ; b = 4 ; } 12 nix - repl > mul = { a , b } : a * b nix - repl > mul { a = 3 ; b = 4 ; } 12 in the first case we defined a function that accepts a single parameter . we then access attributes a and b from the given set . note how the parentheses - less syntax for function calls is very elegant in this case , instead of doing mul ( { a = 3", " ; b = 4 ; } ) in other languages . in the second case we defined an argument set . it ' s like defining a set , except without values . we require that the passed set contains the keys a and b . then we can use those a and b in the function body directly . nix - repl > mul = { a , b } : a * b nix - repl > mul { a = 3 ; b = 4 ; c = 6 ; } error : anonymous function at ( string ) : 1 : 2 called with unexpected argument ` c ' , at ( string ) : 1 : 1 nix -", " repl > mul { a = 3 ; } error : anonymous function at ( string ) : 1 : 2 called without required argument ` b ' , at ( string ) : 1 : 1 only a set with exactly the attributes required by the function is accepted , nothing more , nothing less . default and variadic attributes it is possible to specify default values of attributes in the argument set : nix - repl > mul = { a , b ? 2 } : a * b nix - repl > mul { a = 3 ; } 6 nix - repl > mul { a = 3 ; b = 4 ;", " } 12 also you can allow passing more attributes ( variadic ) than the expected ones : nix - repl > mul = { a , b , . . . } : a * b nix - repl > mul { a = 3 ; b = 4 ; c = 2 ; } however , in the function body you cannot access the \" c \" attribute . the solution is to give a name to the given set with the @ - pattern : nix - repl > mul = s @ { a , b , . . . } : a * b * s . c nix - repl > mul {", " a = 3 ; b = 4 ; c = 2 ; } 24 that ' s it , you give a name to the whole parameter with name @ before the set pattern . advantages of using argument sets : * named unordered arguments : you don ' t have to remember the order of the arguments . * you can pass sets , that adds a whole new layer of flexibility and convenience . disadvantages : * partial application does not work with argument sets . you have to specify the whole attribute set , not part of it . you may find similarities with python * * kwargs . imports the import function is built - in and provides a", " way to parse a . nix file . the natural approach is to define each component in a . nix file , then compose by importing these files . let ' s start with the bare metal . a . nix : 3 b . nix : 4 mul . nix : a : b : a * b nix - repl > a = import . / a . nix nix - repl > b = import . / b . nix nix - repl > mul = import . / mul . nix nix - repl > mul a b 12 yes it ' s really that simple . you import a file , and it", " gets parsed as an expression . note that the scope of the imported file does not inherit the scope of the importer . test . nix : x nix - repl > let x = 5 ; in import . / test . nix error : undefined variable ` x ' at / home / lethal / test . nix : 1 : 1 so how do we pass information to the module ? use functions , like we did with mul . nix . a more complex example : test . nix : { a , b ? 3 , truemsg ? \" yes \" , falsemsg ? \" no \" } : if a > b then", " builtins . trace truemsg true else builtins . trace falsemsg false nix - repl > import . / test . nix { a = 5 ; truemsg = \" ok \" ; } trace : ok true explaining : * in test . nix we return a function . it accepts a set , with default attributes b , truemsg and falsemsg . * builtins . trace is a built - in function that takes two arguments . the first is the message to display , the second is the value to return . it ' s usually used for debugging purposes . * then we import test . nix , and", " call the function with that set . so when is the message shown ? only when it needs to be evaluated . next pill . . . we will finally write our first derivation . our first derivation welcome to the sixth nix pill . in the previous fifth pill we introduced functions and imports . functions and imports are very simple concepts that allow forbuilding complex abstractions and composition of modules to build a flexible nix system . in this post we finally arrived to writing a derivation . derivations are thebuilding blocks of a nix system , from a file system view point . the nix language is used to describe such derivations . i remind you how to enter", " the nix environment : source ~ / . nix - profile / etc / profile . d / nix . sh the derivation function the derivation built - in function is used to create derivations . i invite you to read the link in the nix manual about the derivation built - in . a derivation from a nix language view point is simply a set , with some attributes . therefore you can pass the derivation around with variables like anything else . that ' s where the real power comes in . the derivation function receives a set as its first argument . this set requires at least the following three attributes : * name : the name of the derivation . in the nix", " store the format is hash - name , that ' s the name . * system : is the name of the system in which the derivation can be built . for example , x86 _ 64 - linux . * builder : is the binary program that builds the derivation . first of all , what ' s the name of our system as seen by nix ? nix - repl > builtins . currentsystem \" x86 _ 64 - linux \" let ' s try to fake the name of the system : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system =", " \" mysystem \" ; } nix - repl > d \u00ab derivation / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv \u00bb oh oh , what ' s that ? did it build the derivation ? no it didn ' t , but it did create the . drv file . nix repl does not build derivations unless you tell it to do so . digression about . drv files what ' s that . drv file ? it is the specification of how to build the derivation , without", " all the nix language fuzz . before continuing , some analogies with the c language : * . nix files are like . c files . * . drv files are intermediate files like . o files . the . drv describe s how to build a derivation ; it ' s the bare minimum information . * out paths are then the product of the build . both drv paths and out paths are stored in the nix store as you can see . what ' s in that . drv file ? you can read it , but it ' s better to pretty print it : note : if your version of nix doesn ' t have nix", " derivation show , use nix show - derivation instead . $ nix derivation show / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv { \" / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / 40s0qmrfb45vlh6610rk29ym31", "8dswdr - myname \" } } , \" inputsrcs \" : [ ] , \" inputdrvs \" : { } , \" platform \" : \" mysystem \" , \" builder \" : \" mybuilder \" , \" args \" : [ ] , \" env \" : { \" builder \" : \" mybuilder \" , \" name \" : \" myname \" , \" out \" : \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" , \" system \" : \" mysy", "stem \" } } } ok , we can see there ' s an out path , but it does not exist yet . we never told nix to build it , but we know beforehand where the build output will be . why ? think , if nix ever built the derivation just because we accessed it in nix , we would have to wait a long time if it was , say , firefox . that ' s why nix let us know the path beforehand and kept evaluating the nix expressions , but it ' s still empty because no build was ever made . important : the hash of the out path is based solely on the input derivations in", " the current version of nix , not on the contents of the build product . it ' s possible however to have content - addressable derivations for e . g . tarballs as we ' ll see later on . many things are empty in that . drv , however i ' ll write a summary of the . drv format for you : 1 . the output paths ( there can be multiple ones ) . by default nix creates one out path called \" out \" . 2 . the list of input derivations . it ' s empty because we are not referring to any other derivation . otherwise , there would be a list of other . dr", "v files . 3 . the system and the builder executable ( yes , it ' s a fake one ) . 4 . then a list of environment variables passed to the builder . that ' s it , the minimum necessary information to build our derivation . important note : the environment variables passed to the builder are just those you see in the . drv plus some other nix related configuration ( number of cores , temp dir , . . . ) . the builder will not inherit any variable from your running shell , otherwise builds would suffer from non - determinism . back to our fake derivation . let ' s build our really fake derivation", " : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system = \" mysystem \" ; } nix - repl > : b d [ . . . ] these derivations will be built : / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drvbuilding path ( s ) ` / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname '", " error : a ` mysystem ' is required to build ` / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv ' , but i am a ` x86 _ 64 - linux ' the : b is a nix repl specific command to build a derivation . you can see more commands with : ? . so in the output you can see that it takes the . drv as information on how to build the derivation . then it says it ' s trying to produce our out path . finally the error we", " were waiting for : that derivation can ' t be built on our system . we ' re doing the build inside nix repl , but what if we don ' t want to use nix repl ? you can realise a . drv with : $ nix - store - r / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv you will get the same output as before . let ' s fix the system attribute : nix - repl > d = derivation { name = \" myname \" ; builder = \" my", "builder \" ; system = builtins . currentsystem ; } nix - repl > : b d [ . . . ] build error : invalid file name ` mybuilder ' a step forward : of course , that mybuilder executable does not really exist . stop for a moment . what ' s in a derivation set it is useful to start by inspecting the return value from the derivation function . in this case , the returned value is a plain set : nix - repl > d = derivation { name = \" myname \" ; builder = \" mybuilder \" ; system = \" my", "system \" ; } nix - repl > builtins . isattrs d true nix - repl > builtins . attrnames d [ \" all \" \" builder \" \" drvattrs \" \" drvpath \" \" name \" \" out \" \" outpath \" \" outputname \" \" system \" \" type \" ] you can guess what builtins . isattrs does ; it returns true if the argument is a set . while builtins . attrnames returns a list of keys of the given set . some kind of reflection , you might say . start from drvattrs : nix", " - repl > d . drvattrs { builder = \" mybuilder \" ; name = \" myname \" ; system = \" mysystem \" ; } that ' s basically the input we gave to the derivation function . also the d . name , d . system and d . builder attributes are exactly the ones we gave as input . nix - repl > ( d = = d . out ) true so out is just the derivation itself , it seems weird but the reason is that we only have one output from the derivation . that ' s also the reason why d . all is a singleton . we '", " ll see multiple outputs later . the d . drvpath is the path of the . drv file : / nix / store / z3hhlxbckx4g3n9sw91nnvlkjvyw754p - myname . drv . something interesting is the type attribute . it ' s \" derivation \" . nix does add a little of magic to sets with type derivation , but not that much . to help you understand , you can create yourself a set with that type , it ' s a simple set : nix - repl > { type = \" derivation \" ; } \u00ab derivation", " ? ? ? \u00bb of course it has no other information , so nix doesn ' t know what to say : - ) but you get it , the type = \" derivation \" is just a convention for nix and for us to understand the set is a derivation . when writing packages , we are interested in the outputs . the other metadata is needed for nix to know how to create the drv path and the out path . the outpath attribute is the build path in the nix store : / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname . referring", " to other derivations just like dependencies in other package managers , how do we refer to other packages ? how do we refer to other derivations in terms of files on the disk ? we use the outpath . the outpath describe s the location of the files of that derivation . to make it more convenient , nix is able to do a conversion from a derivation set to a string . nix - repl > d . outpath \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" nix - repl > builtins . to", "string d \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" nix does the \" set to string conversion \" as long as there is the outpath attribute ( much like a tostring method in other languages ) : nix - repl > builtins . tostring { outpath = \" foo \" ; } \" foo \" nix - repl > builtins . tostring { a = \" b \" ; } error : cannot coerce a set to a string , at ( string ) : 1 : 1 say we", " want to use binaries from coreutils ( ignore the nixpkgs etc . ) : nix - repl > : l < nixpkgs > added 3950 variables . nix - repl > coreutils \u00ab derivation / nix / store / 1zcs1y4n27lqs0gw4v038i303pb89rw6 - coreutils - 8 . 21 . drv \u00bb nix - repl > builtins . tostring coreutils \" / nix / store / 8w4cbiy7wqvaqsnsnb3z", "vabq1cp2zhyz - coreutils - 8 . 21 \" apart from the nixpkgs stuff , just think we added to the scope a series of variables . one of them is coreutils . it is the derivation of the coreutils package you all know of from other linux distributions . it contains basic binaries for gnu / linux systems ( you may have multiple derivations of coreutils in the nix store , no worries ) : $ ls / nix / store / * coreutils * / bin [ . . . ] i remind you , inside strings it ' s possible to inter", "polate nix expressions with $ { . . . } : nix - repl > \" $ { d } \" \" / nix / store / 40s0qmrfb45vlh6610rk29ym318dswdr - myname \" nix - repl > \" $ { coreutils } \" \" / nix / store / 8w4cbiy7wqvaqsnsnb3zvabq1cp2zhyz - coreutils - 8 . 21 \" that ' s very convenient , because then we could refer to e . g . the bin / true binary like", " this : nix - repl > \" $ { coreutils } / bin / true \" \" / nix / store / 8w4cbiy7wqvaqsnsnb3zvabq1cp2zhyz - coreutils - 8 . 21 / bin / true \" an almost working derivation in the previous attempt we used a fake builder , mybuilder which obviously does not exist . but we can use for example bin / true , which always exits with 0 ( success ) . nix - repl > : l < nixpkgs > nix - repl > d = derivation { name", " = \" myname \" ; builder = \" $ { coreutils } / bin / true \" ; system = builtins . currentsystem ; } nix - repl > : b d [ . . . ] builder for ` / nix / store / qyfrcd53wmc0v22ymhhd5r6sz5xmdc8a - myname . drv ' failed to produce output path ` / nix / store / ly2k1vswbfmswr33hw0kf0ccilrpisnk - myname ' another step forward , it executed the builder ( bin", " / true ) , but the builder did not create the out path of course , it just exited with 0 . obvious note : every time we change the derivation , a new hash is created . let ' s examine the new . drv now that we referred to another derivation : $ nix derivation show / nix / store / qyfrcd53wmc0v22ymhhd5r6sz5xmdc8a - myname . drv { \" / nix / store / qyfrcd53wmc0v22ymhhd5r6sz5xmdc8a - myname . dr", "v \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / ly2k1vswbfmswr33hw0kf0ccilrpisnk - myname \" } } , \" inputsrcs \" : [ ] , \" inputdrvs \" : { \" / nix / store / hixdnzz2wp75x1jy65cysq06yl74vx7q - coreutils - 8 . 29 . drv \" : [ \" out \" ] } , \" platform \" : \" x86 _", " 64 - linux \" , \" builder \" : \" / nix / store / qrxs7sabhqcr3j9ai0j0cp58zfnny0jz - coreutils - 8 . 29 / bin / true \" , \" args \" : [ ] , \" env \" : { \" builder \" : \" / nix / store / qrxs7sabhqcr3j9ai0j0cp58zfnny0jz - coreutils - 8 . 29 / bin / true \" , \" name \" : \" myname \" , \" out", " \" : \" / nix / store / ly2k1vswbfmswr33hw0kf0ccilrpisnk - myname \" , \" system \" : \" x86 _ 64 - linux \" } } } aha ! nix added a dependency to our myname . drv , it ' s the coreutils . drv . before doing our build , nix should build the coreutils . drv . but since coreutils is already in our nix store , no build is needed , it ' s already there with out path / nix / store / qrxs7sabh", "qcr3j9ai0j0cp58zfnny0jz - coreutils - 8 . 29 . when is the derivation built nix does not build derivations during evaluation of nix expressions . in fact , that ' s why we have to do \" : b drv \" in nix repl , or use nix - store - r in the first place . an important separation is made in nix : * instantiate / evaluation time : the nix expression is parsed , interpreted and finally returns a derivation set . during evaluation , you can refer to other derivations because nix will create . drv files and we", " will know out paths beforehand . this is achieved with nix - instantiate . * realise / build time : the . drv from the derivation set is built , firstbuilding . drv inputs ( build dependencies ) . this is achieved with nix - store - r . think of it as of compile time and link time like with c / c + + projects . you first compile all source files to object files . then link object files in a single executable . in nix , first the nix expression ( usually in a . nix file ) is compiled to . drv , then each . drv is built and the product", " is installed in the relative out paths . conclusion is it that complicated to create a package for nix ? no , it ' s not . we ' re walking through the fundamentals of nix derivations , to understand how they work , how they are represented . packaging in nix is certainly easier than that , but we ' re not there yet in this post . more nix pills are needed . with the derivation function we provide a set of information on how to build a package , and we get back the information about where the package was built . nix converts a set to a string when there ' s an outpath ; that ' s very convenient .", " with that , it ' s easy to refer to other derivations . when nix builds a derivation , it first creates a . drv file from a derivation expression , and uses it to build the output . it does so recursively for all the dependencies ( inputs ) . it \" executes \" the . drv files like a machine . not much magic after all . next pill . . . we will finally write our first working derivation . yes , this post is about \" our first derivation \" , but i never said it was a working one ; ) working derivation introduction welcome to the seventh nix pill . in the previous sixth pill", " we introduced the notion of derivation in the nix language - - - how to define a raw derivation and how to ( try to ) build it . in this post we continue along the path , by creating a derivation that actually builds something . then , we try to package a real program : we compile a simple c file and create a derivation out of it , given a blessed toolchain . i remind you how to enter the nix environment : source ~ / . nix - profile / etc / profile . d / nix . sh using a script as a builder what ' s the easiest way to run a sequence of commands forbuilding something", " ? a bash script . we write a custom bash script , and we want it to be our builder . given a builder . sh , we want the derivation to run bash builder . sh . we don ' t use hash bangs in builder . sh , because at the time we are writing it we do not know the path to bash in the nix store . yes , even bash is in the nix store , everything is there . we don ' t even use / usr / bin / env , because then we lose the cool stateless property of nix . not to mention that path gets cleared whenbuilding , so it wouldn '", " t find bash anyway . in summary , we want the builder to be bash , and pass it an argument , builder . sh . turns out the derivation function accepts an optional args attribute which is used to pass arguments to the builder executable . first of all , let ' s write our builder . sh in the current directory : declare - xp echo foo > $ out the command declare - xp lists exported variables ( declare is a builtin bash function ) . as we covered in the previous pill , nix computes the output path of the derivation . the resulting . drv file contains a list of environment variables passed to the builder .", " one of these is $ out . what we have to do is create something in the path $ out , be it a file or a directory . in this case we are creating a file . in addition , we print out the environment variables during the build process . we cannot use env for this , because env is part of coreutils and we don ' t have a dependency to it yet . we only have bash for now . like for coreutils in the previous pill , we get a blessed bash for free from our magic nixpkgs stuff : nix - repl > : l < nixpkgs > added", " 3950 variables . nix - repl > \" $ { bash } \" \" / nix / store / ihmkc7z2wqk3bbipfnlh0yjrlfkkgnv6 - bash - 4 . 2 - p45 \" so with the usual trick , we can refer to bin / bash and create our derivation : nix - repl > d = derivation { name = \" foo \" ; builder = \" $ { bash } / bin / bash \" ; args = [ . / builder . sh ] ; system = builtins . currentsystem ; } nix - repl >", " : b d [ 1 built , 0 . 0 mib dl ] this derivation produced the following outputs : out - > / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo we did it ! the contents of / nix / store / w024zci0x1hh1wj6gjq0jagkc1sgrf5r - foo is really foo . we ' ve built our first derivation . note that we used . / builder . sh and not \" . / builder . sh \" . this way", " , it is parsed as a path , and nix performs some magic which we will cover later . try using the string version and you will find that it cannot find builder . sh . this is because it tries to find it relative to the temporary build directory . the builder environment we can use nix - store - - read - log to see the logs our builder produced : $ nix - store - - read - log / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo declare - x home = \" / homeless - shelter \" declare - x", " nix _ build _ cores = \" 4 \" declare - x nix _ build _ top = \" / tmp / nix - build - foo . drv - 0 \" declare - x nix _ log _ fd = \" 2 \" declare - x nix _ store = \" / nix / store \" declare - x oldpwd declare - x path = \" / path - not - set \" declare - x pwd = \" / tmp / nix - build - foo . drv - 0 \" declare - x shlvl = \" 1 \" declare - x temp = \" / tmp / nix - build - foo", " . drv - 0 \" declare - x tempdir = \" / tmp / nix - build - foo . drv - 0 \" declare - x tmp = \" / tmp / nix - build - foo . drv - 0 \" declare - x tmpdir = \" / tmp / nix - build - foo . drv - 0 \" declare - x builder = \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" declare -", " x name = \" foo \" declare - x out = \" / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo \" declare - x system = \" x86 _ 64 - linux \" let ' s inspect those environment variables printed during the build process . * $ home is not your home directory , and / homeless - shelter doesn ' t exist at all . we force packages not to depend on $ home during the build process . * $ path plays the same game as $ home * $ nix _ build _ cores and $ nix _ store are", " nix configuration options * $ pwd and $ tmp clearly show that nix created a temporary build directory * then $ builder , $ name , $ out , and $ system are variables set due to the . drv file ' s contents . and that ' s how we were able to use $ out in our derivation and put stuff in it . it ' s like nix reserved a slot in the nix store for us , and we must fill it . in terms of autotools , $ out will be the - - prefix path . yes , not the make destdir , but the - - prefix . that ' s the essence", " of stateless packaging . you don ' t install the package in a global common path under / , you install it in a local isolated path under your nix store slot . the . drv contents we added something else to the derivation this time : the args attribute . let ' s see how this changed the . drv compared to the previous pill : $ nix derivation show / nix / store / i76pr1cz0za3i9r6xq518bqqvd2raspw - foo . drv { \" / nix / store / i76pr1cz0za3i9r", "6xq518bqqvd2raspw - foo . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo \" } } , \" inputsrcs \" : [ \" / nix / store / lb0n38r2b20r8rl1k45a7s4pj6ny22f7 - builder . sh \" ] , \" inputdrvs \" : { \" / nix / store /", " hcgwbx42mcxr7ksnv0i1fg7kw6jvxshb - bash - 4 . 4 - p19 . drv \" : [ \" out \" ] } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" , \" args \" : [ \" / nix / store / lb0n38r", "2b20r8rl1k45a7s4pj6ny22f7 - builder . sh \" ] , \" env \" : { \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin / bash \" , \" name \" : \" foo \" , \" out \" : \" / nix / store / gczb4qrag22harvv693wwnflqy7lx5pb - foo \"", " , \" system \" : \" x86 _ 64 - linux \" } } } much like the usual . drv , except that there ' s a list of arguments in there passed to the builder ( bash ) with builder . sh . . . in the nix store . . ? nix automatically copies files or directories needed for the build into the store to ensure that they are not changed during the build process and that the deployment is stateless and independent of thebuilding machine . builder . sh is not only in the arguments passed to the builder , it ' s also in the input sources . given that builder . sh is a plain file ,", " it has no . drv associated with it . the store path is computed based on the filename and on the hash of its contents . store paths are covered in detail in a later pill . packaging a simple c program start off by writing a simple c program called simple . c : void main ( ) { puts ( \" simple ! \" ) ; } and its simple _ builder . sh : export path = \" $ coreutils / bin : $ gcc / bin \" mkdir $ out gcc - o $ out / simple $ src don ' t worry too much about where those variables come from yet ; let '", " s write the derivation and build it : nix - repl > : l < nixpkgs > nix - repl > simple = derivation { name = \" simple \" ; builder = \" $ { bash } / bin / bash \" ; args = [ . / simple _ builder . sh ] ; gcc = gcc ; coreutils = coreutils ; src = . / simple . c ; system = builtins . currentsystem ; } nix - repl > : b simple this derivation produced the following outputs : out - > / nix / store / ni66p4jfqksbmsl", "616llx3fbs1d232d4 - simple now you can run / nix / store / ni66p4jfqksbmsl616llx3fbs1d232d4 - simple / simple in your shell . explanation we added two new attributes to the derivation call , gcc and coreutils . in gcc = gcc ; , the name on the left is the name in the derivation set , and the name on the right refers to the gcc derivation from nixpkgs . the same applies for coreutils . we also added the src attribute ,", " nothing magical - - - it ' s just a name , to which the path . / simple . c is assigned . like simple - builder . sh , simple . c will be added to the store . the trick : every attribute in the set passed to derivation will be converted to a string and passed to the builder as an environment variable . this is how the builder gains access to coreutils and gcc : when converted to strings , the derivations evaluate to their output paths , and appending / bin to these leads us to their binaries . the same goes for the src variable . $ src is the path to simple", " . c in the nix store . as an exercise , pretty print the . drv file . you ' ll see simple _ builder . sh and simple . c listed in the input derivations , along with bash , gcc and coreutils . drv files . the newly added environment variables describe d above will also appear . in simple _ builder . sh we set the path for gcc and coreutils binaries , so that our build script can find the necessary utilities like mkdir and gcc . we then create $ out as a directory and place the binary inside it . note that gcc is found via", " the path environment variable , but it could equivalently be referenced explicitly using $ gcc / bin / gcc . enough of nix repl drop out of nix repl and write a file simple . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" simple \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / simple _ builder . sh ] ; gcc = pkgs . gcc ; coreutils = pkgs . coreutils ; src = . / simple . c ; system", " = builtins . currentsystem ; } now you can build it with nix - build simple . nix . this will create a symlink result in the current directory , pointing to the out path of the derivation . nix - build does two jobs : * nix - instantiate : parse and evaluate simple . nix and return the . drv file corresponding to the parsed derivation set * nix - store - r : realise the . drv file , which actually builds it . finally , it creates the symlink . in the second line of simple . nix , we have an import function call . recall that import accepts one argument", " , a nix file to load . in this case , the contents of the file evaluate to a function . afterwards , we call the function with the empty set . we saw this already in the fifth pill . to reiterate : import < nixpkgs > { } is calling two functions , not one . reading it as ( import < nixpkgs > ) { } makes this clearer . the value returned by the nixpkgs function is a set ; more specifically , it ' s a set of derivations . calling import < nixpkgs > { } into a let - expression creates the local variable pk", "gs and brings it into scope . this has an effect similar to the : l < nixpkgs > we used in nix repl , in that it allows us to easily access derivations such as bash , gcc , and coreutils , but those derivations will have to be explicitly referred to as members of the pkgs set ( e . g . , pkgs . bash instead of just bash ) . below is a revised version of the simple . nix file , using the inherit keyword : let pkgs = import < nixpkgs > { } ; in derivation { name = \" simple \"", " ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / simple _ builder . sh ] ; inherit ( pkgs ) gcc coreutils ; src = . / simple . c ; system = builtins . currentsystem ; } here we also take the opportunity to introduce the inherit keyword . inherit foo ; is equivalent to foo = foo ; . similarly , inherit gcc coreutils ; is equivalent to gcc = gcc ; coreutils = coreutils ; . lastly , inherit ( pkgs ) gcc coreutils ; is", " equivalent to gcc = pkgs . gcc ; coreutils = pkgs . coreutils ; . this syntax only makes sense inside sets . there ' s no magic involved , it ' s simply a convenience to avoid repeating the same name for both the attribute name and the value in scope . next pill we will generalize the builder . you may have noticed that we wrote two separate builder . sh script s in this post . we would like to have a generic builder script instead , especially since each build script goes in the nix store : a bit of a waste . is it really that hard to package", " stuff in nix ? no , here we ' re studying the fundamentals of nix . generic builders welcome to the 8th nix pill . in the previous 7th pill we successfully built a derivation . we wrote a builder script that compiled a c file and installed the binary under the nix store . in this post , we will generalize the builder script , write a nix expression for gnu helloworld and create a wrapper around the derivation built - in function . packaging gnu helloworld in the previous pill we packaged a simple . c file , which was being compiled with a raw gcc call . that ' s not a good example of a project", " . many use autotools , and since we ' re going to generalize our builder , it would be better to do it with the most used build system . gnu helloworld , despite its name , is a simple yet complete project which uses autotools . fetch the latest tarball here : https : / / ftp . gnu . org / gnu / hello / hello - 2 . 12 . 1 . tar . gz . let ' s create a builder script for gnu helloworld , hello _ builder . sh : export path = \" $ gnutar / bin : $ gcc / bin : $ gnumake /", " bin : $ coreutils / bin : $ gawk / bin : $ gzip / bin : $ gnugrep / bin : $ gnused / bin : $ bintools / bin \" tar - xzf $ src cd hello - 2 . 12 . 1 . / configure - - prefix = $ out make make install and the derivation hello . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" hello \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / hello", " _ builder . sh ] ; inherit ( pkgs ) gnutar gzip gnumake gcc coreutils gawk gnused gnugrep ; bintools = pkgs . binutils . bintools ; src = . / hello - 2 . 12 . 1 . tar . gz ; system = builtins . currentsystem ; } nix on darwin darwin ( i . e . macos ) builds typically use clang rather than gcc for a c compiler . we can adapt this early example for darwin by using this modified version of hello . nix : let pkgs = import <", " nixpkgs > { } ; in derivation { name = \" hello \" ; builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / hello _ builder . sh ] ; inherit ( pkgs ) gnutar gzip gnumake coreutils gawk gnused gnugrep ; gcc = pkgs . clang ; bintools = pkgs . clang . bintools . bintools _ bin ; src = . / hello - 2 . 12 . 1 . tar . gz ; system = builtins . currentsyst", "em ; } later , we will show how nix can automatically handle these differences . for now , please be just aware that changes similar to the above may be needed in what follows . now build it with nix - build hello . nix and you can launch result / bin / hello . nothing easier , but do we have to create a builder . sh for each package ? do we always have to pass the dependencies to the derivation function ? please note the - - prefix = $ out we were talking about in the previous pill . a generic builder let ' s create a generic builder . sh for autotools projects : set - e unset", " path for p in $ buildinputs ; do export path = $ p / bin $ { path : + : } $ path done tar - xf $ src for d in * ; do if [ - d \" $ d \" ] ; then cd \" $ d \" break fi done . / configure - - prefix = $ out make make install what do we do here ? 1 . exit the build on any error with set - e . 2 . first unset path , because it ' s initially set to a non - existent path . 3 . we ' ll see this below in detail , however for each", " path in $ buildinputs , we append bin to path . 4 . unpack the source . 5 . find a directory where the source has been unpacked and cd into it . 6 . once we ' re set up , compile and install . as you can see , there ' s no reference to \" hello \" in the builder anymore . it still makes several assumptions , but it ' s certainly more generic . now let ' s rewrite hello . nix : let pkgs = import < nixpkgs > { } ; in derivation { name = \" hello \" ; builder = \" $ { pk", "gs . bash } / bin / bash \" ; args = [ . / builder . sh ] ; buildinputs = with pkgs ; [ gnutar gzip gnumake gcc coreutils gawk gnused gnugrep binutils . bintools ] ; src = . / hello - 2 . 12 . 1 . tar . gz ; system = builtins . currentsystem ; } all clear , except that buildinputs . however it ' s easier than any black magic you are thinking of at this moment . nix is able to convert a list to a string . it", " first converts the elements to strings , and then concatenates them separated by a space : nix - repl > builtins . tostring 123 \" 123 \" nix - repl > builtins . tostring [ 123 456 ] \" 123 456 \" recall that derivations can be converted to a string , hence : nix - repl > : l < nixpkgs > added 3950 variables . nix - repl > builtins . tostring gnugrep \" / nix / store / g5gdylclfh6d224kqh9sja290pk18", "6xd - gnugrep - 2 . 14 \" nix - repl > builtins . tostring [ gnugrep gnused ] \" / nix / store / g5gdylclfh6d224kqh9sja290pk186xd - gnugrep - 2 . 14 / nix / store / krgdc4sknzpw8iyk9p20lhqfd52kjmg0 - gnused - 4 . 2 . 2 \" simple ! the buildinputs variable is a string with out paths separated by space , perfect for bash", " usage in a for loop . a more convenient derivation function we managed to write a builder that can be used for multiple autotools projects . but in the hello . nix expression we are specifying tools that are common to more projects ; we don ' t want to pass them every time . a natural approach would be to create a function that accepts an attribute set , similar to the one used by the derivation function , and merge it with another attribute set containing values common to many projects . create autotools . nix : pkgs : attrs : let defaultattrs = { builder = \" $ { pkgs . bash", " } / bin / bash \" ; args = [ . / builder . sh ] ; baseinputs = with pkgs ; [ gnutar gzip gnumake gcc coreutils gawk gnused gnugrep binutils . bintools ] ; buildinputs = [ ] ; system = builtins . currentsystem ; } ; in derivation ( defaultattrs / / attrs ) ok now we have to remember a little about nix functions . the whole nix expression of this autotools . nix file will evaluate to a function . this function accepts a parameter pkgs ,", " then returns a function which accepts a parameter attrs . the body of the function is simple , yet at first sight it might be hard to grasp : 1 . first drop in the scope the magic pkgs attribute set . 2 . within a let expression we define a helper variable , defaultattrs , which serves as a set of common attributes used in derivations . 3 . finally we create the derivation with that strange expression , ( defaultattrs / / attrs ) . the / / operator is an operator between two sets . the result is the union of the two sets . in case of conflict s between attribute", " names , the value on the right set is preferred . so we use defaultattrs as base set , and add ( or override ) the attributes from attrs . a couple of examples ought to be enough to clear out the behavior of the operator : nix - repl > { a = \" b \" ; } / / { c = \" d \" ; } { a = \" b \" ; c = \" d \" ; } nix - repl > { a = \" b \" ; } / / { a = \" c \" ; } { a = \" c \" ; } exercise : complete the new builder . sh", " by adding $ baseinputs in the for loop together with $ buildinputs . as you noticed , we passed that new variable in the derivation . instead of merging buildinputs with the base ones , we prefer to preserve buildinputs as seen by the caller , so we keep them separated . just a matter of choice . then we rewrite hello . nix as follows : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name = \" hello \" ; src = . / hello", " - 2 . 12 . 1 . tar . gz ; } finally ! we got a very simple descript ion of a package ! below are a couple of remarks that you may find useful as you ' re continuing to understand the nix language : * we assigned to pkgs the import that we did in the previous expressions in the \" with \" . don ' t be afraid , it ' s that straightforward . * the mkderivation variable is a nice example of partial application , look at it as ( import . / autotools . nix ) pkgs . first we import the expression , then we apply the pkgs", " parameter . that will give us a function that accepts the attribute set attrs . * we create the derivation specifying only name and src . if the project eventually needed other dependencies to be in path , then we would simply add those to buildinputs ( not specified in hello . nix because empty ) . note we didn ' t use any other library . special c flags may be needed to find include files of other libraries at compile time , and ld flags at link time . conclusion nix gives us the bare metal tools for creating derivations , setting up a build environment and storing the result in the nix store . out", " of this pill we managed to create a generic builder for autotools projects , and a function mkderivation that composes by default the common components used in autotools projects instead of repeating them in all the packages we would write . we are familiarizing ourselves with the way a nix system grows up : it ' s about creating and composing derivations with the nix language . analogy : in c you create objects in the heap , and then you compose them inside new objects . pointers are used to refer to other objects . in nix you create derivations stored in the nix store , and then you compose them by creating new derivations", " . store paths are used to refer to other derivations . next pill . . . we will talk a little about runtime dependencies . is the gnu helloworld package self - contained ? what are its runtime dependencies ? we only specified build dependencies by means of using other derivations in the \" hello \" derivation . automatic runtime dependencies welcome to the 9th nix pill . in the previous 8th pill we wrote a generic builder for autotools projects . we fed in build dependencies and a source tarball , and we received a nix derivation as a result . today we stop by the gnu hello program to analyze build and", " runtime dependencies , and we enhance our builder to eliminate unnecessary runtime dependencies . build dependencies let ' s start analyzing build dependencies for our gnu hello package : $ nix - instantiate hello . nix / nix / store / z77vn965a59irqnrrjvbspiyl2rph0jp - hello . drv $ nix - store - q - - references / nix / store / z77vn965a59irqnrrjvbspiyl2rph0jp - hello . drv / nix / store / 0q6pfas", "dma4as22kyaknk4kwx4h58480 - hello - 2 . 10 . tar . gz / nix / store / 1zcs1y4n27lqs0gw4v038i303pb89rw6 - coreutils - 8 . 21 . drv / nix / store / 2h4b30hlfw4fhqx10wwi71mpim4wr877 - gnused - 4 . 2 . 2 . drv / nix / store / 39bgdjissw9gy", "i4y5j9wanf4dbjpbl07 - gnutar - 1 . 27 . 1 . drv / nix / store / 7qa70nay0if4x291rsjr7h9lfl6pl7b1 - builder . sh / nix / store / g6a0shr58qvx2vi6815acgp9lnfh9yy8 - gnugrep - 2 . 14 . drv / nix / store / jdggv3q1sb15140qdx0apvyrps41m4lr - bash", " - 4 . 2 - p45 . drv / nix / store / pglhiyp1zdbmax4cglkpz98nspfgbnwr - gnumake - 3 . 82 . drv / nix / store / q9l257jn9lndbi3r9ksnvf4dr8cwxzk7 - gawk - 4 . 1 . 0 . drv / nix / store / rgyrqxz1ilv90r01zxl0sq5nq0cq7v3v - binutils - 2", " . 23 . 1 . drv / nix / store / qzxhby795niy6wlagfpbja27dgsz43xk - gcc - wrapper - 4 . 8 . 3 . drv / nix / store / sk590g7fv53m3zp0ycnxsc41snc2kdhp - gzip - 1 . 6 . drv it has precisely the derivations referenced in the derivation function ; nothing more , nothing less . of course , we may not use some of them at all . however , given that our generic mk", "derivation function always pulls such dependencies ( think of it like build - essential from debian ) , we will already have these packages in the nix store for any future packages that need them . why are we looking at . drv files ? because the hello . drv file is the representation of the build action that builds the hello out path . as such , it contains the input derivations needed beforebuilding hello . digression about nar files the nar format is the \" nix archive \" . this format was designed due to existing archive formats , such as tar , being insufficient . nix benefits from deterministic build tools ,", " but commonly used archivers lack this property : they add padding , they do not sort files , they add timestamps , and so on . this can result in directories containing bit - identical files turning into non - bit - identical archives , which leads to different hashes . thus the nar format was developed as a simple , deterministic archive format . nars are used extensively within nix , as we will see below . for more rationale and implementation details behind nar see dolstra ' s phd thesis . to create nar archives from store paths , we can use nix - store - - dump and nix -", " store - - restore . runtime dependencies we now note that nix automatically recognized build dependencies once our derivation call referred to them , but we never specified the runtime dependencies . nix handles runtime dependencies for us automatically . the technique it uses to do so may seem fragile at first glance , but it works so well that the nixos operating system is built off of it . the underlying mechanism relies on the hash of the store paths . it proceeds in three steps : 1 . dump the derivation as a nar . recall that this is a serialization of the derivation output - - meaning this works fine whether the output is a", " single file or a directory . 2 . for each build dependency . drv and its relative out path , search the contents of the nar for this out path . 3 . if the path is found , then it ' s a runtime dependency . the snippet below shows the dependencies for hello . $ nix - instantiate hello . nix / nix / store / z77vn965a59irqnrrjvbspiyl2rph0jp - hello . drv $ nix - store - r / nix / store / z77vn965a59irqnrrjvb", "spiyl2rph0jp - hello . drv / nix / store / a42k52zwv6idmf50r9lps1nzwq9khvpf - hello $ nix - store - q - - references / nix / store / a42k52zwv6idmf50r9lps1nzwq9khvpf - hello / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / nix / store /", " 8jm0wksask7cpf85miyakihyfch1y21q - gcc - 4 . 8 . 3 / nix / store / a42k52zwv6idmf50r9lps1nzwq9khvpf - hello we see that glibc and gcc are runtime dependencies . intuitively , gcc shouldn ' t be in this list ! displaying the printable strings in the hello binary shows that the out path of gcc does indeed appear : $ strings result / bin / hello | grep gcc / nix / store / 94n64", "qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib : / nix / store / 8jm0wksask7cpf85miyakihyfch1y21q - gcc - 4 . 8 . 3 / lib64 this is why nix added gcc . but why is that path present in the first place ? the answer is that it is the ld rpath : the list of directories where libraries can be found at runtime . in other distributions , this is usually not abused . but in nix", " , we have to refer to particular versions of libraries , and thus the rpath has an important role . the build process adds the gcc lib path thinking it may be useful at runtime , but this isn ' t necessary . to address issues like these , nix provides a tool called patchelf , which reduces the rpath to the paths that are actually used by the binary . even after reducing the rpath , the hello binary would still depend upon gcc because of some debugging information . this unnecessarily increases the size of our runtime dependencies . we ' ll explore how strip can help us with", " that in the next section . another phase in the builder we will add a new phase to our autotools builder . the builder has six phases already : 1 . the \" environment setup \" phase 2 . the \" unpack phase \" : we unpack the sources in the current directory ( remember , nix changes to a temporary directory first ) 3 . the \" change directory \" phase , where we change source root to the directory that has been unpacked 4 . the \" configure \" phase : . / configure 5 . the \" build \" phase : make 6 . the \" install \" phase : make install now", " we will add a new phase after the installation phase , which we call the \" fixup \" phase . at the end of the builder . sh , we append : find $ out - type f - exec patchelf - - shrink - rpath ' { } ' \\ ; - exec strip ' { } ' \\ ; 2 > / dev / null that is , for each file we run patchelf - - shrink - rpath and strip . note that we used two new commands here , find and patchelf . these must be added to our derivation . exercise : add findutils and patchelf to", " the baseinputs of autotools . nix . now , we rebuild hello . nix . . . $ nix - build hello . nix [ . . . ] $ nix - store - q - - references result / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / nix / store / md4a3zv0ipqzsybhjb8ndjhhga1dj88x - hello and we see that glibc is a runtime dependency . this", " is exactly what we wanted . the package is self - contained . this means that we can copy its closure onto another machine and we will be able to run it . remember , only a very few components under the / nix / store are required to run nix . the hello binary will use the exact version of glibc library and interpreter referred to in the binary , rather than the system one : $ ldd result / bin / hello linux - vdso . so . 1 ( 0x00007fff11294000 ) libc . so . 6 = > / nix / store / 94n64qy9", "9ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib / libc . so . 6 ( 0x00007f7ab7362000 ) / nix / store / 94n64qy99ja0vgbkf675nyk39g9b978n - glibc - 2 . 19 / lib / ld - linux - x86 - 64 . so . 2 ( 0x00007f7ab770f000 ) of course , the executable will", " run fine as long as everything is under the / nix / store path . conclusion we saw some of the tools nix provides , along with their features . in particular , we saw how nix is able to compute runtime dependencies automatically . this is not limited to only shared libraries , but can also reference executables , script s , python libraries , and so forth . approaching builds in this way makes packages self - contained , ensuring ( apart from data and configuration ) that copying the runtime closure onto another machine is sufficient to run the program . this enables us to run programs without installation using nix - shell , and forms the basis", " for reliable deployment in the cloud . next pill the next pill will introduce nix - shell . with nix - build , we ' ve always built derivations from scratch : the source gets unpacked , configured , built , and installed . but this can take a long time for large packages . what if we want to apply some small changes and compile incrementally instead , yet still want to keep a self - contained environment similar to nix - build ? nix - shell enables this . developing with nix - shell welcome to the 10th nix pill . in the previous 9th pill we saw one of the powerful features of nix : automatic discovery of", " runtime dependencies . we also finalized the gnu hello package . in this pill , we will introduce the nix - shell tool and use it to hack on the gnu hello program . we will see how nix - shell gives us an isolated environmentwhile we modify the source files of the project , similar to how nix - build gave us an isolated environmentwhilebuilding the derivation . finally , we will modify our builder to work more ergonomically with a nix - shell - focused workflow . what is nix - shell ? the nix - shell tool drops us in a shell after setting up the environment variables necessary to hack on a derivation . it", " does not build the derivation ; it only serves as a preparation so that we can run the build steps manually . recall that in a nix environment , we don ' t have access to libraries or programs unless they have been installed with nix - env . however , installing libraries with nix - env is not good practice . we prefer to have isolated environments for development , which nix - shell provides for us . we can call nix - shell on any nix expression which returns a derivation , but the resulting bash shell ' s path does not have the utilities we want : $ nix - shell hello . nix [ nix - shell ] $ make bash :", " make : command not found [ nix - shell ] $ echo $ baseinputs / nix / store / jff4a6zqi0yrladx3kwy4v6844s3swpc - gnutar - 1 . 27 . 1 [ . . . ] this shell is rather useless . it would be reasonable to expect that the gnu hello build inputs are available in path , including gnu make , but this is not the case . however , we do have the environment variables that we set in the derivation , like $ baseinputs , $ buildinputs , $ src , and so on", " . this means that we can source our builder . sh , and it will build the derivation . you may get an error in the installation phase , because your user may not have the permission to write to / nix / store : [ nix - shell ] $ source builder . sh . . . the derivation didn ' t install , but it did build . note the following : * we sourced builder . sh and it ran all of the build steps , including setting up the path for us . * the working directory is no longer a temp directory created by nix - build , but is instead the directory in which we entered the shell . therefore ,", " hello - 2 . 10 has been unpacked in the current directory . we are able to cd into hello - 2 . 10 and type make , because make is now available . the take - away is that nix - shell drops us in a shell with the same ( or very similar ) environment used to run the builder . a builder for nix - shell the previous steps require some manual commands to be run and are not optimized for a workflow centered on nix - shell . we will now improve our builder to be more nix - shell friendly . there are a few things that we would like to change . first , when we sourced", " the builder . sh file , we obtained the file in the current directory . what we really wanted was the builder . sh that is stored in the nix store , as this is the file that would be used by nix - build . to achieve this , the correct technique is to pass an environment variable through the derivation . ( note that $ builder is already defined , but it points to the bash executable rather than our builder . sh . our builder . sh is passed as an argument to bash . ) second , we don ' t want to run the whole builder : we only want to setup the necessary environment for manuallybuilding the project .", " thus , we can break builder . sh into two files : a setup . sh for setting up the environment , and the real builder . sh that nix - build expects . during our refactoring , we will wrap the build phases in functions to give more struct ure to our design . additionally , we ' ll move the set - e to the builder file instead of the setup file . the set - e is annoying in nix - shell , as it will terminate the shell if an error is encountered ( such as a mistyped command . ) here is our modified autotools . nix . noteworthy is the setup = . /", " setup . sh ; attribute in the derivation , which adds setup . sh to the nix store and correspondingly adds a $ setup environment variable in the builder . pkgs : attrs : let defaultattrs = { builder = \" $ { pkgs . bash } / bin / bash \" ; args = [ . / builder . sh ] ; setup = . / setup . sh ; baseinputs = with pkgs ; [ gnutar gzip gnumake gcc coreutils gawk gnused gnugrep binutils . bintools patchelf findutils ] ; build", "inputs = [ ] ; system = builtins . currentsystem ; } ; in derivation ( defaultattrs / / attrs ) thanks to that , we can split builder . sh into setup . sh and builder . sh . what builder . sh does is source $ setup and call the genericbuild function . everything else is just some changes to the bash script . here is the modified builder . sh : set - e source $ setup genericbuild here is the newly added setup . sh : unset path for p in $ baseinputs $ buildinputs ; do export path = $", " p / bin $ { path : + : } $ path done function unpackphase ( ) { tar - xzf $ src for d in * ; do if [ - d \" $ d \" ] ; then cd \" $ d \" break fi done } function configurephase ( ) { . / configure - - prefix = $ out } function buildphase ( ) { make } function installphase ( ) { make install } function fixupphase ( ) { find $ out - type f - exec patchelf - - shrink - rpath ' { } ' \\", " ; - exec strip ' { } ' \\ ; 2 > / dev / null } function genericbuild ( ) { unpackphase configurephase buildphase installphase fixupphase } finally , here is hello . nix : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name = \" hello \" ; src = . / hello - 2 . 12 . 1 . tar . gz ; } now back to nix - shell : $ nix - shell hello", " . nix [ nix - shell ] $ source $ setup [ nix - shell ] $ now , for example , you can run unpackphase which unpacks $ src and enters the directory . and you can run commands like . / configure , make , and so forth manually , or run phases with their respective functions . the process is that straightforward . nix - shell builds the . drv file and its input dependencies , then drops into a shell by setting up the environment variables necessary to build the . drv . in particular , the environment variables in the shell match those passed to the derivation function . conclusion with", " nix - shell we are able to drop into an isolated environment suitable for developing a project . this environment provides the necessary dependencies for the development shell , similar to how nix - build provides the necessary dependencies to a builder . additionally , we can build and debug the project manually , executing step - by - step like we would in any other operating system . note that we never installed tools such gcc or make system - wide ; these tools and libraries are isolated and available per - build . next pill in the next pill , we will clean up the nix store . we havewritten and built derivations which add to the nix store", " , but until now we haven ' t worried about cleaning up the used space in the store . the garbage collector welcome to the 11th nix pill . in the previous 10th pill , we drew a parallel between the isolated build environment provided by nix - build and the isolated development shell provided by nix - shell . using nix - shell allowed us to debug , modify , and manually build software using an environment that is almost identical to the one provided by nix - build . today , we will stop focusing on packaging and instead look at a critical component of nix : the garbage collector . when we use nix tools , we are oftenbuilding derivations .", " this includes . drv files as well as out paths . these artifacts go in the nix store and take up space in our storage . eventually we may wish to free up some space by removing derivations we no longer need . this is the focus of the 11th pill . by default , nix takes a relatively conservative approach when automatically deciding which derivations are \" needed \" . in this pill , we will also see a technique to conduct more destruct ive upgrade and deletion operations . how does garbage collection work ? programming languages with garbage collectors use the concept of a set of \" garbage collector ( or ' gc ' ) roots \"", " to keep track of \" live \" objects . a gc root is an object that is always considered \" live \" ( unless explicitly removed as gc root ) . the garbage collection process starts from the gc roots and proceeds by recursively marking object references as \" live \" . all other objects can be collected and deleted . instead of objects , nix ' s garbage collection operates on store paths , with the gc roots themselves being store paths . . this approach is much more principled than traditional package managers such as dpkg or rpm , which may leave around unused packages or dangling files . the implementation is very simple and transparent", " to the user . the primary gc roots are stored under / nix / var / nix / gcroots . if there is a symlink to a store path , then the linked store path is a gc root . nix allows this directory to have subdirectories : it will simply recursively traverse the subdirectories in search of symlinks to store paths . when a symlink is encountered , its target is added to the list of live store paths . in summary , nix maintains a list of gc roots . these roots can then be used to compute a list of all live", " store paths . any other store paths are considered dead . deleting these paths is now straightforward . nix first moves dead store paths to / nix / store / trash , which is an atomic operation . afterwards , the trash is emptied . playing with the gc before we begin we first run the nix garbage collector so that we have a clean setup for our experiments : $ nix - collect - garbage finding garbage collector roots . . . [ . . . ] deleting unused links . . . note : currently hard linking saves - 0 . 00 mib 1169 store paths deleted , 228 . 43 mib freed if we run the garbage", " collector again it won ' t find anything new to delete , as we expect . after running the garbage collector , the nix store only contains paths with references from the gc roots . we now install a new program , bsd - games , inspect its store path , and examine its gc root . the nix - store - q - - roots command is used to query the gc roots that refer to a given derivation . in this case , our current user environment refers to bsd - games : $ nix - env - ia nixpkgs . bsdgames $ readlink - f ` which fortune ` / nix /", " store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 . 17 / bin / fortune $ nix - store - q - - roots ` which fortune ` / nix / var / nix / profiles / default - 9 - link $ nix - env - - list - generations [ . . . ] 9 2014 - 08 - 20 12 : 44 : 14 ( current ) now we remove it and run the garbage collector , and note that bsd - games is still in the nix store : $ nix - env - e bsd", " - games uninstalling ` bsd - games - 2 . 17 ' $ nix - collect - garbage [ . . . ] $ ls / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 . 17 bin share the old generation is still in the nix store because it is a gc root . as we will see below , all profiles and their generations are automatically gc roots . removing a gc root is simple . in our case , we delete the generation that refers to bsd - games", " , run the garbage collector , and note that bsd - games is no longer in the nix store : $ rm / nix / var / nix / profiles / default - 9 - link $ nix - env - - list - generations [ . . . ] 8 2014 - 07 - 28 10 : 23 : 24 10 2014 - 08 - 20 12 : 47 : 16 ( current ) $ nix - collect - garbage [ . . . ] $ ls / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 .", " 17 ls : cannot access / nix / store / b3lxx3d3ggxcggvjw5n0m1ya1gcrmbyn - bsd - games - 2 . 17 : no such file or directory note : nix - env - - list - generations does not rely on any particular metadata . it is able to list generations based solely on the file names under the profiles directory . note that we removed the link from / nix / var / nix / profiles , not from / nix / var / nix / gcroots . in addition to the latter , nix treats / nix / var", " / nix / profiles as a gc root . this is useful because it means that any profile and its generations are gc roots . other paths are considered gc roots as well ; for example , / run / booted - system on nixos . the command nix - store - - gc - - print - roots prints all paths considered as gc roots when running the garbage collector . indirect roots recall thatbuilding the gnu hello package with nix - build produces a result symlink in the current directory . despite the garbage collection done above , the hello program is still working . therefore , it has not been garbage collected . since there", " is no other derivation that depends upon the gnu hello package , it must be a gc root . in fact , nix - build automatically adds the result symlink as a gc root . note that this is not the built derivation , but the symlink itself . these gc roots are added under / nix / var / nix / gcroots / auto . $ ls - l / nix / var / nix / gcroots / auto / total 8 drwxr - xr - x 2 nix nix 4096 aug 20 10 : 24 . / drwxr - xr - x", " 3 nix nix 4096 jul 24 10 : 38 . . / lrwxrwxrwx 1 nix nix 16 jul 31 10 : 51 xlgz5x2ppa0m72z5qfc78b8wlciwvgiz - > / home / nix / result / the name of the gc root symlink is not important to us at this time . what is important is that such a symlink exists and points to / home / nix / result . this is called an indirect gc root . a gc root is considered indirect if its specification is outside", " of / nix / var / nix / gcroots . in this case , this means that the target of the result symlink will not be garbage collected . to remove a derivation considered \" live \" by an indirect gc root , there are two possibilities : * remove the indirect gc root from / nix / var / nix / gcroots / auto . * remove the result symlink . in the first case , the derivation will be deleted from the nix store during garbage collection , and result becomes a dangling symlink . in the second case , the derivation is removed as well as the indirect root in /", " nix / var / nix / gcroots / auto . running nix - collect - garbage after deleting the gc root or the indirect gc root will remove the derivation from the store . cleanup everything the main source of software duplication in the nix store comes from gc roots , due to nix - build and profile generations . running nix - build results in a gc root for the build that refers to a specific version of specific libraries , such as glibc . after an upgrade , we must delete the previous build if we want the garbage collector to remove the corresponding derivation , as well as if we want old", " dependencies cleaned up . the same holds for profiles . manipulating the nix - env profile will create further generations . old generations refer to old software , thus increasing duplication in the nix store after an upgrade . other systems typically \" forget \" everything about their previous state after an upgrade . with nix , we can perform this type of upgrade ( having nix remove all old derivations , including old generations ) , but we do so manually . there are four steps to doing this : * first , we download a new version of the nixpkgs channel , which holds the descript ion of all the software . this is done via nix -", " channel - - update . * then we upgrade our installed packages with nix - env - u . this will bring us into a new generation with updated software . * then we remove all the indirect roots generated by nix - build : beware , as this will result in dangling symlinks . a smarter strategy would also remove the target of those symlinks . * finally , the - d option of nix - collect - garbage is used to delete old generations of all profiles , then collect garbage . after this , you lose the ability to rollback to any previous generation . it is important to ensure the new generation is working", " well before running this command . the four steps are shown below : $ nix - channel - - update $ nix - env - u - - always $ rm / nix / var / nix / gcroots / auto / * $ nix - collect - garbage - d conclusion garbage collection in nix is a powerful mechanism to clean up your system . the nix - store commands allow us to know why a certain derivation is present in the nix store , and whether or not it is eligible for garbage collection . we also saw how to conduct more destruct ive deletion and upgrade operations . next pill in the next pill , we will", " package another project and introduce the \" inputs \" design pattern . we ' ve only played with a single derivation until now ; however we ' d like to start organizing a small repository of software . the \" inputs \" pattern is widely used in nixpkgs ; it allows us to decouple derivations from the repository itself and increase customization opportunities . package repositories and the inputs design pattern welcome to the 12th nix pill . in the previous 11th pill , we stopped packaging and cleaned up the system with the garbage collector . this time , we will resume packaging and improve different aspects of it . we will also demonstrate how to create", " a repository of multiple packages . repositories in nix package repositories in nix arose naturally from the need to organize packages . there is no preset directory struct ure or packaging policy prescribe d by nix itself ; nix , as a full , functional programming language , is powerful enough to support multiple different repository formats . over time , the nixpkgs repository evolved a particular struct ure . this struct ure reflects the history of nix as well as the design patterns adopted by its users as useful tools inbuilding and organizing packages . below , we will examine some of these patterns in detail . the single", " repository pattern different operating system distributions have different opinions about how package repositories should be organized . systems like debian scatter packages in several small repositories ( which tends to make tracking interdependent changes more difficult , and hinders contributions to the repositories ) ,while systems like gentoo put all package descript ions in a single repository . nix follows the \" single repository \" pattern by placing all descript ions of all packages into nixpkgs . this approach has proven natural and attractive for new contributions . for the rest of this pill , we will adopt the single repository pattern . the natural", " implementation in nix is to create a top - level nix expression , followed by one expression for each package . the top - level expression imports and combines all package expressions in an attribute set mapping names to packages . in some programming languages , such an approach - - including every possible package descript ion in a single data struct ure - - would be untenable due to the language needing to load the entire data struct ure into memory before operating on it . nix , however , is a lazy language and only evaluates what is needed . packaging graphviz we have already packaged gnu hello . next , we will package a graph", " - drawing program called graphviz so that we can create a repository containing multiple packages . the graphviz package was selected because it uses the standard autotools build system and requires no patching . it also has optional dependencies , which will give us an opportunity to illustrate a technique to configure builds to a particular situation . first , we download graphviz from gitlab . the graphviz . nix expression is straightforward : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name", " = \" graphviz \" ; src = . / graphviz - 2 . 49 . 3 . tar . gz ; } if we build the project with nix - build graphviz . nix , we will get runnable binaries under result / bin . notice how we reused the same autotools . nix of hello . nix . by default , graphviz does not compile with the ability to produce png files . thus , the derivation above will build a binary supporting only the native output formats , as we see below : $ echo ' graph test { a - - b } ' | result / bin /", " dot - tpng - o test . png format : \" png \" not recognized . use one of : canon cmap [ . . . ] if we want to produce a png file with graphviz , we must add it to our derivation . the place to do so is in autotools . nix , where we created a buildinputs variable that gets concatenated to baseinputs . this is the exact reason for this variable : to allow users of autotools . nix to add additional inputs from package expressions . version 2 . 49 of graphviz has several plugins to output p", "ng . for simplicity , we will use libgd . passing library information to pkg - config via environment variables the graphviz configuration script uses pkg - config to specify which flags are passed to the compiler . since there is no global location for libraries , we need to tell pkg - config where to find its descript ion files , which tell the configuration script where to find headers and libraries . in classic posix systems , pkg - config just finds the . pc files of all installed libraries in system folders like / usr", " / lib / pkgconfig . however , these files are not present in the isolated environments presented to nix . as an alternative , we can inform pkg - config about the location of libraries via the pkg _ config _ path environment variable . we can populate this environment variable using the same trick we used for path : automatically filling the variables from buildinputs . this is the relevant snippet of setup . sh : for p in $ baseinputs $ buildinputs ; do if [ - d $ p / bin ] ; then export path = \" $", " p / bin $ { path : + : } $ path \" fi if [ - d $ p / lib / pkgconfig ] ; then export pkg _ config _ path = \" $ p / lib / pkgconfig $ { pkg _ config _ path : + : } $ pkg _ config _ path \" fi done now if we add derivations to buildinputs , their lib / pkgconfig and bin paths are automatically added in setup . sh . completing graphviz with gd below , we", " finish the expression for graphviz with gd support . note the use of the with expression in buildinputs to avoid repeating pkgs : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in mkderivation { name = \" graphviz \" ; src = . / graphviz - 2 . 49 . 3 . tar . gz ; buildinputs = with pkgs ; [ pkg - config ( pkgs . lib . getlib gd ) ( p", "kgs . lib . getdev gd ) ] ; } we add pkg - config to the derivation to make this tool available for the configure script . as gd is a package with split outputs , we need to add both the library and development outputs . afterbuilding , graphviz can now create pngs . the repository expression now that we have two packages , we want to combine them into a single repository . to do so , we ' ll mimic what nixpkgs does : we will create a single attribute set containing derivations . this attribute set can then be imported ,", " and derivations can be selected by accessing the top - level attribute set . using this technique we are able to abstract from the file names . instead of referring to a package by repo / some / sub / dir / package . nix , this technique allows us to select a derivation as importedrepo . package ( or pkgs . package in our examples ) . to begin , create a default . nix in the current directory : { hello = import . / hello . nix ; graphviz = import . / graphviz . nix ; } this file is ready to use with nix repl : $ nix repl nix", " - repl > : l default . nix added 2 variables . nix - repl > hello \u00ab derivation / nix / store / dkib02g54fpdqgpskswgp6m7bd7mgx89 - hello . drv \u00bb nix - repl > graphviz \u00ab derivation / nix / store / zqv520v9mk13is0w980c91z7q1vkhhil - graphviz . drv \u00bb with nix - build , we can pass the - a option to access an attribute of the set from the given . nix", " expression : $ nix - build default . nix - a hello [ . . . ] $ result / bin / hello hello ,world ! the default . nix file is special . when a directory contains a default . nix file , it is used as the implicit nix expression of the directory . this , for example , allows us to run nix - build - a hello without specifying default . nix explicitly . we can now use nix - env to install the package into our user environment : $ nix - env - f . - ia graphviz [ . . . ] $ dot - v taking a closer look at the above command ,", " we see the following options : * the - f option is used to specify the expression to use . in this case , the expression is the . / default . nix of the current directory . * the - i option stands for \" installation \" . * the - a is the same as above for nix - build . we reproduced the very basic behavior of nixpkgs : combining multiple derivations into a single , top - level attribute set . the inputs pattern the approach we ' ve taken so far has a few problems : * first , hello . nix and graphviz . nix are dependent on nixpkgs , which they import", " directly . a better approach would be to pass in nixpkgs as an argument , as we did in autotools . nix . * second , we don ' t have a straightforward way to compile different variants of the same software , such as graphviz with or without libgd support . * third , we don ' t have a way to test graphviz with a particular libgd version . until now , our approach to addressing the above problems has been inadequate and required changing the nix expression to match our needs . with the inputs pattern , we provide another answer : let the user change the inputs of", " the expression . when we talk about \" the inputs of an expression \" , we are referring to the set of derivations needed to build that expression . in this case : * mkderivation from autotools . recall that mkderivation has an implicit dependency on the toolchain . * libgd and its dependencies . the . / src directory is also an input , but we wouldn ' t change the source from the caller . in nixpkgs we prefer to write another expression for version bumps ( e . g . because patches or different inputs are needed ) . our goal is to make package expressions independent of", " the repository . to achieve this , we use functions to declare inputs for a derivation . for example , with graphviz . nix , we make the following changes to make the derivation independent of the repository and customizable : { mkderivation , lib , gdsupport ? true , gd , pkg - config } : mkderivation { name = \" graphviz \" ; src = . / graphviz - 2 . 49 . 3 . tar . gz ; buildinputs = if gdsupport then [ pkg - config ( lib . get", "lib gd ) ( lib . getdev gd ) ] else [ ] ; } recall that \" { . . . } : . . . \" is the syntax for defining functions accepting an attribute set as argument ; the above snippet just defines a function . we made gd and its dependencies optional . if gdsupport is true ( which it is by default ) , we will fill buildinputs and graphviz will be built with gd support . otherwise , if an attribute set is passed with gdsupport = false ; , the build will be completed without gd support . going back", " to back to default . nix , we modify our expression to utilize the inputs pattern : let pkgs = import < nixpkgs > { } ; mkderivation = import . / autotools . nix pkgs ; in with pkgs ; { hello = import . / hello . nix { inherit mkderivation ; } ; graphviz = import . / graphviz . nix { inherit mkderivation lib gd pkg - config ; } ; graphvizcore = import . / graphviz . nix { inherit mkderivation lib gd pkg -", " config ; gdsupport = false ; } ; } we factorized the import of nixpkgs and mkderivation , and also added a variant of graphviz with gd support disabled . the result is that both hello . nix ( left as an exercise for the reader ) and graphviz . nix are independent of the repository and customizable by passing specific inputs . if we wanted to build graphviz with a specific version of gd , it would suffice to pass gd = . . . ; . if we wanted to change the toolchain , we would simply pass a different", " mkderivation function . let ' s talk a closer look at the snippet and dissect the syntax : * the entire expression in default . nix returns an attribute set with the keys hello , graphviz , and graphvizcore . * with \" let \" , we define some local variables . * we bring pkgs into the scope when defining the package set . this saves us from having to type pkgs \" repeatedly . * we import hello . nix and graphviz . nix , which each return a function . we call the functions with a set of inputs to get back the derivation . * the \"", " inherit x \" syntax is equivalent to \" x = x \" . this means that the \" inherit gd \" here , combined with the above \" with pkgs ; \" , is equivalent to \" gd = pkgs . gd \" . the entire repository of this can be found at the pill 12 gist . conclusion the \" inputs \" pattern allows our expressions to be easily customizable through a set of arguments . these arguments could be flags , derivations , or any other customizations enabled by the nix language . our package expressions are simply functions : there is no extra magic present . the \" inputs \" pattern also makes", " the expressions independent of the repository . given that we pass all needed information through arguments , it is possible to use these expressions in any other context . next pill in the next pill , we will talk about the \" callpackage \" design pattern . this removes the tedium of specifying the names of the inputs twice : once in the top - level default . nix , and once in the package expression . with callpackage , we will implicitly pass the necessary inputs from the top - level expression . callpackage design pattern welcome to the 13th nix pill . in the previous 12th pill , we introduced the first basic design pattern for organizing", " a repository of software . in addition , we packaged graphviz so that we had two packages to bundle into an example repository . the next design pattern we will examine is called the callpackage pattern . this technique is extensively used in nixpkgs , and it ' s the current de facto standard for importing packages in a repository . its purpose is to reduce the duplication of identifiers between package derivation inputs and repository derivations . the callpackage convenience in the previous pill , we demonstrated how the inputs pattern decouples packages from the repository . this allowed us to manually pass the inputs to the derivation ; the derivation", " declares its inputs , and the caller passes the arguments . however , as with usual programming languages , there is some duplication of work : we declare parameter names and then we pass arguments , typically with the same name . for example , if we define a package derivation using the inputs pattern such as : { input1 , input2 , . . . } : . . . we would likely want to bundle that package derivation into a repository via a an attribute set defined as something like : rec { lib1 = import package1 . nix { inherit input1 input2 ; } ; program2 = import package2 . nix { inherit inputx", " inputy lib1 ; } ; } there are two things to note . first , that inputs often have the same name as attributes in the repository itself . second , that ( due to the rec keyword ) , the inputs to a package derivation may be other packages in the repository itself . rather than passing the inputs twice , we would prefer to pass those inputs from the repository automatically and allow for manually overriding defaults . to achieve this , we will define a callpackage function with the following calling convention : { lib1 = callpackage package1 . nix { } ; program2 = callpackage package2 .", " nix { someoverride = overriddenderivation ; } ; } we want callpackage to be a function of two arguments , with the following behavior : * import the given expression contained in the file of the first argument , and return a function . this function returns a package derivation that uses the inputs pattern . * determine the name of the arguments to the function ( i . e . , the names of the inputs to the package derivation ) . * pass default arguments from the repository set , and let us override those arguments if we wish to customize the package derivation . implementing callpackage in this section , we will build", " up the callpackages pattern from scratch . to start , we need a way to obtain the argument names of a function ( in this case , the function that takes \" inputs \" and produces a package derivation ) at runtime . this is because we want to automatically pass such arguments . nix provides a builtin function to do this : nix - repl > add = { a ? 3 , b } : a + b nix - repl > builtins . functionargs add { a = true ; b = false ; } in addition to returning the argument names , the attribute set returned by functionargs indicates whether or not the", " argument has a default value . for our purposes , we are only interested in the argument names ; we do not care about the default values right now . the next step is to make callpackage automatically pass inputs to our package derivations based on the argument names we ' ve just obtained with functionargs . to do this , we need two things : * a package repository set containing package derivations that match the arguments names we ' ve obtained * a way to obtain an auto - populated attribute set combining the package repository and the return value of functionargs . the former is easy : we just have to set our package derivation ' s", " inputs to be package names in a repository , such as nixpkgs . for the latter , nix provides another builtin function : nix - repl > values = { a = 3 ; b = 5 ; c = 10 ; } nix - repl > builtins . intersectattrs values ( builtins . functionargs add ) { a = true ; b = false ; } nix - repl > builtins . intersectattrs ( builtins . functionargs add ) values { a = 3 ; b = 5 ; } the intersectattrs returns an attribute set whose names are the intersection of both arguments ' attribute", " names , with the attribute values taken from the second argument . this is all we need to do : we have obtained the argument names from a function , and populated these with an existing set of attributes . this is our simple implementation of callpackage : nix - repl > callpackage = set : f : f ( builtins . intersectattrs ( builtins . functionargs f ) set ) nix - repl > callpackage values add 8 nix - repl > with values ; add { inherit a b ; } 8 let ' s dissect the above snippet : * we define a callpackage", " variable which is a function . * the first parameter to the callpackage function is a set of name - value pairs that may appear in the argument set of the function we wish to \" autocall \" . * the second parameter is the function to \" autocall \" * we take the argument names of the function and intersect with the set of all values . * finally , we call the passed function f with the resulting intersection . in the snippet above , we ' ve also demonstrated that the callpackage call is equivalent to directly calling add a b . we achieved most of what we wanted : to automatically call functions given", " a set of possible arguments . if an argument is not found within the set we used to call the function , then we receive an error ( unless the function has variadic arguments denoted with . . . , as explained in the 5th pill ) . the last missing piece is allowing users to override some of the parameters . we may not want to always call functions with values taken from the big set . thus , we add a third parameter which takes a set of overrides : nix - repl > callpackage = set : f : overrides : f ( ( builtins . intersectattrs ( builtins . function", "args f ) set ) / / overrides ) nix - repl > callpackage values add { } 8 nix - repl > callpackage values add { b = 12 ; } 15 apart from the increasing number of parentheses , it should be clear that we simply take a set union between the default arguments and the overriding set . using callpackage to simplify the repository given our callpackages , we can simplify the repository expression in default . nix : let nixpkgs = import < nixpkgs > { } ; allpkgs = nixpkgs / / pkgs", " ; callpackage = path : overrides : let f = import path ; in f ( ( builtins . intersectattrs ( builtins . functionargs f ) allpkgs ) / / overrides ) ; pkgs = with nixpkgs ; { mkderivation = import . / autotools . nix nixpkgs ; hello = callpackage . / hello . nix { } ; graphviz = callpackage . / graphviz . nix { } ; graphvizcore = callpackage . / graphviz . nix { gdsupport = false", " ; } ; } ; in pkgs let ' s examine this in detail : * the expression above defines our own package repository , which we call pkgs , that contains hello along with our two variants of graphviz . * in the let expression , we import nixpkgs . note that previously , we referred to this import with the variable pkgs , but now that name is taken by the repository we are creating ourselves . * we needed a way to pass pkgs to callpackage somehow . instead of returning the set of packages directly from default . nix , we first assign it to a let variable and", " reuse it in callpackage . * for convenience , in callpackage we first import the file instead of calling it directly . otherwise we would have to write the import for each package . * since our expressions use packages from nixpkgs , in callpackage we use allpkgs , which is the union of nixpkgs and our packages . * we moved mkderivation into pkgs itself , so that it also gets passed automatically . note how easily we overrode arguments in the case of graphviz without gd . in addition , note how easy it was to merge two repositori", "es : nixpkgs and our pkgs ! the reader should notice a magic thing happening . we ' re defining pkgs in terms of callpackage , and callpackage in terms of pkgs . that magic is possible thanks to lazy evaluation : builtins . intersectattrs doesn ' t need to know the values in allpkgs in order to perform intersection , only the keys that do not require callpackage evaluation . conclusion the \" callpackage \" pattern has simplified our repository considerably . we were able to import packages that require named arguments and call them automatically , given the set of all packages sourced", " from nixpkgs . we ' ve also introduced some useful builtin functions that allows us to introspect nix functions and manipulate attributes . these builtin functions are not usually used when packaging software , but rather act as tools for packaging . they are documented in the nix manual . writing a repository in nix is an evolution of writing convenient functions for combining the packages . this pill demonstrates how nix can be a generic tool to build and deploy software , and how suitable it is to create software repositories with our own conventions . next pill in the next pill , we will talk about the \" override \" design pattern . the graph", "vizcore seems straightforward . it starts from graphviz . nix and builds it without gd . in the next pill , we will consider another point of view : starting from pkgs . graphviz and disabling gd ? override design pattern welcome to the 14th nix pill . in the previous 13th pill , we introduced the callpackage pattern and used it to simplify the composition of software in a repository . the next design pattern is less necessary , but is useful in many cases and is a good exercise to learn more about nix . about composability functional languages are known for being able to compose functions", " . in particular , these languages gain expressivity from functions that manipulate an original value into a new value having the same struct ure . this allows us to compose multiple functions to perform the desired modifications . in nix , we mostly talk about functions that accept inputs in order to return derivations . in ourworld , we want utility functions that are able to manipulate those struct ures . these utilities add some useful properties to the original value , and we ' d like to be able to apply more utilities on top of the result . for example , let ' s say we have an initial derivation drv and we want to transform it into", " a drv with debugging information and custom patches : debugversion ( applypatches [ . / patch1 . patch . / patch2 . patch ] drv ) the final result should be the original derivation with some changes . this is both interesting and very different from other packaging approaches , which is a consequence of using a functional language to describe packages . designing such utilities is not trivial in a functional language without static typing , because understanding what can or cannot be composed is difficult . but we try to do our best . the override pattern in pill 12 we introduced the inputs design pattern . we do not return a", " derivation picking dependencies directly from the repository ; rather we declare the inputs and let the callers pass the necessary arguments . in our repository we have a set of attributes that import the expressions of the packages and pass these arguments , getting back a derivation . let ' s take for example the graphviz attribute : graphviz = import . / graphviz . nix { inherit mkderivation gd fontconfig libjpeg bzip2 ; } ; if we wanted to produce a derivation of graphviz with a customized gd version , we would have to repeat most of the above plus specifying an", " alternative gd : { mygraphviz = import . / graphviz . nix { inherit mkderivation fontconfig libjpeg bzip2 ; gd = customgd ; } ; } that ' s hard to maintain . using callpackage would be easier : mygraphviz = callpackage . / graphviz . nix { gd = customgd ; } ; but we may still be diverging from the original graphviz in the repository . we would like to avoid specifying the nix expression again . instead , we would like to reuse the original graphvi", "z attribute in the repository and add our overrides like so : mygraphviz = graphviz . override { gd = customgd ; } ; the difference is obvious , as well as the advantages of this approach . note : that . override is not a \" method \" in the oo sense as you may think . nix is a functional language . the . override is simply an attribute of a set . the override implementation recall that the graphviz attribute in the repository is the derivation returned by the function imported from graphviz . nix . we would like to add a further attribute named \"", " override \" to the returned set . let ' s start by first creating a function \" makeoverridable \" . this function will take two arguments : a function ( that must return a set ) and the set of original arguments to be passed to the function . we will put this function in a lib . nix : { makeoverridable = f : origargs : let origres = f origargs ; in origres / / { override = newargs : f ( origargs / / newargs ) ; } ; } makeoverridable takes a function and a", " set of original arguments . it returns the original returned set , plus a new override attribute . this override attribute is a function taking a set of new arguments , and returns the result of the original function called with the original arguments unified with the new arguments . this is admittedly somewhat confusing , but the examples below should make it clear . let ' s try it with nix repl : $ nix repl nix - repl > : l lib . nix added 1 variables . nix - repl > f = { a , b } : { result = a + b ; } nix - repl > f { a = 3", " ; b = 5 ; } { result = 8 ; } nix - repl > res = makeoverridable f { a = 3 ; b = 5 ; } nix - repl > res { override = \u00ab lambda \u00bb ; result = 8 ; } nix - repl > res . override { a = 10 ; } { result = 15 ; } note that , as we specified above , the function f does not return the plain sum . instead , it returns a set with the sum bound to the name result . the variable res contains the result of the function call without any override . it ' s easy to see", " in the definition of makeoverridable . in addition , you can see that the new override attribute is a function . calling res . override with a set will invoke the original function with the overrides , as expected . this is a good start , but we can ' t override again ! this is because the returned set ( with result = 15 ) does not have an override attribute of its own . this is bad ; it breaks further composition . the solution is simple : the . override function should make the result overridable again : rec { makeoverridable = f : origargs", " : let origres = f origargs ; in origres / / { override = newargs : makeoverridable f ( origargs / / newargs ) ; } ; } please note the rec keyword . it ' s necessary so that we can refer to makeoverridable from makeoverridable itself . now let ' s try overriding twice : nix - repl > : l lib . nix added 1 variables . nix - repl > f = { a , b } : { result = a + b ; } nix - repl > res = makeover", "ridable f { a = 3 ; b = 5 ; } nix - repl > res2 = res . override { a = 10 ; } nix - repl > res2 { override = \u00ab lambda \u00bb ; result = 15 ; } nix - repl > res2 . override { b = 20 ; } { override = \u00ab lambda \u00bb ; result = 30 ; } success ! the result is 30 ( as expected ) because a is overridden to 10 in the first override , and b is overridden to 20 in the second . now it would be nice if callpackage made our derivation", "s overridable . this is an exercise for the reader . conclusion the \" override \" pattern simplifies the way we customize packages starting from an existing set of packages . this opens aworld of possibilities for using a central repository like nixpkgs and defining overrides on our local machine without modifying the original package . we can dream of a custom , isolated nix - shell environment for testing graphviz with a custom gd : debugversion ( graphviz . override { gd = customgd ; } ) once a new version of the overridden package comes out in the repository ,", " the customized package will make use of it automatically . the key in nix is to find powerful yet simple abstractions in order to let the user customize their environment with highest consistency and lowest maintenance time , by using predefined composable components . next pill in the next pill , we will talk about nix search paths . by \" search path \" , we mean a place in the file system where nix looks for expressions . this answers the question of where < nixpkgs > comes from . nix search paths welcome to the 15th nix pill . in the previous 14th pill we have introduced the \" override \" pattern , useful for", " writing variants of derivations by passing different inputs . assuming you followed the previous posts , i hope you are now ready to understand nixpkgs . but we have to find nixpkgs in our system first ! so this is the step : introducing some options and environment variables used by nix tools . the nix _ path the nix _ path environment variable is very important . it ' s very similar to the path environment variable . the syntax is similar , several paths are separated by a colon : . nix will then search for something in those paths from left to right . who uses nix _ path ? the nix expressions ! yes , nix _", " path is not of much use by the nix tools themselves , rather it ' s used when writing nix expressions . in the shell for example , when you execute the command ping , it ' s being searched in the path directories . the first one found is the one being used . in nix it ' s exactly the same , however the syntax is different . instead of just typing ping you have to type < ping > . yes , i know . . . you are already thinking of < nixpkgs > . however , don ' t stop reading here , let ' s keep going . what ' s nix _ path good for ? nix", " expressions may refer to an \" abstract \" path such as < nixpkgs > , and it ' s possible to override it from the command line . for ease we will use nix - instantiate - - eval to do our tests . i remind you , nix - instantiate is used to evaluate nix expressions and generate the . drv files . here we are not interested inbuilding derivations , so evaluation is enough . it can be used for one - shot expressions . fake it a little it ' s useless from a nix view point , but i think it ' s useful for your own understanding . let ' s use path", " itself as nix _ path , and try to locate ping ( or another binary if you don ' t have it ) . $ nix - instantiate - - eval - e ' < ping > ' error : file ` ping ' was not found in the nix search path ( add it using $ nix _ path or - i ) $ nix _ path = $ path nix - instantiate - - eval - e ' < ping > ' / bin / ping $ nix - instantiate - i / bin - - eval - e ' < ping > ' / bin / ping great . at first attempt nix obviously said could not be found", " anywhere in the search path . note that the - i option accepts a single directory . paths added with - i take precedence over nix _ path . the nix _ path also accepts a different yet very handy syntax : \" somename = somepath \" . that is , instead of searching inside a directory for a name , we specify exactly the value of that name . $ nix _ path = \" ping = / bin / ping \" nix - instantiate - - eval - e ' < ping > ' / bin / ping $ nix _ path = \" ping = / bin / foo \" nix - instantiate - - eval - e '", " < ping > ' error : file ` ping ' was not found in the nix search path ( add it using $ n note in the second case how nix checks whether the path exists or not . the path to repository you are out of curiosity , right ? $ nix - instantiate - - eval - e ' < nixpkgs > ' / home / nix / . nix - defexpr / channels / nixpkgs $ echo $ nix _ path nixpkgs = / home / nix / . nix - defexpr / channels / nixpkgs you may have a different path , depending on how you", " added channels etc . . anyway that ' s the whole point . the < nixpkgs > stranger that we used in our nix expressions , is referring to a path in the filesystem specified by nix _ path . you can list that directory and realize it ' s simply a checkout of the nixpkgs repository at a specific commit ( hint : . version - suffix ) . the nix _ path variable is exported by nix . sh , and that ' s the reason why i always asked you to source nix . sh at the beginning of my posts . you may wonder : then i can also specify a different nixpk", "gs path to , e . g . , a git checkout of nixpkgs ? yes , you can and i encourage doing that . we ' ll talk about this in the next pill . let ' s define a path for our repository , then ! let ' s say all the default . nix , graphviz . nix etc . are under / home / nix / mypkgs : $ export nix _ path = mypkgs = / home / nix / mypkgs : $ nix _ path $ nix - instantiate - - eval ' < mypkgs > ' { graphviz", " = < code > ; graphvizcore = < code > ; hello = < code > ; mkderivation = < code > ; } yes , nix - build also accepts paths with angular brackets . we first evaluate the whole repository ( default . nix ) and then pick the graphviz attribute . a big word about nix - env the nix - env command is a little different than nix - instantiate and nix - build . whereas nix - instantiate and nix - build require a starting nix expression , nix - env does not . you may be crippled by this concept at the beginning , you may think nix - en", "v uses nix _ path to find the nixpkgs repository . but that ' s not it . the nix - env command uses ~ / . nix - defexpr , which is also part of nix _ path by default , but that ' s only a coincidence . if you empty nix _ path , nix - env will still be able to find derivations because of ~ / . nix - defexpr . so if you run nix - env - i graphviz inside your repository , it will install the nixpkgs one . same if you set nix _ path to point to your repository . in order", " to specify an alternative to ~ / . nix - defexpr it ' s possible to use the - f option : $ nix - env - f ' < mypkgs > ' - i graphviz warning : there are multiple derivations named ` graphviz ' ; using the first one replacing old ` graphviz ' installing ` graphviz ' oh why did it say there ' s another derivation named graphviz ? because both graphviz and graphvizcore attributes in our repository have the name \" graphviz \" for the derivation : $ nix - env - f ' < mypk", "gs > ' - qap graphviz graphviz graphvizcore graphviz hello hello by default nix - env parses all derivations and uses the derivation names to interpret the command line . so in this case \" graphviz \" matched two derivations . alternatively , like for nix - build , one can use - a to specify an attribute name instead of a derivation name : $ nix - env - f ' < mypkgs > ' - i - a graphviz replacing old ` graphviz ' installing ` graphviz ' this form , other than being more precise , it ' s", " also faster because nix - env does not have to parse all the derivations . for completeness : you must install graphvizcore with - a , since without the - a switch it ' s ambiguous . in summary , it may happen when playing with nix that nix - env picks a different derivation than nix - build . in that case you probably specified nix _ path , but nix - env is instead looking into ~ / . nix - defexpr . why is nix - env having this different behavior ? i don ' t know specifically by myself either , but the answers could be : * nix - env", " tries to be generic , thus it does not look for nixpkgs in nix _ path , rather it looks in ~ / . nix - defexpr . * nix - env is able to merge multiple trees in ~ / . nix - defexpr by looking at all the possible derivations it may also happen to you that you cannot match a derivation name when installing , because of the derivation name vs - a switch describe d above . maybe nix - env wanted to be more friendly in this case for default user setups . it may or may not make sense for you , or it ' s like that for historical", " reasons , but that ' s how it works currently , unless somebody comes up with a better idea . conclusion the nix _ path variable is the search path used by nix when using the angular brackets syntax . it ' s possible to refer to \" abstract \" paths inside nix expressions and define the \" concrete \" path by means of nix _ path , or the usual - i flag in nix tools . we ' ve also explained some of the uncommon nix - env behaviors for newcomers . the nix - env tool does not use nix _ path to search for packages , but rather for ~ / . nix - defexpr . beware of that", " ! in general do not abuse nix _ path , when possible use relative paths when writing your own nix expressions . of course , in the case of < nixpkgs > in our repository , that ' s a perfectly fine usage of nix _ path . instead , inside our repository itself , refer to expressions with relative paths like . / hello . nix . next pill . . . we will finally dive into nixpkgs . most of the techniques we have developed in this series are already in nixpkgs , like mkderivation , callpackage , override , etc . , but of course better . with time , those", " base utilities get enhanced by the community with more features in order to handle more and more use cases and in a more general way . nixpkgs parameters welcome to the 16th nix pill . in the previous 15th pill we ' ve realized how nix finds expressions with the angular brackets syntax , so that we finally know where < nixpkgs > is located on our system . we can start diving into the nixpkgs repository , through all the various tools and design patterns . please note that also nixpkgs has its own manual , underlying the difference between the general nix language and the nixpkgs repository . the default .", " nix expression we will not start inspecting packages at the beginning , rather the general struct ure of nixpkgs . in our custom repository we created a default . nix which composed the expressions of the various packages . also nixpkgs has its own default . nix , which is the one being loaded when referring to < nixpkgs > . it does a simple thing : check whether the nix version is at least 1 . 7 ( at the time of writing this blog post ) . then import pkgs / top - level / all - packages . nix . from now on , we will refer to this set of packages", " as pkgs . the all - packages . nix is then the file that composes all the packages . note the pkgs / subdirectory ,while nixos is in the nixos / subdirectory . the all - packages . nix is a bit contrived . first of all , it ' s a function . it accepts a couple of interesting parameters : * system : defaults to the current system * config : defaults to null * others . . . the system parameter , as per comment in the expression , it ' s the system for which the packages will be built . it", " allows for example to install i686 packages on amd64 machines . the config parameter is a simple attribute set . packages can read some of its values and change the behavior of some derivations . the system parameter you will find this parameter in many other . nix expressions ( e . g . release expressions ) . the reason is that , given pkgs accepts a system parameter , then whenever you want to import pkgs you also want to pass through the value of system . e . g . : myrelease . nix : { system ? builtins . currentsystem } : let pkgs = import <", " nixpkgs > { inherit system ; } ; . . . why is it useful ? with this parameter it ' s very easy to select a set of packages for a particular system . for example : nix - build - a psmisc - - argstr system i686 - linux this will build the psmisc derivation for i686 - linux instead of x86 _ 64 - linux . this concept is very similar to multi - arch of debian . the setup for cross compiling is also in nixpkgs , however it ' s a little contrived to talk about it and i don ' t know", " much of it either . the config parameter i ' m sure on the wiki or other manuals you ' ve read about ~ / . config / nixpkgs / config . nix ( previously ~ / . nixpkgs / config . nix ) and i ' m sure you ' ve wondered whether that ' s hardcoded in nix . it ' s not , it ' s in nixpkgs . the all - packages . nix expression accepts the config parameter . if it ' s null , then it reads the nixpkgs _ config environment variable .", " if not specified , nixpkgs will pick $ home / . config / nixpkgs / config . nix . after determining config . nix , it will be imported as a nix expression , and that will be the value of config ( in case it hasn ' t been passed as parameter to import < nixpkgs > ) . the config is available in the resulting repository : $ nix repl nix - repl > pkgs = import < nixpkgs > { } nix - repl > pkgs . config { } nix - repl", " > pkgs = import < nixpkgs > { config = { foo = \" bar \" ; } ; } nix - repl > pkgs . config { foo = \" bar \" ; } what attributes go in config is a matter of convenience and conventions . for example , config . allowunfree is an attribute that forbidsbuilding packages that have an unfree license by default . the config . pulseaudio setting tells whether to build packages with pulseaudio support or not where applicable and when the derivation obeys to the setting . about . nix functions a .", " nix file contains a nix expression . thus it can also be a function . i remind you that nix - build expects the expression to return a derivation . therefore it ' s natural to return straight a derivation from a . nix file . however , it ' s also very natural for the . nix file to accept some parameters , in order to tweak the derivation being returned . in this case , nix does a trick : * if the expression is a derivation , build it . * if the expression is a function , call it and build the resulting derivation . for example you can nix - build the . nix file below : { pkgs", " ? import < nixpkgs > { } } : pkgs . psmisc nix is able to call the function because the pkgs parameter has a default value . this allows you to pass a different value for pkgs using the - - arg option . does it work if you have a function returning a function that returns a derivation ? no , nix only calls the function it encounters once . conclusion we ' ve unleashed the < nixpkgs > repository . it ' s a function that accepts some parameters , and returns the set of all packages . due to laziness , only the accessed derivations will", " be built . you can use this repository to build your own packages as we ' ve seen in the previous pill when creating our own repository . lately i ' m a little busy with the nixos 14 . 11 release and other stuff , and i ' m also looking toward migrating from blogger to a more coder - oriented blogging platform . so sorry for the delayed and shorter pills : ) next pill . . . we will talk about overriding packages in the nixpkgs repository . what if you want to change some options of a library and let all other packages pick the new library ? one possibility is to use , like describe", " d above , the config parameter when applicable . the other possibility is to override derivations . nixpkgs overriding packages welcome to the 17th nix pill . in the previous 16th pill we have started to dive into the nixpkgs repository . nixpkgs is a function , and we ' ve looked at some parameters like system and config . today we ' ll talk about a special attribute : config . packageoverrides . overriding packages in a set with fixed point can be considered another design pattern in nixpkgs . overriding a package recall the override design pattern from the", " nix pill 14 . instead of calling a function with parameters directly , we make the call ( function + parameters ) overridable . we put the override function in the returned attribute set of the original function call . take for example graphviz . it has an input parameter xorg . if it ' s null , then graphviz will build without x support . $ nix repl nix - repl > : l < nixpkgs > added 4360 variables . nix - repl > : b graphviz . override { withxorg = false ; } this will build graphviz without x support , it", " ' s as simple as that . however , let ' s say a package p depends on graphviz , how do we make p depend on the new graphviz without x support ? in an imperativeworld . . . . . . you could do something like this : pkgs = import < nixpkgs > { } ; pkgs . graphviz = pkgs . graphviz . override { withxorg = false ; } ; build ( pkgs . p ) given pkgs . p depends on pkgs . graphviz , it ' s easy to build p with", " the replaced graphviz . in a pure functional language it ' s not that easy because you can assign to variables only once . fixed point the fixed point with lazy evaluation is crippling but about necessary in a language like nix . it lets us achieve something similar to what we ' d do imperatively . follows the definition of fixed point in nixpkgs : { # take a function and evaluate it with its own returned value . fix = f : let result = f result ; in result ; } it ' s a function that accepts a function f , calls f result on the result just returned by f result and returns it", " . in other words it ' s f ( f ( f ( . . . . at first sight , it ' s an infinite loop . with lazy evaluation it isn ' t , because the call is done only when needed . nix - repl > fix = f : let result = f result ; in result nix - repl > pkgs = self : { a = 3 ; b = 4 ; c = self . a + self . b ; } nix - repl > fix pkgs { a = 3 ; b = 4 ; c = 7 ; } without the rec keyword , we were able to refer to", " a and b of the same set . * first pkgs gets called with an unevaluated thunk ( pkgs ( pkgs ( . . . ) * to set the value of c then self . a and self . b are evaluated . * the pkgs function gets called again to get the value of a and b . the trick is that c is not needed to be evaluated in the inner call , thus it doesn ' t go in an infinite loop . won ' t go further with the explanation here . a good post about fixed point and nix can be found here . overriding a set with fixed point", " given that self . a and self . b refer to the passed set and not to the literal set in the function , we ' re able to override both a and b and get a new value for c : nix - repl > overrides = { a = 1 ; b = 2 ; } nix - repl > let newpkgs = pkgs ( newpkgs / / overrides ) ; in newpkgs { a = 3 ; b = 4 ; c = 3 ; } nix - repl > let newpkgs = pkgs ( newpkgs / /", " overrides ) ; in newpkgs / / overrides { a = 1 ; b = 2 ; c = 3 ; } in the first case we computed pkgs with the overrides , in the second case we also included the overridden attributes in the result . overriding nixpkgs packages we ' ve seen how to override attributes in a set such that they get recursively picked by dependent attributes . this approach can be used for derivations too , after all nixpkgs is a giant set of attributes that depend on each other . to do this , nixpkgs offers", " config . packageoverrides . so nixpkgs returns a fixed point of the package set , and packageoverrides is used to inject the overrides . create a config . nix file like this somewhere : { packageoverrides = pkgs : { graphviz = pkgs . graphviz . override { # disable xorg support withxorg = false ; } ; } ; } now we can build e . g . asciidoc - full and it will automatically use the overridden graphviz : nix - repl > pkgs", " = import < nixpkgs > { config = import . / config . nix ; } nix - repl > : b pkgs . asciidoc - full note how we pass the config with packageoverrides when importing nixpkgs . then pkgs . asciidoc - full is a derivation that has graphviz input ( pkgs . asciidoc is the lighter version and doesn ' t use graphviz at all ) . since there ' s no version of asciidoc with graphviz without x support in the binary cache", " , nix will recompile the needed stuff for you . the ~ / . config / nixpkgs / config . nix file in the previous pill we already talked about this file . the above config . nix that we just wrote could be the content of ~ / . config / nixpkgs / config . nix ( or the deprecated location ~ / . nixpkgs / config . nix ) . instead of passing it explicitly whenever we import nixpkgs , it will be automatically imported by nixpkgs . conclusion we ' ve learned about a", " new design pattern : using fixed point for overriding packages in a package set . whereas in an imperative setting , like with other package managers , a library is installed replacing the old version and applications will use it , in nix it ' s not that straight and simple . but it ' s more precise . nix applications will depend on specific versions of libraries , hence the reason why we have to recompile asciidoc to use the new graphviz library . the newly built asciidoc will depend on the new graphviz , and old asciidoc will keep using the old graphviz undisturbed . next", " pill . . . we will stop studying nixpkgs for a moment and talk about store paths . how does nix compute the path in the store where to place the result of builds ? how to add files to the store for which we have an integrity hash ? nix store paths welcome to the 18th nix pill . in the previous 17th pill we have scratched the surface of the nixpkgs repository struct ure . it is a set of packages , and it ' s possible to override such packages so that all other packages will use the overrides . before reading existing derivations , i ' d like to talk about store", " paths and how they are computed . in particular we are interested in fixed store paths that depend on an integrity hash ( e . g . a sha256 ) , which is usually applied to source tarballs . the way store paths are computed is a little contrived , mostly due to historical reasons . our reference will be the nix source code . source paths let ' s start simple . you know nix allows relative paths to be used , such that the file or directory is stored in the nix store , that is . / myfile gets stored into / nix / store / . . . . . . . we want to understand how", " is the store path generated for such a file : $ echo mycontent > myfile i remind you , the simplest derivation you can write has a name , a builder and the system : $ nix repl nix - repl > derivation { system = \" x86 _ 64 - linux \" ; builder = . / myfile ; name = \" foo \" ; } \u00ab derivation / nix / store / y4h73bmrc9ii5bxg6i7ck6hsf5gqv8ck - foo . drv \u00bb now inspect the . drv to see where is . /", " myfile being stored : $ nix derivation show / nix / store / y4h73bmrc9ii5bxg6i7ck6hsf5gqv8ck - foo . drv { \" / nix / store / y4h73bmrc9ii5bxg6i7ck6hsf5gqv8ck - foo . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / hs0yi5n5nw6micqhy8l1igkbhqdk", "zqa1 - foo \" } } , \" inputsrcs \" : [ \" / nix / store / xv2iccirbrvklck36f1g7vldn5v58vck - myfile \" ] , \" inputdrvs \" : { } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / xv2iccirbrvklck36f1g7vldn5v58vck - myfile \" , \" args \" : [ ] , \" env \" : { \"", " builder \" : \" / nix / store / xv2iccirbrvklck36f1g7vldn5v58vck - myfile \" , \" name \" : \" foo \" , \" out \" : \" / nix / store / hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 - foo \" , \" system \" : \" x86 _ 64 - linux \" } } } great , how did nix decide to use xv2iccirbrvklck36f1g7vldn5v58", "vck ? keep looking at the nix comments . note : doing nix - store - - add myfile will store the file in the same store path . step 1 , compute the hash of the file the comments tell us to first compute the sha256 of the nar serialization of the file . can be done in two ways : $ nix - hash - - type sha256 myfile 2bfef67de873c54551d884fdab3055d84d573e654efa79db3c0d7b9888", "3f9ee3 or : $ nix - store - - dump myfile | sha256sum 2bfef67de873c54551d884fdab3055d84d573e654efa79db3c0d7b98883f9ee3 in general , nix understands two contents : flat for regular files , or recursive for nar serializations which can be anything . step 2 , build the string descript ion then nix uses a special string which includes the hash , the path type and the file name .", " we store this in another file : $ echo - n \" source : sha256 : 2bfef67de873c54551d884fdab3055d84d573e654efa79db3c0d7b98883f9ee3 : / nix / store : myfile \" > myfile . str step 3 , compute the final hash finally the comments tell us to compute the base - 32 representation of the first 160 bits ( truncation ) of a sha256 of the above string : $ nix -", " hash - - type sha256 - - truncate - - base32 - - flat myfile . str xv2iccirbrvklck36f1g7vldn5v58vck output paths output paths are usually generated for derivations . we use the above example because it ' s simple . even if we didn ' t build the derivation , nix knows the out path hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 . this is because the out path only depends on inputs . it ' s computed in a similar", " way to source paths , except that the . drv is hashed and the type of derivation is output : out . in case of multiple outputs , we may have different output : < id > . at the time nix computes the out path , the . drv contains an empty string for each out path . so what we do is getting our . drv and replacing the out path with an empty string : $ cp - f / nix / store / y4h73bmrc9ii5bxg6i7ck6hsf5gqv8ck - foo . drv myout . drv", " $ sed - i ' s , / nix / store / hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 - foo , , g ' myout . drv the myout . drv is the . drv state in which nix is when computing the out path for our derivation : $ sha256sum myout . drv 1bdc41b9649a0d59f270a92d69ce6b5af0bc82b46cb9d9441ebc6620665f40", "b5 myout . drv $ echo - n \" output : out : sha256 : 1bdc41b9649a0d59f270a92d69ce6b5af0bc82b46cb9d9441ebc6620665f40b5 : / nix / store : foo \" > myout . str $ nix - hash - - type sha256 - - truncate - - base32 - - flat myout . str hs0yi5n5nw6micqhy8l1igkbhqd", "kzqa1 then nix puts that out path in the . drv , and that ' s it . in case the . drv has input derivations , that is it references other . drv , then such . drv paths are replaced by this same algorithm which returns a hash . in other words , you get a final . drv where every other . drv path is replaced by its hash . fixed - output paths finally , the other most used kind of path is when we know beforehand an integrity hash of a file . this is usual for tarballs . a derivation can take three special attributes : outputhashm", "ode , outputhash and outputhashalgo which are well documented in the nix manual . the builder must create the out path and make sure its hash is the same as the one declared with outputhash . let ' s say our builder should create a file whose contents is mycontent : $ echo mycontent > myfile $ sha256sum myfile f3f3c4763037e059b4d834eaf68595bbc02ba19f6d2a500dce06d124e2cd99bb my", "file nix - repl > derivation { name = \" bar \" ; system = \" x86 _ 64 - linux \" ; builder = \" none \" ; outputhashmode = \" flat \" ; outputhashalgo = \" sha256 \" ; outputhash = \" f3f3c4763037e059b4d834eaf68595bbc02ba19f6d2a500dce06d124e2cd99bb \" ; } \u00ab derivation / nix / store / ymsf5zcqr9wlkkqd", "jwhqllgwa97rff5i - bar . drv \u00bb inspect the . drv and see that it also stored the fact that it ' s a fixed - output derivation with sha256 algorithm , compared to the previous examples : $ nix derivation show / nix / store / ymsf5zcqr9wlkkqdjwhqllgwa97rff5i - bar . drv { \" / nix / store / ymsf5zcqr9wlkkqdjwhqllgwa97rff5i - bar", " . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / a00d5f71k0vp5a6klkls0mvr1f7sx6ch - bar \" , \" hashalgo \" : \" sha256 \" , \" hash \" : \" f3f3c4763037e059b4d834eaf68595bbc02ba19f6d2a500dce06d124e2cd99bb \" } } , [ .", " . . ] } it doesn ' t matter which input derivations are being used , the final out path must only depend on the declared hash . what nix does is to create an intermediate string representation of the fixed - output content : $ echo - n \" fixed : out : sha256 : f3f3c4763037e059b4d834eaf68595bbc02ba19f6d2a500dce06d124e2cd99bb : \" > mycontent . str $ sha256sum mycontent . st", "r 423e6fdef56d53251c5939359c375bf21ea07aaa8d89ca5798fb374dbcfd7639 myfile . str then proceed as it was a normal derivation output path : $ echo - n \" output : out : sha256 : 423e6fdef56d53251c5939359c375bf21ea07aaa8d89ca5798fb374dbcfd7639 : / nix / store : bar", " \" > myfile . str $ nix - hash - - type sha256 - - truncate - - base32 - - flat myfile . str a00d5f71k0vp5a6klkls0mvr1f7sx6ch hence , the store path only depends on the declared fixed - output hash . conclusion there are other types of store paths , but you get the idea . nix first hashes the contents , then creates a string descript ion , and the final store path is the hash of this string . also we ' ve introduced some fundamentals", " , in particular the fact that nix knows beforehand the out path of a derivation since it only depends on the inputs . we ' ve also introduced fixed - output derivations which are especially used by the nixpkgs repository for downloading and verifying source tarballs . next pill . . . we will introduce stdenv . in the previous pills we rolled our own mkderivation convenience function for wrapping the builtin derivation , but the nixpkgs repository also has its own convenience functions for dealing with autotools projects and other build systems . fundamentals of stdenv welcome to the 19th nix pill . in the previous 18th", " pill we dived into the algorithm used by nix to compute the store paths , and also introduced fixed - output store paths . this time we will instead look into nixpkgs , in particular one of its core derivations : stdenv . the stdenv is not treated as a special derivation by nix , but it ' s very important for the nixpkgs repository . it serves as a base for packaging software . it is used to pull in dependencies such as the gcc toolchain , gnu make , core utilities , patch and diff utilities , and so on : basic tools needed to compile a huge", " pile of software currently present in nixpkgs . what is stdenv ? first of all , stdenv is a derivation , and it ' s a very simple one : $ nix - build ' < nixpkgs > ' - a stdenv / nix / store / k4jklkcag4zq4xkqhkpy156mgfm34ipn - stdenv $ ls - r result / result / : nix - support / setup result / nix - support : propagated - user - env - packages it has just two files : / setup and / nix", " - support / propagated - user - env - packages . don ' t worry about the latter . it ' s empty , in fact . the important file is / setup . how can this simple derivation pull in all of the toolchain and basic tools needed to compile packages ? let ' s look at the runtime dependencies : $ nix - store - q - - references result / nix / store / 3a45nb37s0ndljp68228snsqr3qsyp96 - bzip2 - 1 . 0 . 6 / nix / store / a457", "ywa1haa0sgr9g7a1pgldrg3s798d - coreutils - 8 . 24 / nix / store / zmd4jk4db5lgxb8l93mhkvr3x92g2sx2 - bash - 4 . 3 - p39 / nix / store / 47sfpm2qclpqvrzijizimk4md1739b1b - gcc - wrapper - 4 . 9 . 3 . . . how can it be ? the package must be referring to those other packages somehow . in", " fact , they are hardcoded in the / setup file : $ head result / setup export shell = / nix / store / zmd4jk4db5lgxb8l93mhkvr3x92g2sx2 - bash - 4 . 3 - p39 / bin / bash initialpath = \" / nix / store / a457ywa1haa0sgr9g7a1pgldrg3s798d - coreutils - 8 . 24 . . . \" defaultnativebuildinputs = \" / nix / store / sgw", "q15xg00xnm435gjicspm048rqg9y6 - patchelf - 0 . 8 . . . \" the setup file remember our generic builder . sh in pill 8 ? it sets up a basic path , unpacks the source and runs the usual autotools commands for us . the stdenv setup file is exactly that . it sets up several environment variables like path and creates some helper bash functions to build a package . i invite you to read it . the hardcoded toolchain and utilities are used to initially fill up the environment variables so that it", " ' s more pleasant to run common commands , similar to what we did with our builder with baseinputs and buildinputs . the build with stdenv works in phases . phases are like unpackphase , configurephase , buildphase , checkphase , installphase , fixupphase . you can see the default list in the genericbuild function . what genericbuild does is just run these phases . default phases are just bash functions . you can easily read them . every phase has hooks to run commands before and after the phase has been executed . phases can be", " overwritten , reordered , whatever , it ' s just bash code . how to use this file ? like our old builder . to test it , we enter a fake empty derivation , source the stdenv setup , unpack the hello sources and build it : $ nix - shell - e ' derivation { name = \" fake \" ; builder = \" fake \" ; system = \" x86 _ 64 - linux \" ; } ' nix - shell $ unset path nix - shell $ source / nix / store / k4jklkcag4zq4xkqhkpy156mgfm34ipn", " - stdenv / setup nix - shell $ tar - xf hello - 2 . 10 . tar . gz nix - shell $ cd hello - 2 . 10 nix - shell $ configurephase . . . nix - shell $ buildphase . . . i unset path to further show that the stdenv is sufficiently self - contained to build autotools packages that have no other dependencies . so we ran the configurephase function and buildphase function and they worked . these bash functions should be self - explanatory . you can read the code in the setup file", " . how the setup file is built until now we worked with plain bash script s . what about the nix side ? the nixpkgs repository offers a useful function , like we did with our old builder . it is a wrapper around the raw derivation function which pulls in the stdenv for us , and runs genericbuild . it ' s stdenv . mkderivation . note how stdenv is a derivation but it ' s also an attribute set which contains some other attributes , like mkderivation . nothing fancy here , just convenience . let ' s write a hello . nix expression using this newly discovered", " stdenv : with import < nixpkgs > { } ; stdenv . mkderivation { name = \" hello \" ; src = . / hello - 2 . 10 . tar . gz ; } don ' t be scared by the with expression . it pulls the nixpkgs repository into scope , so we can directly use stdenv . it looks very similar to the hello expression in pill 8 . it builds , and runs fine : $ nix - build hello . nix . . . / nix / store / 6y0mzdarm5qxfafvn2zm9nr01", "d1j0a72 - hello $ result / bin / hello hello ,world ! the stdenv . mkderivation builder let ' s take a look at the builder used by mkderivation . you can read the code here in nixpkgs : { # . . . builder = attrs . realbuilder or shell ; args = attrs . args or [ \" - e \" ( attrs . builder or . / default - builder . sh ) ] ; stdenv = result ; # . . . } also take a look at our old derivation wrapper in previous", " pills ! the builder is bash ( that shell variable ) , the argument to the builder ( bash ) is default - builder . sh , and then we add the environment variable $ stdenv in the derivation which is the stdenv derivation . you can open default - builder . sh and see what it does : source $ stdenv / setup genericbuild it ' s what we did in pill 10 to make the derivations nix - shell friendly . when entering the shell , the setup file only sets up the environment withoutbuilding anything . when doing nix - build , it actually runs the build process . to get a clear understanding", " of the environment variables , look at the . drv of the hello derivation : $ nix derivation show $ ( nix - instantiate hello . nix ) warning : you did not specify ' - - add - root ' ; the result might be removed by the garbage collector { \" / nix / store / abwj50lycl0m515yblnrvwyydlhhqvj2 - hello . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / 6y0mzdarm5qxfafvn2zm9nr01", "d1j0a72 - hello \" } } , \" inputsrcs \" : [ \" / nix / store / 9krlzvny65gdc8s7kpb6lkx8cd02c25b - default - builder . sh \" , \" / nix / store / svc70mmzrlgq42m9acs0prsmci7ksh6h - hello - 2 . 10 . tar . gz \" ] , \" inputdrvs \" : { \" / nix / store / hcgwbx42mcxr7ksnv0i", "1fg7kw6jvxshb - bash - 4 . 4 - p19 . drv \" : [ \" out \" ] , \" / nix / store / sfxh3ybqh97cgl4s59nrpi78kgcc8f3d - stdenv - linux . drv \" : [ \" out \" ] } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297", "d - bash - 4 . 4 - p19 / bin / bash \" , \" args \" : [ \" - e \" , \" / nix / store / 9krlzvny65gdc8s7kpb6lkx8cd02c25b - default - builder . sh \" ] , \" env \" : { \" buildinputs \" : \" \" , \" builder \" : \" / nix / store / q1g0rl8zfmz7r371fp5p42p4acmv297d - bash - 4 . 4 - p19 / bin", " / bash \" , \" configureflags \" : \" \" , \" depsbuildbuild \" : \" \" , \" depsbuildbuildpropagated \" : \" \" , \" depsbuildtarget \" : \" \" , \" depsbuildtargetpropagated \" : \" \" , \" depshostbuild \" : \" \" , \" depshostbuildpropagated \" : \" \" , \" depstargettarget \" : \" \" , \" depstargettargetpropagated \" : \"", " \" , \" name \" : \" hello \" , \" nativebuildinputs \" : \" \" , \" out \" : \" / nix / store / 6y0mzdarm5qxfafvn2zm9nr01d1j0a72 - hello \" , \" propagatedbuildinputs \" : \" \" , \" propagatednativebuildinputs \" : \" \" , \" src \" : \" / nix / store / svc70mmzrlgq42m9acs0prsmci7ksh6h - hello - 2", " . 10 . tar . gz \" , \" stdenv \" : \" / nix / store / 6kz2vbh98s2r1pfshidkzhiy2s2qdw0a - stdenv - linux \" , \" system \" : \" x86 _ 64 - linux \" } } } it ' s so short i decided to paste it entirely above . the builder is bash , with - e default - builder . sh arguments . then you can see the src and stdenv environment variables . the last bit , the unpackphase in the setup , is used to", " unpack the sources and enter the directory . again , like we did in our old builder . conclusion the stdenv is the core of the nixpkgs repository . all packages use the stdenv . mkderivation wrapper instead of the raw derivation . it does a bunch of operations for us and also sets up a pleasant build environment . the overall process is simple : * nix - build * bash - e default - builder . sh * source $ stdenv / setup * genericbuild that ' s it . everything you need to know about the stdenv phases is in the setup file . really , take", " your time to read that file . don ' t forget that juicy docs are also available in the nixpkgs manual . next pill . . . . . . we will talk about how to add dependencies to our packages with buildinputs and propagatedbuildinputs , and influence downstream builds with setup hooks and env hooks . these concepts are crucial to how nixpkgs packages are composed . basic dependencies and hooks welcome to the 20th nix pill . in the previous 19th pill we introduced nixpkgs ' stdenv , including setup . sh script , default - builder . sh help", "er script , and stdenv . mkderivation builder . we focused on how stdenv is put together , and how it ' s used , and a bit about the phases of genericbuild . this time , we ' ll focus on the interaction of packages built with stdenv . mkderivation . packages need to depend on each other , of course . for this we have buildinputs and propagatedbuildinputs attributes . we ' ve also found that dependencies sometimes need to influence their dependents in ways the dependents can ' t or shouldn ' t predict . for this we", " have setup hooks and env hooks . together , these 4 concepts support almost all build - time package interactions . note : the complexity of the dependencies and hooks infrastruct ure has increased , over time , to support cross compilation . once you learn the core concepts , you will be able to understand the extra complexity . as a starting point , you might want to refer to nixpkgs commit 6675f0a5 , the last version of stdenv without cross - compilation complexity . the buildinputs attribute for the simplest dependencies where the current package directly needs another , we use the buildinputs", " attribute . this is exactly the pattern used in our builder in pill 8 . to demo this , let ' s build gnu hello , and then another package which provides a shell script that execs it . let nixpkgs = import < nixpkgs > { } ; inherit ( nixpkgs ) stdenv fetchurl which ; actualhello = stdenv . mkderivation { name = \" hello - 2 . 3 \" ; src = fetchurl { url = \" mirror : / / gnu / hello / hello - 2 . 3 . tar . bz2 \" ; sha", "256 = \" 0c7vijq8y68bpr7g6dh1gny0bff8qq81vnp4ch8pjzvg56wb3js1 \" ; } ; } ; wrappedhello = stdenv . mkderivation { name = \" hello - wrapper \" ; buildinputs = [ actualhello which ] ; unpackphase = \" true \" ; installphase = ' ' mkdir - p \" $ out / bin \" echo \" # ! $ { stdenv . shell } \" > > \" $", " out / bin / hello \" echo \" exec $ ( which hello ) \" > > \" $ out / bin / hello \" chmod 0755 \" $ out / bin / hello \" ' ' ; } ; in wrappedhello notice that the wrappedhello derivation finds the hello binary from the path . this works because stdenv contains something like : pkgs = \" \" for i in $ buildinputs ; do findinputs $ i done where findinputs is defined like : findinputs ( ) { local pkg = $ 1 # # don ' t need to repeat already", " processed package case $ pkgs in * \\ $ pkg \\ * ) return 0 ; ; esac pkgs = \" $ pkgs $ pkg \" # # more goes here in reality that we can ignore for now . } then after this is run : for i in $ pkgs ; do addtoenv $ i done where addtoenv is defined like : addtoenv ( ) { local pkg = $ 1 if test - d $ 1 / bin ; then addtosearchpath _ path $ 1 / bin fi # # more goes here in reality that we", " can ignore for now . } the addtosearchpath call adds $ 1 / bin to _ path if the former exists ( code here ) . once all the packages in buildinputs have been processed , then content of _ path is added to path , as follows : path = \" $ { _ path - } $ { _ path : + $ { path : + : } } $ path \" with the real hello on the path , the installphase should hopefully make sense . the propagatedbuildinputs attribute the buildinputs covers direct dependencies , but what about indirect dependencies where one package", " needs a second package which needs a third ? nix itself handles this just fine , understanding various dependency closures as covered in previous builds . but what about the conveniences that buildinputs provides , namely accumulating in pkgs environment variable and inclusion of \u00ab pkg \u00bb / bin directories on the path ? for this , stdenv provides the propagatedbuildinputs : let nixpkgs = import < nixpkgs > { } ; inherit ( nixpkgs ) stdenv fetchurl which ; actualhello = stdenv . mkderivation { name =", " \" hello - 2 . 3 \" ; src = fetchurl { url = \" mirror : / / gnu / hello / hello - 2 . 3 . tar . bz2 \" ; sha256 = \" 0c7vijq8y68bpr7g6dh1gny0bff8qq81vnp4ch8pjzvg56wb3js1 \" ; } ; } ; intermediary = stdenv . mkderivation { name = \" middle - man \" ; propagatedbuildinputs = [ actualhello ] ;", " unpackphase = \" true \" ; installphase = ' ' mkdir - p \" $ out \" ' ' ; } ; wrappedhello = stdenv . mkderivation { name = \" hello - wrapper \" ; buildinputs = [ intermediary which ] ; unpackphase = \" true \" ; installphase = ' ' mkdir - p \" $ out / bin \" echo \" # ! $ { stdenv . shell } \" > > \" $ out / bin / hello \" echo \" exec $ ( which hello ) \" > > \" $ out / bin", " / hello \" chmod 0755 \" $ out / bin / hello \" ' ' ; } ; in wrappedhello see how the intermediate package has a propagatedbuildinputs dependency , but the wrapper only needs a buildinputs dependency on the intermediary . how does this work ? you might think we do something in nix , but actually it ' s done not at eval time but at build time in bash . let ' s look at part of the fixupphase of stdenv : fixupphase ( ) { # # elided if test - n \" $ propaga", "tedbuildinputs \" ; then mkdir - p \" $ out / nix - support \" echo \" $ propagatedbuildinputs \" > \" $ out / nix - support / propagated - build - inputs \" fi # # elided } this dumps the propagated build inputs in a so - named file in $ out / nix - support / . then , back in findinputs look at the lines at the bottom we elided before : findinputs ( ) { local pkg = $ 1 # # more goes here in reality that we can ignore for now", " . if test - f $ pkg / nix - support / propagated - build - inputs ; then for i in $ ( cat $ pkg / nix - support / propagated - build - inputs ) ; do findinputs $ i done fi } see how findinputs is actually recursive , looking at the propagated build inputs of each dependency , and those dependencies ' propagated build inputs , etc . we actually simplified the findinputs call site from before ; propagatedbuildinputs is also looped over in reality : pkgs = \"", " \" for i in $ buildinputs $ propagatedbuildinputs ; do findinputs $ i done this demonstrates an important point . for the current package alone , it doesn ' t matter whether a dependency is propagated or not . it will be processed the same way : called with findinputs and addtoenv . ( the packages discovered by findinputs , which are also accumulated in pkgs and passed to addtoenv , are also the same in both cases . ) downstream however , it certainly does matter because only the propagated immediate dependencies are put in", " the $ out / nix - support / propagated - build - inputs . setup hooks as we mentioned above , sometimes dependencies need to influence the packages that use them in ways other than just being a dependency . ^ 1 propagatedbuildinputs can actually be seen as an example of this : packages using that are effectively \" injecting \" those dependencies as extra buildinputs in their downstream dependents . but in general , a dependency might affect the packages it depends on in arbitrary ways . arbitrary is the key word here . we could teach setup . sh things about upstream packages like \u00ab pkg \u00bb", " / nix - support / propagated - build - inputs , but not arbitrary interactions . setup hooks are the basicbuilding block we have for this . in nixpkgs , a \" hook \" is basically a bash callback , and a setup hook is no exception . let ' s look at the last part of findinputs we haven ' t covered : findinputs ( ) { local pkg = $ 1 # # more goes here in reality that we can ignore for now . if test - f $ pkg / nix - support / setup - hook ; then source $ pkg / nix -", " support / setup - hook fi # # more goes here in reality that we can ignore for now . } if a package includes the path \u00ab pkg \u00bb / nix - support / setup - hook , it will be sourced by any stdenv - based build including that as a dependency . this is strictly more general than any of the other mechanisms introduced in this chapter . for example , try writing a setup hook that has the same effect as a propagatedbuildinputs entry . one can almost think of this as an escape hatch around nix ' s normal isolation guarantees , and the principle that dependencies are immutable", " and inert . we ' re not actually doing something unsafe or modifying dependencies , but we are allowing arbitrary ad - hoc behavior . for this reason , setup - hooks should only be used as a last resort . environment hooks as a final convenience , we have environment hooks . recall in pill 12 how we created nix _ cflags _ compile for - i flags and nix _ ldflags for - l flags , in a similar manner to how we prepared the path . one point of ugliness was how anti - modular this was . it makes sense to build the path in a generic builder , because the path is used by the", " shell , and the generic builder is intrinsically tied to the shell . but - i and - l flags are only relevant to the c compiler . the stdenv isn ' t wedded to including a c compiler ( though it does by default ) , and there are other compilers too which may take completely different flags . as a first step , we can move that logic to a setup hook on the c compiler ; indeed that ' s just what we do in cc wrapper . ^ 2 but this pattern comes up fairly often , so somebody decided to add some helper support to reduce boilerplate . the other half of addtoen", "v is : addtoenv ( ) { local pkg = $ 1 # # more goes here in reality that we can ignore for now . # run the package - specific hooks set by the setup - hook script s . for i in \" $ { envhooks [ @ ] } \" ; do $ i $ pkg done } functions listed in envhooks are applied to every package passed to addtoenv . one can write a setup hook like : anenvhook ( ) { local pkg = $ 1 echo \" i ' m depending on \\ \" $ p", "kg \\ \" \" } envhooks + = ( anenvhook ) and if one dependency has that setup hook then all of them will be so echoed . allowing dependencies to learn about their sibling dependencies is exactly what compilers need . next pill . . . . . . i ' m not sure ! we could talk about the additional dependency types and hooks which cross compilation necessitates ,building on our knowledge here to cover stdenv as it works today . we could talk about how nixpkgs is bootstrapped . or we could talk about how localsystem and crosssyste", "m are elaborated into the buildplatform , hostplatform , and targetplatform each bootstrapping stage receives . let us know which most interests you ! ^ 1 we can now be precise and consider what addtoenv does alone the minimal treatment of a dependency : i . e . a package that is just a dependency would only have addtoenv applied to it . ^ 2 it was called gcc wrapper in the version of nixpkgs suggested for following along in this pill ; darwin and clang support hadn ' t yet motivated the rename .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ install on your running system welcome to the second nix pill . in the first pill we briefly describe d nix . now we ' ll install nix on our running system and understand what changed in our system after the installation . if you", " ' re using nixos , nix is already installed ; you can skip to the next pill . for installation instruct ions , please refer to the nix reference manual on installing nix . installation these articles are not a tutorial on using nix . instead , we ' re going to walk through the nix system to understand the fundamentals . the first thing to note : derivations in the nix store refer to other derivations which are themselves in the nix store . they don ' t use libc from our system or anywhere else . it ' s a self - contained store of all the software we need to bootstrap up to any particular package", " . note : in a multi - user installation , such as the one used in nixos , the store is owned by root and multiple users can install and build software through a nix daemon . you can read more about multi - user installations here . the beginnings of the nix store start looking at the output of the install command : copying nix to / nix / store . . . . . . . . . . . . . . . . . . . . . . . . . . that ' s the / nix / store we were talking about in the first article . we ' re copying in the necessary software to bootstrap a", " nix system . you can see bash , coreutils , the c compiler toolchain , perl libraries , sqlite and nix itself with its own tools and libnix . you may have noticed that / nix / store can contain not only directories , but also files , still always in the form \u00ab hash - name \u00bb . the nix database right after copying the store , the installation process initializes a database : initialising nix database . . . yes , nix also has a database . it ' s stored under / nix / var / nix / db . it is a sqlite database that keeps track of the dependencies between", " derivations . the schema is very simple : there ' s a table of valid paths , mapping from an auto increment integer to a store path . then there ' s a dependency relation from path to paths upon which they depend . you can inspect the database by installing sqlite ( nix - env - ia sqlite - f ' < nixpkgs > ' ) and then running sqlite3 / nix / var / nix / db / db . sqlite . note : if this is the first time you ' re using nix after the initial installation , remember you must close and open your terminals first , so that your", " shell environment will be updated . important : never change / nix / store manually . if you do , then it will no longer be in sync with the sqlite db , unless you really know what you are doing . the first profile next in the installation , we encounter the concept of the profile : creating / home / nix / . nix - profile installing ' nix - 2 . 1 . 3 'building path ( s ) ` / nix / store / a7p1w3z2h8pl00ywvw6icr3g5l9vm5r7 - user - environment ' created 7 syml", "inks in user environment a profile in nix is a general and convenient concept for realizing rollbacks . profiles are used to compose components that are spread among multiple paths under a new unified path . not only that , but profiles are made up of multiple \" generations \" : they are versioned . whenever you change a profile , a new generation is created . generations can be switched and rolled back atomically , which makes them convenient for managing changes to your system . let ' s take a closer look at our profile : $ ls - l ~ / . nix - profile / bin - > / nix / store / ig31y9gf", "pp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin [ . . . ] manifest . nix - > / nix / store / q8b5238akq07lj9gfb3qb5ycq4dxxiwm - env - manifest . nix [ . . . ] share - > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / share that nix - 2 . 1 . 3", " derivation in the nix store is nix itself , with binaries and libraries . the process of \" installing \" the derivation in the profile basically reproduces the hierarchy of the nix - 2 . 1 . 3 store derivation in the profile by means of symbolic links . the contents of this profile are special , because only one program has been installed in our profile , therefore e . g . the bin directory points to the only program which has been installed ( nix itself ) . but that ' s only the contents of the latest generation of our profile . in fact , ~ / . nix - profile itself is a symbolic link to / nix / var / nix", " / profiles / default . in turn , that ' s a symlink to default - 1 - link in the same directory . yes , that means it ' s the first generation of the default profile . finally , default - 1 - link is a symlink to the nix store \" user - environment \" derivation that you saw printed during the installation process . we ' ll talk about manifest . nix more in the next article . nixpkgs expressions more output from the installer : downloading nix expressions from ` http : / / releases . nixos . org / nixpkgs / nixpkgs - 14 . 10", "pre46060 . a1a2851 / nixexprs . tar . xz ' . . . unpacking channels . . . created 2 symlinks in user environment modifying / home / nix / . profile . . . nix expressions arewritten in the nix language and used to describe packages and how to build them . nixpkgs is the repository containing all of the expressions : https : / / github . com / nixos / nixpkgs . the installer downloaded the package descript ions from commit a1a2851 . the second profile we discover is the channels profile . ~", " / . nix - defexpr / channels points to / nix / var / nix / profiles / per - user / nix / channels which points to channels - 1 - link which points to a nix store directory containing the downloaded nix expressions . channels are a set of packages and expressions available for download . similar to debian stable and unstable , there ' s a stable and unstable channel . in this installation , we ' re tracking nixpkgs - unstable . don ' t worry about nix expressions yet , we ' ll get to them later . finally , for your convenience , the installer modified ~ / . profile to automatically enter the nix", " environment . what ~ / . nix - profile / etc / profile . d / nix . sh really does is simply to add ~ / . nix - profile / bin to path and ~ / . nix - defexpr / channels / nixpkgs to nix _ path . we ' ll discuss nix _ path later . read nix . sh , it ' s short . faq : can i change / nix to something else ? you can , but there ' s a good reason to keep using / nix instead of a different directory . all the derivations depend on other derivations by using absolute paths . we saw in the first article", " that bash referenced a glibc under a specific absolute path in / nix / store . you can see for yourself , don ' t worry if you see multiple bash derivations : $ ldd / nix / store / * bash * / bin / bash [ . . . ] keeping the store in / nix means we can grab the binary cache from nixos . org ( just like you grab packages from debian mirrors ) otherwise : * glibc would be installed under / foo / store * thus bash would need to point to glibc under / foo / store , instead of under / nix / store * so the binary cache", " can ' t help , because we need a different bash , and so we ' d have to recompile everything ourselves . after all / nix is a sensible place for the store . conclusion we ' ve installed nix on our system , fully isolated and owned by the nix user as we ' re still coming to terms with this new system . we learned some new concepts like profiles and channels . in particular , with profiles we ' re able to manage multiple generations of a composition of packages ,while with channels we ' re able to download binaries from nixos . org . the installation put everything under / nix , and some symlinks", " in the nix user home . that ' s because every user is able to install and use software in her own environment . i hope i left nothing uncovered so that you think there ' s some kind of magic going on behind the scenes . it ' s all about putting components in the store and symlinking these components together . next pill . . . . . . we will enter the nix environment and learn how to interact with the store .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ nix store paths welcome to the 18th nix pill . in the previous 17th pill we have scratched the surface of the nixpkgs repository struct ure . it is a set of packages , and it ' s possible to over", "ride such packages so that all other packages will use the overrides . before reading existing derivations , i ' d like to talk about store paths and how they are computed . in particular we are interested in fixed store paths that depend on an integrity hash ( e . g . a sha256 ) , which is usually applied to source tarballs . the way store paths are computed is a little contrived , mostly due to historical reasons . our reference will be the nix source code . source paths let ' s start simple . you know nix allows relative paths to be used , such that the file or directory is stored in the nix", " store , that is . / myfile gets stored into / nix / store / . . . . . . . we want to understand how is the store path generated for such a file : $ echo mycontent > myfile i remind you , the simplest derivation you can write has a name , a builder and the system : $ nix repl nix - repl > derivation { system = \" x86 _ 64 - linux \" ; builder = . / myfile ; name = \" foo \" ; } \u00ab derivation / nix / store / y4h73bmrc9ii5bxg6i", "7ck6hsf5gqv8ck - foo . drv \u00bb now inspect the . drv to see where is . / myfile being stored : $ nix derivation show / nix / store / y4h73bmrc9ii5bxg6i7ck6hsf5gqv8ck - foo . drv { \" / nix / store / y4h73bmrc9ii5bxg6i7ck6hsf5gqv8ck - foo . drv \" : { \" outputs \" : { \" out \" : { \" path", " \" : \" / nix / store / hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 - foo \" } } , \" inputsrcs \" : [ \" / nix / store / xv2iccirbrvklck36f1g7vldn5v58vck - myfile \" ] , \" inputdrvs \" : { } , \" platform \" : \" x86 _ 64 - linux \" , \" builder \" : \" / nix / store / xv2iccirbrvklck36f1g7", "vldn5v58vck - myfile \" , \" args \" : [ ] , \" env \" : { \" builder \" : \" / nix / store / xv2iccirbrvklck36f1g7vldn5v58vck - myfile \" , \" name \" : \" foo \" , \" out \" : \" / nix / store / hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 - foo \" , \" system \" : \" x86 _ 64 - linux \" } } }", " great , how did nix decide to use xv2iccirbrvklck36f1g7vldn5v58vck ? keep looking at the nix comments . note : doing nix - store - - add myfile will store the file in the same store path . step 1 , compute the hash of the file the comments tell us to first compute the sha256 of the nar serialization of the file . can be done in two ways : $ nix - hash - - type sha256 myfile 2bfef67de873c54551d884", "fdab3055d84d573e654efa79db3c0d7b98883f9ee3 or : $ nix - store - - dump myfile | sha256sum 2bfef67de873c54551d884fdab3055d84d573e654efa79db3c0d7b98883f9ee3 in general , nix understands two contents : flat for regular files , or recursive for nar serializations which can be anything", " . step 2 , build the string descript ion then nix uses a special string which includes the hash , the path type and the file name . we store this in another file : $ echo - n \" source : sha256 : 2bfef67de873c54551d884fdab3055d84d573e654efa79db3c0d7b98883f9ee3 : / nix / store : myfile \" > myfile . str step 3 , compute the final hash finally the comments tell us to", " compute the base - 32 representation of the first 160 bits ( truncation ) of a sha256 of the above string : $ nix - hash - - type sha256 - - truncate - - base32 - - flat myfile . str xv2iccirbrvklck36f1g7vldn5v58vck output paths output paths are usually generated for derivations . we use the above example because it ' s simple . even if we didn ' t build the derivation , nix knows the out path hs0yi5n5nw6micqhy8l", "1igkbhqdkzqa1 . this is because the out path only depends on inputs . it ' s computed in a similar way to source paths , except that the . drv is hashed and the type of derivation is output : out . in case of multiple outputs , we may have different output : < id > . at the time nix computes the out path , the . drv contains an empty string for each out path . so what we do is getting our . drv and replacing the out path with an empty string : $ cp - f / nix / store / y4h73bmrc", "9ii5bxg6i7ck6hsf5gqv8ck - foo . drv myout . drv $ sed - i ' s , / nix / store / hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 - foo , , g ' myout . drv the myout . drv is the . drv state in which nix is when computing the out path for our derivation : $ sha256sum myout . drv 1bdc41b9649a0d59f270a9", "2d69ce6b5af0bc82b46cb9d9441ebc6620665f40b5 myout . drv $ echo - n \" output : out : sha256 : 1bdc41b9649a0d59f270a92d69ce6b5af0bc82b46cb9d9441ebc6620665f40b5 : / nix / store : foo \" > myout . str $ nix - hash - - type sha256 - - truncate - - base", "32 - - flat myout . str hs0yi5n5nw6micqhy8l1igkbhqdkzqa1 then nix puts that out path in the . drv , and that ' s it . in case the . drv has input derivations , that is it references other . drv , then such . drv paths are replaced by this same algorithm which returns a hash . in other words , you get a final . drv where every other . drv path is replaced by its hash . fixed - output paths finally , the other most used kind of path is", " when we know beforehand an integrity hash of a file . this is usual for tarballs . a derivation can take three special attributes : outputhashmode , outputhash and outputhashalgo which are well documented in the nix manual . the builder must create the out path and make sure its hash is the same as the one declared with outputhash . let ' s say our builder should create a file whose contents is mycontent : $ echo mycontent > myfile $ sha256sum myfile f3f3c4763037e059b4d834eaf6", "8595bbc02ba19f6d2a500dce06d124e2cd99bb myfile nix - repl > derivation { name = \" bar \" ; system = \" x86 _ 64 - linux \" ; builder = \" none \" ; outputhashmode = \" flat \" ; outputhashalgo = \" sha256 \" ; outputhash = \" f3f3c4763037e059b4d834eaf68595bbc02ba19f6d2a500dce06d124", "e2cd99bb \" ; } \u00ab derivation / nix / store / ymsf5zcqr9wlkkqdjwhqllgwa97rff5i - bar . drv \u00bb inspect the . drv and see that it also stored the fact that it ' s a fixed - output derivation with sha256 algorithm , compared to the previous examples : $ nix derivation show / nix / store / ymsf5zcqr9wlkkqdjwhqllgwa97rff5i - bar . drv { \" / nix / store", " / ymsf5zcqr9wlkkqdjwhqllgwa97rff5i - bar . drv \" : { \" outputs \" : { \" out \" : { \" path \" : \" / nix / store / a00d5f71k0vp5a6klkls0mvr1f7sx6ch - bar \" , \" hashalgo \" : \" sha256 \" , \" hash \" : \" f3f3c4763037e059b4d834eaf68595bbc", "02ba19f6d2a500dce06d124e2cd99bb \" } } , [ . . . ] } it doesn ' t matter which input derivations are being used , the final out path must only depend on the declared hash . what nix does is to create an intermediate string representation of the fixed - output content : $ echo - n \" fixed : out : sha256 : f3f3c4763037e059b4d834eaf68595bbc02ba19f6d2a500dce06d", "124e2cd99bb : \" > mycontent . str $ sha256sum mycontent . str 423e6fdef56d53251c5939359c375bf21ea07aaa8d89ca5798fb374dbcfd7639 myfile . str then proceed as it was a normal derivation output path : $ echo - n \" output : out : sha256 : 423e6fdef56d53251c5939359c375bf21ea", "07aaa8d89ca5798fb374dbcfd7639 : / nix / store : bar \" > myfile . str $ nix - hash - - type sha256 - - truncate - - base32 - - flat myfile . str a00d5f71k0vp5a6klkls0mvr1f7sx6ch hence , the store path only depends on the declared fixed - output hash . conclusion there are other types of store paths , but you get the idea . nix first hashes the contents", " , then creates a string descript ion , and the final store path is the hash of this string . also we ' ve introduced some fundamentals , in particular the fact that nix knows beforehand the out path of a derivation since it only depends on the inputs . we ' ve also introduced fixed - output derivations which are especially used by the nixpkgs repository for downloading and verifying source tarballs . next pill . . . we will introduce stdenv . in the previous pills we rolled our own mkderivation convenience function for wrapping the builtin derivation , but the nixpkgs repository also has its own convenience functions", " for dealing with autotools projects and other build systems .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ enter the environment welcome to the third nix pill . in the second pill we installed nix on our running system . now we can finally play with it a little , these things also apply to nixos users . enter the environment if you", " ' re using nixos , you can skip to the next step . in the previous article we created a nix user , so let ' s start by switching to it with su - nix . if your ~ / . profile got evaluated , then you should now be able to run commands like nix - env and nix - store . if that ' s not the case : $ source ~ / . nix - profile / etc / profile . d / nix . sh to remind you , ~ / . nix - profile / etc points to the nix - 2 . 1 . 3 derivation . at this point , we are in our nix user profile .", " install something finally something practical ! installation into the nix environment is an interesting process . let ' s install hello , a simple cli tool which prints helloworld and is mainly used to test compilers and package installations . back to the installation : $ nix - env - i hello installing ' hello - 2 . 10 ' [ . . . ]building ' / nix / store / 0vqw0ssmh6y5zj48yg34gc6macr883xk - user - environment . drv ' . . . created 36 symlinks in user environment now you can run hello . things", " to notice : * we installed software as a user , and only for the nix user . * it created a new user environment . that ' s a new generation of our nix user profile . * the nix - env tool manages environments , profiles and their generations . * we installed hello by derivation name minus the version . i repeat : we specified the derivation name ( minus the version ) to install it . we can list generations without walking through the / nix hierarchy : $ nix - env - - list - generations 1 2014 - 07 - 24 09 : 23 : 30 2 2014 - 07 - 25 08 : 45 : 01 ( current )", " listing installed derivations : $ nix - env - q nix - 2 . 1 . 3 hello - 2 . 10 so , where did hello really get installed ? which hello is ~ / . nix - profile / bin / hello which points to the store . we can also list the derivation paths with nix - env - q - - out - path . so that ' s what those derivation paths are called : the output of a build . path merging at this point you probably want to run man to get some documentation . even if you already have man system - wide outside of the nix environment , you can install and use it within nix", " with nix - env - i man - db . as usual , a new generation will be created , and ~ / . nix - profile will point to it . let ' s inspect the profile a bit : $ ls - l ~ / . nix - profile / dr - xr - xr - x 2 nix nix 4096 jan 1 1970 bin lrwxrwxrwx 1 nix nix 55 jan 1 1970 etc - > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3", " / etc [ . . . ] now that ' s interesting . when only nix - 2 . 1 . 3 was installed , bin was a symlink to nix - 2 . 1 . 3 . now that we ' ve actually installed some things ( man , hello ) , it ' s a real directory , not a symlink . $ ls - l ~ / . nix - profile / bin / [ . . . ] man - > / nix / store / 83cn9ing5sc6644h50dqzzfxcs07r2jn - man - 1 . 6g / bin / man", " [ . . . ] nix - env - > / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env [ . . . ] hello - > / nix / store / 58r35bqb4f3lxbnbabq718svq9i2pda3 - hello - 2 . 10 / bin / hello [ . . . ] okay , that ' s clearer now . nix - env merged the paths from the installed derivations .", " which man points to the nix profile , rather than the system man , because ~ / . nix - profile / bin is at the head of $ path . rolling back and switching generation the last command installed man . we should be at generation 3 , unless you changed something in the middle . let ' s say we want to rollback to the old generation : $ nix - env - - rollback switching from generation 3 to 2 now nix - env - q does not list man anymore . ls - l ` which man ` should now be your system copy . enough with the rollback , let ' s go back to the most", " recent generation : $ nix - env - g 3 switching from generation 2 to 3 i invite you to read the manpage of nix - env . nix - env requires an operation to perform , then there are common options for all operations , as well as options specific to each operation . you can of course also uninstall and upgrade packages . querying the store so far we learned how to query and manipulate the environment . but all of the environment components point to the store . to query and manipulate the store , there ' s the nix - store command . we can do some interesting things , but we ' ll only see", " some queries for now . to show the direct runtime dependencies of hello : $ nix - store - q - - references ` which hello ` / nix / store / fg4yq8i8wd08xg3fy58l6q73cjy8hjr2 - glibc - 2 . 27 / nix / store / 58r35bqb4f3lxbnbabq718svq9i2pda3 - hello - 2 . 10 the argument to nix - store can be anything as long as it points to the nix store .", " it will follow symlinks . it may not make sense to you right now , but let ' s print reverse dependencies of hello : $ nix - store - q - - referrers ` which hello ` / nix / store / 58r35bqb4f3lxbnbabq718svq9i2pda3 - hello - 2 . 10 / nix / store / fhvy2550cpmjgcjcx5rzz328i0kfv3z3 - env - manifest . nix / nix / store / yzdk0x", "vr0b8dcwhi2nns6d75k2ha5208 - env - manifest . nix / nix / store / mp987abm20c70pl8p31ljw1r5by4xwfw - user - environment / nix / store / ppr3qbq7fk2m2pa49i2z3i32cvfhsv7p - user - environment was it what you expected ? it turns out that our environments depend upon hello . yes , that means that the environments are in the store , and since they contain sy", "mlinks to hello , therefore the environment depends upon hello . two environments were listed , generation 2 and generation 3 , since these are the ones that had hello installed in them . the manifest . nix file contains metadata about the environment , such as which derivations are installed . so that nix - env can list , upgrade or remove them . and yet again , the current manifest . nix can be found at ~ / . nix - profile / manifest . nix . closures the closures of a derivation is a list of all its dependencies , recursively , including absolutely everything necessary to use that derivation . $ nix - store -", " qr ` which man ` [ . . . ] copying all those derivations to the nix store of another machine makes you able to run man out of the box on that other machine . that ' s the base of deployment using nix , and you can already foresee the potential when deploying software in the cloud ( hint : nix - copy - closures and nix - store - - export ) . a nicer view of the closure : $ nix - store - q - - tree ` which man ` [ . . . ] with the above command , you can find out exactly why a runtime dependency , be it direct or indirect", " , exists for a given derivation . the same applies to environments . as an exercise , run nix - store - q - - tree ~ / . nix - profile , and see that the first children are direct dependencies of the user environment : the installed derivations , and the manifest . nix . dependency resolution there isn ' t anything like apt which solves a sat problem in order to satisfy dependencies with lower and upper bounds on versions . there ' s no need for this because all the dependencies are static : if a derivation x depends on a derivation y , then it always depends on it . a version of x which depended on z", " would be a different derivation . recovering the hard way $ nix - env - e ' * ' uninstalling ' hello - 2 . 10 ' uninstalling ' nix - 2 . 1 . 3 ' [ . . . ] oops , that uninstalled all derivations from the environment , including nix . that means we can ' t even run nix - env , what now ? previously we got nix - env from the environment . environments are a convenience for the user , but nix is still there in the store ! first , pick one nix - 2 . 1 . 3 derivation : ls / nix", " / store / * nix - 2 . 1 . 3 , say / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 . the first option is to rollback : $ / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env - - rollback the second option is to install nix , thus creating a new generation : $ / nix / store / ig31y", "9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env - i / nix / store / ig31y9gfpp8pf3szdd7d4sf29zr7igbr - nix - 2 . 1 . 3 / bin / nix - env channels so where are we getting packages from ? we said something about this already in the second article . there ' s a list of channels from which we get packages , although usually we use a single channel . the tool to manage channels is nix - channel .", " $ nix - channel - - list nixpkgs http : / / nixos . org / channels / nixpkgs - unstable if you ' re using nixos , you may not see any output from the above command ( if you ' re using the default ) , or you may see a channel whose name begins with \" nixos - \" instead of \" nixpkgs \" . that ' s essentially the contents of ~ / . nix - channels . note : ~ / . nix - channels is not a symlink to the nix store ! to update the channel run nix - channel - - update . that will download", " the new nix expressions ( descript ions of the packages ) , create a new generation of the channels profile and unpack it under ~ / . nix - defexpr / channels . this is quite similar to apt - get update . ( see this table for a rough mapping between ubuntu and nixos package management . ) conclusion we learned how to query the user environment and to manipulate it by installing and uninstalling software . upgrading software is also straightforward , as you can read in the manual ( nix - env - u will upgrade all packages in the environment ) . every time we change the environment , a new generation", " is created . switching between generations is easy and immediate . then we learned how to query the store . we inspected the dependencies and reverse dependencies of store paths . we saw how symlinks are used to compose paths from the nix store , a useful trick . a quick analogy with programming languages : you have the heap with all the objects , that corresponds to the nix store . you have objects that point to other objects , those correspond to derivations . this is a suggestive metaphor , but will it be the right path ? next pill . . . we will learn the basics of the nix language . the nix language is used to", " describe how to build derivations , and it ' s the basis for everything else , including nixos . therefore it ' s very important to understand both the syntax and the semantics of the language .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ preface this is a ported version of the nix pills , a series of blog postswritten by luca bruno ( aka lethalman ) and originally published in 2014 and 2015 . it provides a tutorial introduction into the nix package manager and nix", "pkgs package collection , in the form of short chapters called ' pills ' . since the nix pills are considered a classic introduction to nix , an effort to port them to the current format was led by graham christensen ( aka grahamc / gchristensen ) and other contributors in 2017 . for an up - to - date version , please visit https : / / nixos . org / guides / nix - pills / . an epub version is also available . if you encounter problems , please report them on the nixos / nix - pills issue tracker .", " [ ] 1 . preface 2 . 1 . why you should give it a try 3 . 2 . install on your running system 4 . 3 . enter the environment 5 . 4 . the basics of the language 6 . 5 . functions and imports 7 . 6 . our first derivation 8 . 7 . working derivation 9 . 8 . generic builders 10 . 9 . automatic runtime dependencies 11 . 10 . developing with nix - shell 12 . 11 . the garbage collector 13 . 12 . package repositories and the inputs design pattern 14 . 13 . callpackage design pattern 15 . 14 . override design pattern 16 . 15 . nix", " search paths 17 . 16 . nixpkgs parameters 18 . 17 . nixpkgs overriding packages 19 . 18 . nix store paths 20 . 19 . fundamentals of stdenv 21 . 20 . basic dependencies and hooks * light * rust * coal * navy * ayu nix pills _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ basic dependencies and hooks welcome to the 20th nix pill . in the previous 19th pill we introduced nixpkgs ' stdenv , including setup . sh script , default - builder . sh helper script , and", " stdenv . mkderivation builder . we focused on how stdenv is put together , and how it ' s used , and a bit about the phases of genericbuild . this time , we ' ll focus on the interaction of packages built with stdenv . mkderivation . packages need to depend on each other , of course . for this we have buildinputs and propagatedbuildinputs attributes . we ' ve also found that dependencies sometimes need to influence their dependents in ways the dependents can ' t or shouldn ' t predict . for this we have setup hooks and en", "v hooks . together , these 4 concepts support almost all build - time package interactions . note : the complexity of the dependencies and hooks infrastruct ure has increased , over time , to support cross compilation . once you learn the core concepts , you will be able to understand the extra complexity . as a starting point , you might want to refer to nixpkgs commit 6675f0a5 , the last version of stdenv without cross - compilation complexity . the buildinputs attribute for the simplest dependencies where the current package directly needs another , we use the buildinputs attribute . this is exactly", " the pattern used in our builder in pill 8 . to demo this , let ' s build gnu hello , and then another package which provides a shell script that execs it . let nixpkgs = import < nixpkgs > { } ; inherit ( nixpkgs ) stdenv fetchurl which ; actualhello = stdenv . mkderivation { name = \" hello - 2 . 3 \" ; src = fetchurl { url = \" mirror : / / gnu / hello / hello - 2 . 3 . tar . bz2 \" ; sha256 = \" 0", "c7vijq8y68bpr7g6dh1gny0bff8qq81vnp4ch8pjzvg56wb3js1 \" ; } ; } ; wrappedhello = stdenv . mkderivation { name = \" hello - wrapper \" ; buildinputs = [ actualhello which ] ; unpackphase = \" true \" ; installphase = ' ' mkdir - p \" $ out / bin \" echo \" # ! $ { stdenv . shell } \" > > \" $ out / bin / hello", " \" echo \" exec $ ( which hello ) \" > > \" $ out / bin / hello \" chmod 0755 \" $ out / bin / hello \" ' ' ; } ; in wrappedhello notice that the wrappedhello derivation finds the hello binary from the path . this works because stdenv contains something like : pkgs = \" \" for i in $ buildinputs ; do findinputs $ i done where findinputs is defined like : findinputs ( ) { local pkg = $ 1 # # don ' t need to repeat already processed package case $ p", "kgs in * \\ $ pkg \\ * ) return 0 ; ; esac pkgs = \" $ pkgs $ pkg \" # # more goes here in reality that we can ignore for now . } then after this is run : for i in $ pkgs ; do addtoenv $ i done where addtoenv is defined like : addtoenv ( ) { local pkg = $ 1 if test - d $ 1 / bin ; then addtosearchpath _ path $ 1 / bin fi # # more goes here in reality that we can ignore for now .", " } the addtosearchpath call adds $ 1 / bin to _ path if the former exists ( code here ) . once all the packages in buildinputs have been processed , then content of _ path is added to path , as follows : path = \" $ { _ path - } $ { _ path : + $ { path : + : } } $ path \" with the real hello on the path , the installphase should hopefully make sense . the propagatedbuildinputs attribute the buildinputs covers direct dependencies , but what about indirect dependencies where one package needs a second package which", " needs a third ? nix itself handles this just fine , understanding various dependency closures as covered in previous builds . but what about the conveniences that buildinputs provides , namely accumulating in pkgs environment variable and inclusion of \u00ab pkg \u00bb / bin directories on the path ? for this , stdenv provides the propagatedbuildinputs : let nixpkgs = import < nixpkgs > { } ; inherit ( nixpkgs ) stdenv fetchurl which ; actualhello = stdenv . mkderivation { name = \" hello - 2 .", " 3 \" ; src = fetchurl { url = \" mirror : / / gnu / hello / hello - 2 . 3 . tar . bz2 \" ; sha256 = \" 0c7vijq8y68bpr7g6dh1gny0bff8qq81vnp4ch8pjzvg56wb3js1 \" ; } ; } ; intermediary = stdenv . mkderivation { name = \" middle - man \" ; propagatedbuildinputs = [ actualhello ] ; unpackphase =", " \" true \" ; installphase = ' ' mkdir - p \" $ out \" ' ' ; } ; wrappedhello = stdenv . mkderivation { name = \" hello - wrapper \" ; buildinputs = [ intermediary which ] ; unpackphase = \" true \" ; installphase = ' ' mkdir - p \" $ out / bin \" echo \" # ! $ { stdenv . shell } \" > > \" $ out / bin / hello \" echo \" exec $ ( which hello ) \" > > \" $ out / bin / hello \" chmo", "d 0755 \" $ out / bin / hello \" ' ' ; } ; in wrappedhello see how the intermediate package has a propagatedbuildinputs dependency , but the wrapper only needs a buildinputs dependency on the intermediary . how does this work ? you might think we do something in nix , but actually it ' s done not at eval time but at build time in bash . let ' s look at part of the fixupphase of stdenv : fixupphase ( ) { # # elided if test - n \" $ propagatedbuildinput", "s \" ; then mkdir - p \" $ out / nix - support \" echo \" $ propagatedbuildinputs \" > \" $ out / nix - support / propagated - build - inputs \" fi # # elided } this dumps the propagated build inputs in a so - named file in $ out / nix - support / . then , back in findinputs look at the lines at the bottom we elided before : findinputs ( ) { local pkg = $ 1 # # more goes here in reality that we can ignore for now . if test - f", " $ pkg / nix - support / propagated - build - inputs ; then for i in $ ( cat $ pkg / nix - support / propagated - build - inputs ) ; do findinputs $ i done fi } see how findinputs is actually recursive , looking at the propagated build inputs of each dependency , and those dependencies ' propagated build inputs , etc . we actually simplified the findinputs call site from before ; propagatedbuildinputs is also looped over in reality : pkgs = \" \" for i in $", " buildinputs $ propagatedbuildinputs ; do findinputs $ i done this demonstrates an important point . for the current package alone , it doesn ' t matter whether a dependency is propagated or not . it will be processed the same way : called with findinputs and addtoenv . ( the packages discovered by findinputs , which are also accumulated in pkgs and passed to addtoenv , are also the same in both cases . ) downstream however , it certainly does matter because only the propagated immediate dependencies are put in the $ out / nix", " - support / propagated - build - inputs . setup hooks as we mentioned above , sometimes dependencies need to influence the packages that use them in ways other than just being a dependency . ^ 1 propagatedbuildinputs can actually be seen as an example of this : packages using that are effectively \" injecting \" those dependencies as extra buildinputs in their downstream dependents . but in general , a dependency might affect the packages it depends on in arbitrary ways . arbitrary is the key word here . we could teach setup . sh things about upstream packages like \u00ab pkg \u00bb / nix - support /", " propagated - build - inputs , but not arbitrary interactions . setup hooks are the basicbuilding block we have for this . in nixpkgs , a \" hook \" is basically a bash callback , and a setup hook is no exception . let ' s look at the last part of findinputs we haven ' t covered : findinputs ( ) { local pkg = $ 1 # # more goes here in reality that we can ignore for now . if test - f $ pkg / nix - support / setup - hook ; then source $ pkg / nix - support / setup - hook", " fi # # more goes here in reality that we can ignore for now . } if a package includes the path \u00ab pkg \u00bb / nix - support / setup - hook , it will be sourced by any stdenv - based build including that as a dependency . this is strictly more general than any of the other mechanisms introduced in this chapter . for example , try writing a setup hook that has the same effect as a propagatedbuildinputs entry . one can almost think of this as an escape hatch around nix ' s normal isolation guarantees , and the principle that dependencies are immutable and inert . we", " ' re not actually doing something unsafe or modifying dependencies , but we are allowing arbitrary ad - hoc behavior . for this reason , setup - hooks should only be used as a last resort . environment hooks as a final convenience , we have environment hooks . recall in pill 12 how we created nix _ cflags _ compile for - i flags and nix _ ldflags for - l flags , in a similar manner to how we prepared the path . one point of ugliness was how anti - modular this was . it makes sense to build the path in a generic builder , because the path is used by the shell , and the generic", " builder is intrinsically tied to the shell . but - i and - l flags are only relevant to the c compiler . the stdenv isn ' t wedded to including a c compiler ( though it does by default ) , and there are other compilers too which may take completely different flags . as a first step , we can move that logic to a setup hook on the c compiler ; indeed that ' s just what we do in cc wrapper . ^ 2 but this pattern comes up fairly often , so somebody decided to add some helper support to reduce boilerplate . the other half of addtoenv is : addto", "env ( ) { local pkg = $ 1 # # more goes here in reality that we can ignore for now . # run the package - specific hooks set by the setup - hook script s . for i in \" $ { envhooks [ @ ] } \" ; do $ i $ pkg done } functions listed in envhooks are applied to every package passed to addtoenv . one can write a setup hook like : anenvhook ( ) { local pkg = $ 1 echo \" i ' m depending on \\ \" $ pkg \\ \" \"", " } envhooks + = ( anenvhook ) and if one dependency has that setup hook then all of them will be so echoed . allowing dependencies to learn about their sibling dependencies is exactly what compilers need . next pill . . . . . . i ' m not sure ! we could talk about the additional dependency types and hooks which cross compilation necessitates ,building on our knowledge here to cover stdenv as it works today . we could talk about how nixpkgs is bootstrapped . or we could talk about how localsystem and crosssystem are elaborated into the", " buildplatform , hostplatform , and targetplatform each bootstrapping stage receives . let us know which most interests you ! ^ 1 we can now be precise and consider what addtoenv does alone the minimal treatment of a dependency : i . e . a package that is just a dependency would only have addtoenv applied to it . ^ 2 it was called gcc wrapper in the version of nixpkgs suggested for following along in this pill ; darwin and clang support hadn ' t yet motivated the rename ."]